{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-24T20:43:18.833817Z",
     "start_time": "2024-05-24T20:43:18.704613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output at epoch 0: tensor([[ 0.7302, -0.5910],\n",
      "        [ 2.2035, -2.2061],\n",
      "        [ 1.2731, -1.1809],\n",
      "        [ 3.1928, -3.1440]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 0: 2.2809104919433594\n",
      "Epoch 0, Loss: 2.2809104919433594\n",
      "Output at epoch 1: tensor([[ 0.2767, -0.3033],\n",
      "        [ 1.6833, -1.5866],\n",
      "        [ 0.6882, -0.7111],\n",
      "        [ 2.4871, -2.3077]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 1: 1.726210594177246\n",
      "Output at epoch 2: tensor([[-0.1195, -0.0550],\n",
      "        [ 1.1921, -0.9901],\n",
      "        [ 0.1775, -0.2969],\n",
      "        [ 1.8210, -1.5027]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 2: 1.2875335216522217\n",
      "Output at epoch 3: tensor([[-0.4382,  0.1507],\n",
      "        [ 0.6311, -0.5959],\n",
      "        [-0.2620,  0.0011],\n",
      "        [ 1.0706, -0.9511]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 3: 1.0009478330612183\n",
      "Output at epoch 4: tensor([[-0.6958,  0.3197],\n",
      "        [ 0.0797, -0.2440],\n",
      "        [-0.6273,  0.2377],\n",
      "        [ 0.3263, -0.4737]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 4: 0.8478530645370483\n",
      "Output at epoch 5: tensor([[-0.8717,  0.4407],\n",
      "        [-0.3836,  0.0567],\n",
      "        [-0.8950,  0.4153],\n",
      "        [-0.3243, -0.0548]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 5: 0.8236075639724731\n",
      "Output at epoch 6: tensor([[-0.9694,  0.5080],\n",
      "        [-0.7233,  0.2809],\n",
      "        [-1.0459,  0.5177],\n",
      "        [-0.8250,  0.2660]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 6: 0.8697522282600403\n",
      "Output at epoch 7: tensor([[-0.9882,  0.5206],\n",
      "        [-0.9493,  0.4266],\n",
      "        [-1.0954,  0.5503],\n",
      "        [-1.1676,  0.4778]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 7: 0.915618896484375\n",
      "Output at epoch 8: tensor([[-0.9459,  0.4920],\n",
      "        [-1.0710,  0.5020],\n",
      "        [-1.0647,  0.5290],\n",
      "        [-1.3413,  0.5846]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 8: 0.9333696365356445\n",
      "Output at epoch 9: tensor([[-0.8605,  0.4350],\n",
      "        [-1.1085,  0.5218],\n",
      "        [-0.9759,  0.4697],\n",
      "        [-1.3983,  0.6158]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 9: 0.9208605289459229\n",
      "Output at epoch 10: tensor([[-0.7462,  0.3596],\n",
      "        [-1.0809,  0.4994],\n",
      "        [-0.8474,  0.3852],\n",
      "        [-1.3689,  0.5910]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 10: 0.8867079019546509\n",
      "Epoch 10, Loss: 0.8867079019546509\n",
      "Output at epoch 11: tensor([[-0.6141,  0.2735],\n",
      "        [-1.0046,  0.4463],\n",
      "        [-0.6939,  0.2855],\n",
      "        [-1.2749,  0.5254]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 11: 0.8414158821105957\n",
      "Output at epoch 12: tensor([[-0.4739,  0.1830],\n",
      "        [-0.8936,  0.3720],\n",
      "        [-0.5279,  0.1790],\n",
      "        [-1.1350,  0.4316]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 12: 0.7947803139686584\n",
      "Output at epoch 13: tensor([[-0.3335,  0.0934],\n",
      "        [-0.7599,  0.2845],\n",
      "        [-0.3603,  0.0726],\n",
      "        [-0.9656,  0.3207]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 13: 0.7547593116760254\n",
      "Output at epoch 14: tensor([[-0.2003,  0.0092],\n",
      "        [-0.6147,  0.1912],\n",
      "        [-0.2010, -0.0275],\n",
      "        [-0.7814,  0.2023]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 14: 0.7265925407409668\n",
      "Output at epoch 15: tensor([[-0.0806, -0.0658],\n",
      "        [-0.4682,  0.0986],\n",
      "        [-0.0583, -0.1163],\n",
      "        [-0.5964,  0.0853]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 15: 0.7121430039405823\n",
      "Output at epoch 16: tensor([[ 0.0206, -0.1286],\n",
      "        [-0.3297,  0.0124],\n",
      "        [ 0.0609, -0.1897],\n",
      "        [-0.4230, -0.0228]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 16: 0.7098091840744019\n",
      "Output at epoch 17: tensor([[ 0.0997, -0.1773],\n",
      "        [-0.2073, -0.0628],\n",
      "        [ 0.1515, -0.2451],\n",
      "        [-0.2719, -0.1157]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 17: 0.715333104133606\n",
      "Output at epoch 18: tensor([[ 0.1548, -0.2110],\n",
      "        [-0.1069, -0.1235],\n",
      "        [ 0.2111, -0.2811],\n",
      "        [-0.1507, -0.1891]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 18: 0.7233749032020569\n",
      "Output at epoch 19: tensor([[ 0.1857, -0.2297],\n",
      "        [-0.0317, -0.1682],\n",
      "        [ 0.2390, -0.2979],\n",
      "        [-0.0639, -0.2407]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 19: 0.7292003631591797\n",
      "Output at epoch 20: tensor([[ 0.1936, -0.2345],\n",
      "        [ 0.0170, -0.1964],\n",
      "        [ 0.2370, -0.2966],\n",
      "        [-0.0129, -0.2701]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 20: 0.7297908067703247\n",
      "Epoch 20, Loss: 0.7297908067703247\n",
      "Output at epoch 21: tensor([[ 0.1808, -0.2268],\n",
      "        [ 0.0402, -0.2090],\n",
      "        [ 0.2079, -0.2792],\n",
      "        [ 0.0038, -0.2786]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 21: 0.7241535782814026\n",
      "Output at epoch 22: tensor([[ 0.1505, -0.2086],\n",
      "        [ 0.0403, -0.2076],\n",
      "        [ 0.1557, -0.2482],\n",
      "        [-0.0105, -0.2683]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 22: 0.7130332589149475\n",
      "Output at epoch 23: tensor([[ 0.1062, -0.1822],\n",
      "        [ 0.0209, -0.1946],\n",
      "        [ 0.0850, -0.2064],\n",
      "        [-0.0512, -0.2424]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 23: 0.6983287930488586\n",
      "Output at epoch 24: tensor([[ 0.0516, -0.1497],\n",
      "        [-0.0141, -0.1724],\n",
      "        [ 0.0008, -0.1568],\n",
      "        [-0.1127, -0.2043]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 24: 0.6824368834495544\n",
      "Output at epoch 25: tensor([[-0.0094, -0.1137],\n",
      "        [-0.0601, -0.1439],\n",
      "        [-0.0920, -0.1024],\n",
      "        [-0.1888, -0.1577]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 25: 0.6676451563835144\n",
      "Output at epoch 26: tensor([[-0.0730, -0.0762],\n",
      "        [-0.1124, -0.1119],\n",
      "        [-0.1883, -0.0462],\n",
      "        [-0.2735, -0.1064]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 26: 0.6556529998779297\n",
      "Output at epoch 27: tensor([[-0.1354, -0.0396],\n",
      "        [-0.1665, -0.0790],\n",
      "        [-0.2833,  0.0091],\n",
      "        [-0.3605, -0.0539]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 27: 0.6472886800765991\n",
      "Output at epoch 28: tensor([[-0.1933, -0.0058],\n",
      "        [-0.2181, -0.0478],\n",
      "        [-0.3726,  0.0609],\n",
      "        [-0.4441, -0.0036]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 28: 0.6424604654312134\n",
      "Output at epoch 29: tensor([[-0.2437,  0.0235],\n",
      "        [-0.2634, -0.0205],\n",
      "        [-0.4524,  0.1070],\n",
      "        [-0.5193,  0.0414]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 29: 0.6403310894966125\n",
      "Output at epoch 30: tensor([[-0.2845,  0.0471],\n",
      "        [-0.2995,  0.0012],\n",
      "        [-0.5197,  0.1456],\n",
      "        [-0.5820,  0.0789]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 30: 0.6396421194076538\n",
      "Epoch 30, Loss: 0.6396421194076538\n",
      "Output at epoch 31: tensor([[-0.3140,  0.0639],\n",
      "        [-0.3243,  0.0160],\n",
      "        [-0.5724,  0.1756],\n",
      "        [-0.6294,  0.1071]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 31: 0.6390777230262756\n",
      "Output at epoch 32: tensor([[-0.3313,  0.0734],\n",
      "        [-0.3366,  0.0233],\n",
      "        [-0.6092,  0.1962],\n",
      "        [-0.6598,  0.1251]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 32: 0.6375695466995239\n",
      "Output at epoch 33: tensor([[-0.3364,  0.0757],\n",
      "        [-0.3361,  0.0230],\n",
      "        [-0.6251,  0.2037],\n",
      "        [-0.6730,  0.1328]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 33: 0.6351419687271118\n",
      "Output at epoch 34: tensor([[-0.3269,  0.0690],\n",
      "        [-0.3226,  0.0148],\n",
      "        [-0.6224,  0.2000],\n",
      "        [-0.6684,  0.1298]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 34: 0.630609929561615\n",
      "Output at epoch 35: tensor([[-3.0438e-01,  5.4279e-02],\n",
      "        [-2.9784e-01, -2.5449e-04],\n",
      "        [-6.0717e-01,  1.8910e-01],\n",
      "        [-6.4831e-01,  1.1730e-01]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 35: 0.6238977909088135\n",
      "Output at epoch 36: tensor([[-0.2709,  0.0329],\n",
      "        [-0.2639, -0.0208],\n",
      "        [-0.5816,  0.1722],\n",
      "        [-0.6156,  0.0973]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 36: 0.6158065795898438\n",
      "Output at epoch 37: tensor([[-0.2289,  0.0062],\n",
      "        [-0.2235, -0.0453],\n",
      "        [-0.5452,  0.1487],\n",
      "        [-0.5740,  0.0718]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 37: 0.6076199412345886\n",
      "Output at epoch 38: tensor([[-0.1840, -0.0220],\n",
      "        [-0.1806, -0.0712],\n",
      "        [-0.5006,  0.1201],\n",
      "        [-0.5291,  0.0445]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 38: 0.6009700298309326\n",
      "Output at epoch 39: tensor([[-0.1387, -0.0503],\n",
      "        [-0.1379, -0.0969],\n",
      "        [-0.4557,  0.0915],\n",
      "        [-0.4848,  0.0177]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 39: 0.5954707860946655\n",
      "Output at epoch 40: tensor([[-0.0952, -0.0773],\n",
      "        [-0.0983, -0.1209],\n",
      "        [-0.4134,  0.0648],\n",
      "        [-0.4446, -0.0066]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 40: 0.591071367263794\n",
      "Epoch 40, Loss: 0.591071367263794\n",
      "Output at epoch 41: tensor([[-0.0553, -0.1021],\n",
      "        [-0.0638, -0.1418],\n",
      "        [-0.3764,  0.0414],\n",
      "        [-0.4118, -0.0265]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 41: 0.587451159954071\n",
      "Output at epoch 42: tensor([[-0.0207, -0.1237],\n",
      "        [-0.0364, -0.1585],\n",
      "        [-0.3467,  0.0225],\n",
      "        [-0.3887, -0.0405]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 42: 0.5841363668441772\n",
      "Output at epoch 43: tensor([[ 0.0074, -0.1415],\n",
      "        [-0.0170, -0.1705],\n",
      "        [-0.3259,  0.0089],\n",
      "        [-0.3769, -0.0478]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 43: 0.5806406736373901\n",
      "Output at epoch 44: tensor([[ 0.0285, -0.1550],\n",
      "        [-0.0063, -0.1774],\n",
      "        [-0.3148,  0.0012],\n",
      "        [-0.3772, -0.0478]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 44: 0.5765914916992188\n",
      "Output at epoch 45: tensor([[ 0.0423, -0.1642],\n",
      "        [-0.0041, -0.1793],\n",
      "        [-0.3137, -0.0004],\n",
      "        [-0.3894, -0.0407]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 45: 0.5718094110488892\n",
      "Output at epoch 46: tensor([[ 0.0491, -0.1692],\n",
      "        [-0.0095, -0.1767],\n",
      "        [-0.3222,  0.0038],\n",
      "        [-0.4123, -0.0270]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 46: 0.5663269758224487\n",
      "Output at epoch 47: tensor([[ 0.0496, -0.1704],\n",
      "        [-0.0211, -0.1702],\n",
      "        [-0.3393,  0.0133],\n",
      "        [-0.4441, -0.0077]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 47: 0.5603471994400024\n",
      "Output at epoch 48: tensor([[ 0.0450, -0.1685],\n",
      "        [-0.0372, -0.1610],\n",
      "        [-0.3636,  0.0273],\n",
      "        [-0.4825,  0.0157]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 48: 0.5541616678237915\n",
      "Output at epoch 49: tensor([[ 0.0365, -0.1643],\n",
      "        [-0.0555, -0.1503],\n",
      "        [-0.3933,  0.0447],\n",
      "        [-0.5246,  0.0416]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 49: 0.5480526089668274\n",
      "Output at epoch 50: tensor([[ 0.0258, -0.1587],\n",
      "        [-0.0739, -0.1393],\n",
      "        [-0.4263,  0.0643],\n",
      "        [-0.5672,  0.0683]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 50: 0.5422099232673645\n",
      "Epoch 50, Loss: 0.5422099232673645\n",
      "Output at epoch 51: tensor([[ 0.0143, -0.1525],\n",
      "        [-0.0901, -0.1296],\n",
      "        [-0.4559,  0.0815],\n",
      "        [-0.6075,  0.0938]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 51: 0.537416934967041\n",
      "Output at epoch 52: tensor([[ 0.0082, -0.1501],\n",
      "        [-0.1007, -0.1232],\n",
      "        [-0.4775,  0.0932],\n",
      "        [-0.6405,  0.1151]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 52: 0.5330319404602051\n",
      "Output at epoch 53: tensor([[ 0.0079, -0.1516],\n",
      "        [-0.1044, -0.1209],\n",
      "        [-0.4945,  0.1022],\n",
      "        [-0.6645,  0.1311]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 53: 0.528157114982605\n",
      "Output at epoch 54: tensor([[ 0.0136, -0.1570],\n",
      "        [-0.1006, -0.1233],\n",
      "        [-0.5067,  0.1081],\n",
      "        [-0.6788,  0.1412]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 54: 0.5226470232009888\n",
      "Output at epoch 55: tensor([[ 0.0250, -0.1664],\n",
      "        [-0.0893, -0.1302],\n",
      "        [-0.5141,  0.1110],\n",
      "        [-0.6833,  0.1454]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 55: 0.5164687633514404\n",
      "Output at epoch 56: tensor([[ 0.0416, -0.1793],\n",
      "        [-0.0710, -0.1415],\n",
      "        [-0.5172,  0.1113],\n",
      "        [-0.6789,  0.1442]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 56: 0.5097053050994873\n",
      "Output at epoch 57: tensor([[ 0.0626, -0.1953],\n",
      "        [-0.0471, -0.1563],\n",
      "        [-0.5132,  0.1066],\n",
      "        [-0.6672,  0.1384]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 57: 0.5031060576438904\n",
      "Output at epoch 58: tensor([[ 0.0819, -0.2101],\n",
      "        [-0.0206, -0.1727],\n",
      "        [-0.5078,  0.1010],\n",
      "        [-0.6528,  0.1312]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 58: 0.4970473051071167\n",
      "Output at epoch 59: tensor([[ 0.0987, -0.2232],\n",
      "        [ 0.0067, -0.1897],\n",
      "        [-0.5063,  0.0982],\n",
      "        [-0.6381,  0.1239]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 59: 0.49094587564468384\n",
      "Output at epoch 60: tensor([[ 0.1122, -0.2342],\n",
      "        [ 0.0332, -0.2062],\n",
      "        [-0.5097,  0.0987],\n",
      "        [-0.6252,  0.1178]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 60: 0.4847627282142639\n",
      "Epoch 60, Loss: 0.4847627282142639\n",
      "Output at epoch 61: tensor([[ 0.1221, -0.2427],\n",
      "        [ 0.0575, -0.2214],\n",
      "        [-0.5187,  0.1031],\n",
      "        [-0.6162,  0.1142]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 61: 0.4784347712993622\n",
      "Output at epoch 62: tensor([[ 0.1281, -0.2487],\n",
      "        [ 0.0784, -0.2345],\n",
      "        [-0.5334,  0.1115],\n",
      "        [-0.6124,  0.1140]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 62: 0.4719060957431793\n",
      "Output at epoch 63: tensor([[ 0.1306, -0.2523],\n",
      "        [ 0.0954, -0.2454],\n",
      "        [-0.5535,  0.1236],\n",
      "        [-0.6145,  0.1175]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 63: 0.4651550352573395\n",
      "Output at epoch 64: tensor([[ 0.1303, -0.2539],\n",
      "        [ 0.1084, -0.2538],\n",
      "        [-0.5782,  0.1391],\n",
      "        [-0.6226,  0.1250]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 64: 0.4582052528858185\n",
      "Output at epoch 65: tensor([[ 0.1283, -0.2542],\n",
      "        [ 0.1179, -0.2600],\n",
      "        [-0.6062,  0.1572],\n",
      "        [-0.6362,  0.1360]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 65: 0.4511154890060425\n",
      "Output at epoch 66: tensor([[ 0.1256, -0.2539],\n",
      "        [ 0.1247, -0.2646],\n",
      "        [-0.6358,  0.1767],\n",
      "        [-0.6540,  0.1498]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 66: 0.4439530670642853\n",
      "Output at epoch 67: tensor([[ 0.1238, -0.2539],\n",
      "        [ 0.1300, -0.2682],\n",
      "        [-0.6652,  0.1966],\n",
      "        [-0.6743,  0.1655]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 67: 0.4367639720439911\n",
      "Output at epoch 68: tensor([[ 0.1241, -0.2551],\n",
      "        [ 0.1351, -0.2717],\n",
      "        [-0.6928,  0.2156],\n",
      "        [-0.6955,  0.1817]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 68: 0.42955395579338074\n",
      "Output at epoch 69: tensor([[ 0.1277, -0.2584],\n",
      "        [ 0.1412, -0.2760],\n",
      "        [-0.7169,  0.2328],\n",
      "        [-0.7158,  0.1975]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 69: 0.4222889542579651\n",
      "Output at epoch 70: tensor([[ 0.1355, -0.2642],\n",
      "        [ 0.1494, -0.2817],\n",
      "        [-0.7346,  0.2460],\n",
      "        [-0.7336,  0.2119]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 70: 0.41512373089790344\n",
      "Epoch 70, Loss: 0.41512373089790344\n",
      "Output at epoch 71: tensor([[ 0.1527, -0.2767],\n",
      "        [ 0.1621, -0.2905],\n",
      "        [-0.7428,  0.2529],\n",
      "        [-0.7457,  0.2224]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 71: 0.40748709440231323\n",
      "Output at epoch 72: tensor([[ 0.1787, -0.2952],\n",
      "        [ 0.1789, -0.3021],\n",
      "        [-0.7407,  0.2526],\n",
      "        [-0.7525,  0.2292]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 72: 0.3996485769748688\n",
      "Output at epoch 73: tensor([[ 0.2067, -0.3151],\n",
      "        [ 0.1974, -0.3150],\n",
      "        [-0.7356,  0.2505],\n",
      "        [-0.7575,  0.2350]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 73: 0.3919067978858948\n",
      "Output at epoch 74: tensor([[ 0.2351, -0.3353],\n",
      "        [ 0.2166, -0.3285],\n",
      "        [-0.7307,  0.2487],\n",
      "        [-0.7622,  0.2408]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 74: 0.38416600227355957\n",
      "Output at epoch 75: tensor([[ 0.2627, -0.3550],\n",
      "        [ 0.2356, -0.3418],\n",
      "        [-0.7278,  0.2483],\n",
      "        [-0.7681,  0.2474]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 75: 0.3764265179634094\n",
      "Output at epoch 76: tensor([[ 0.2880, -0.3733],\n",
      "        [ 0.2533, -0.3544],\n",
      "        [-0.7285,  0.2505],\n",
      "        [-0.7764,  0.2556]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 76: 0.3686582148075104\n",
      "Output at epoch 77: tensor([[ 0.3102, -0.3895],\n",
      "        [ 0.2694, -0.3659],\n",
      "        [-0.7342,  0.2561],\n",
      "        [-0.7879,  0.2662]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 77: 0.36082330346107483\n",
      "Output at epoch 78: tensor([[ 0.3289, -0.4034],\n",
      "        [ 0.2836, -0.3762],\n",
      "        [-0.7452,  0.2656],\n",
      "        [-0.8027,  0.2791]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 78: 0.3528994917869568\n",
      "Output at epoch 79: tensor([[ 0.3440, -0.4149],\n",
      "        [ 0.2963, -0.3855],\n",
      "        [-0.7616,  0.2788],\n",
      "        [-0.8204,  0.2942]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 79: 0.3448941111564636\n",
      "Output at epoch 80: tensor([[ 0.3560, -0.4244],\n",
      "        [ 0.3081, -0.3942],\n",
      "        [-0.7827,  0.2953],\n",
      "        [-0.8402,  0.3108]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 80: 0.3368397653102875\n",
      "Epoch 80, Loss: 0.3368397653102875\n",
      "Output at epoch 81: tensor([[ 0.3660, -0.4324],\n",
      "        [ 0.3200, -0.4030],\n",
      "        [-0.8072,  0.3144],\n",
      "        [-0.8607,  0.3280]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 81: 0.32877814769744873\n",
      "Output at epoch 82: tensor([[ 0.3750, -0.4398],\n",
      "        [ 0.3330, -0.4126],\n",
      "        [-0.8335,  0.3350],\n",
      "        [-0.8804,  0.3449]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 82: 0.32074153423309326\n",
      "Output at epoch 83: tensor([[ 0.3842, -0.4473],\n",
      "        [ 0.3481, -0.4236],\n",
      "        [-0.8557,  0.3525],\n",
      "        [-0.8981,  0.3605]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 83: 0.31319960951805115\n",
      "Output at epoch 84: tensor([[ 0.4002, -0.4600],\n",
      "        [ 0.3675, -0.4379],\n",
      "        [-0.8727,  0.3663],\n",
      "        [-0.9102,  0.3722]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 84: 0.30536460876464844\n",
      "Output at epoch 85: tensor([[ 0.4226, -0.4775],\n",
      "        [ 0.3907, -0.4550],\n",
      "        [-0.8850,  0.3767],\n",
      "        [-0.9175,  0.3804]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 85: 0.2972721457481384\n",
      "Output at epoch 86: tensor([[ 0.4502, -0.4991],\n",
      "        [ 0.4166, -0.4741],\n",
      "        [-0.8915,  0.3827],\n",
      "        [-0.9216,  0.3862]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 86: 0.2892313003540039\n",
      "Output at epoch 87: tensor([[ 0.4757, -0.5192],\n",
      "        [ 0.4414, -0.4927],\n",
      "        [-0.8984,  0.3889],\n",
      "        [-0.9277,  0.3934]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 87: 0.28157365322113037\n",
      "Output at epoch 88: tensor([[ 0.4980, -0.5370],\n",
      "        [ 0.4640, -0.5096],\n",
      "        [-0.9102,  0.3988],\n",
      "        [-0.9376,  0.4034]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 88: 0.2739555239677429\n",
      "Output at epoch 89: tensor([[ 0.5167, -0.5523],\n",
      "        [ 0.4835, -0.5246],\n",
      "        [-0.9274,  0.4128],\n",
      "        [-0.9522,  0.4168]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 89: 0.26635611057281494\n",
      "Output at epoch 90: tensor([[ 0.5320, -0.5651],\n",
      "        [ 0.5001, -0.5375],\n",
      "        [-0.9497,  0.4306],\n",
      "        [-0.9714,  0.4335]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 90: 0.2587878108024597\n",
      "Epoch 90, Loss: 0.2587878108024597\n",
      "Output at epoch 91: tensor([[ 0.5447, -0.5759],\n",
      "        [ 0.5145, -0.5489],\n",
      "        [-0.9760,  0.4515],\n",
      "        [-0.9941,  0.4529]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 91: 0.25129085779190063\n",
      "Output at epoch 92: tensor([[ 0.5560, -0.5858],\n",
      "        [ 0.5279, -0.5597],\n",
      "        [-1.0047,  0.4742],\n",
      "        [-1.0186,  0.4736]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 92: 0.24390913546085358\n",
      "Output at epoch 93: tensor([[ 0.5674, -0.5957],\n",
      "        [ 0.5419, -0.5708],\n",
      "        [-1.0337,  0.4975],\n",
      "        [-1.0428,  0.4942]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 93: 0.2366662621498108\n",
      "Output at epoch 94: tensor([[ 0.5803, -0.6065],\n",
      "        [ 0.5577, -0.5833],\n",
      "        [-1.0613,  0.5199],\n",
      "        [-1.0650,  0.5134]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 94: 0.22956019639968872\n",
      "Output at epoch 95: tensor([[ 0.5956, -0.6191],\n",
      "        [ 0.5761, -0.5977],\n",
      "        [-1.0853,  0.5399],\n",
      "        [-1.0839,  0.5304]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 95: 0.22262750566005707\n",
      "Output at epoch 96: tensor([[ 0.6193, -0.6381],\n",
      "        [ 0.5991, -0.6157],\n",
      "        [-1.0999,  0.5528],\n",
      "        [-1.0965,  0.5427]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 96: 0.21570956707000732\n",
      "Output at epoch 97: tensor([[ 0.6446, -0.6584],\n",
      "        [ 0.6240, -0.6350],\n",
      "        [-1.1118,  0.5639],\n",
      "        [-1.1069,  0.5533]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 97: 0.20897844433784485\n",
      "Output at epoch 98: tensor([[ 0.6708, -0.6792],\n",
      "        [ 0.6494, -0.6548],\n",
      "        [-1.1231,  0.5746],\n",
      "        [-1.1168,  0.5637]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 98: 0.20240160822868347\n",
      "Output at epoch 99: tensor([[ 0.6965, -0.6997],\n",
      "        [ 0.6741, -0.6741],\n",
      "        [-1.1353,  0.5860],\n",
      "        [-1.1279,  0.5749]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 99: 0.1959841251373291\n",
      "Accuracy: 1.0, Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Example DataFrame structures for job descriptions and resumes\n",
    "job_descriptions = pd.DataFrame({\n",
    "    'job_id': [1, 2],\n",
    "    'skills': [['python', 'ml'], ['java', 'spring']],\n",
    "    'job_title': ['data scientist', 'backend developer'],\n",
    "    'min_experience': [12, 24]\n",
    "})\n",
    "\n",
    "resumes = pd.DataFrame({\n",
    "    'job_title': ['data scientist', 'backend developer'],\n",
    "    'skills': [['python', 'data analysis'], ['java', 'spring boot']],\n",
    "    'experience': [24, 36]\n",
    "})\n",
    "resumes['candidate_id'] = range(1, len(resumes) + 1)\n",
    "\n",
    "# One-hot encoding skills\n",
    "all_skills = list(set(sum(job_descriptions['skills'].tolist() + resumes['skills'].tolist(), [])))\n",
    "mlb = MultiLabelBinarizer(classes=all_skills)\n",
    "job_skills_encoded = mlb.fit_transform(job_descriptions['skills'])\n",
    "resume_skills_encoded = mlb.fit_transform(resumes['skills'])\n",
    "\n",
    "job_skills_tensor = torch.tensor(job_skills_encoded, dtype=torch.float)\n",
    "resume_skills_tensor = torch.tensor(resume_skills_encoded, dtype=torch.float)\n",
    "\n",
    "# Function to create feature matrix from selected columns\n",
    "def create_feature_matrix(df, feature_columns):\n",
    "    features = []\n",
    "    for _, row in df.iterrows():\n",
    "        features.append(torch.tensor([row[col] for col in feature_columns], dtype=torch.float))\n",
    "    return torch.stack(features)\n",
    "\n",
    "# Create feature matrices for job descriptions and resumes\n",
    "job_exp_features = create_feature_matrix(job_descriptions, ['min_experience'])\n",
    "resume_exp_features = create_feature_matrix(resumes, ['experience'])\n",
    "\n",
    "# Ensure the dimensions of tensors match correctly for concatenation\n",
    "job_features = torch.cat([job_skills_tensor, job_exp_features], dim=1)\n",
    "resume_features = torch.cat([resume_skills_tensor, resume_exp_features], dim=1)\n",
    "\n",
    "x_one_hot = torch.cat([job_features, resume_features], dim=0)\n",
    "\n",
    "# Embedding skills using nn.Embedding\n",
    "skill_to_index = {skill: idx for idx, skill in enumerate(all_skills)}\n",
    "embedding_dim = 50\n",
    "embedding = nn.Embedding(len(all_skills), embedding_dim)\n",
    "\n",
    "# Function to get average embedding for a list of skills\n",
    "def get_skill_embedding(skills, embedding, skill_to_index):\n",
    "    skill_indices = [skill_to_index[skill] for skill in skills if skill in skill_to_index]\n",
    "    if not skill_indices:\n",
    "        return torch.zeros(embedding_dim)\n",
    "    skill_tensor = torch.tensor(skill_indices, dtype=torch.long)\n",
    "    skill_embeddings = embedding(skill_tensor)\n",
    "    return skill_embeddings.mean(dim=0)\n",
    "\n",
    "# Encode skills as embeddings\n",
    "job_skills_embedded = torch.stack([get_skill_embedding(skills, embedding, skill_to_index) for skills in job_descriptions['skills']])\n",
    "resume_skills_embedded = torch.stack([get_skill_embedding(skills, embedding, skill_to_index) for skills in resumes['skills']])\n",
    "\n",
    "# Ensure the dimensions of tensors match correctly for concatenation\n",
    "job_features_embedded = torch.cat([job_skills_embedded, job_exp_features], dim=1)\n",
    "resume_features_embedded = torch.cat([resume_skills_embedded, resume_exp_features], dim=1)\n",
    "\n",
    "x_embeddings = torch.cat([job_features_embedded, resume_features_embedded], dim=0)\n",
    "\n",
    "# Function to create edge index for bipartite graph\n",
    "def create_edge_index(job_descriptions, resumes):\n",
    "    edges = []\n",
    "    for i, job in job_descriptions.iterrows():\n",
    "        for j, resume in resumes.iterrows():\n",
    "            if set(job['skills']).intersection(set(resume['skills'])):\n",
    "                edges.append([i, j + len(job_descriptions)])  # Offset for bipartite graph\n",
    "    return torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "edge_index = create_edge_index(job_descriptions, resumes)\n",
    "\n",
    "# Create Data objects for GCN\n",
    "data_embeddings = Data(x=x_embeddings, edge_index=edge_index)\n",
    "\n",
    "# Define the GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "input_dim = x_embeddings.size(1)  # Number of input features (50 + 1 = 51)\n",
    "hidden_dim = 16  # Size of hidden layers\n",
    "output_dim = 2  # Size of the output layer\n",
    "\n",
    "model = GCN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Create realistic targets for binary classification\n",
    "num_jobs = len(job_descriptions)\n",
    "num_resumes = len(resumes)\n",
    "targets = torch.zeros(num_jobs + num_resumes, dtype=torch.long)\n",
    "targets[num_jobs:] = 1\n",
    "\n",
    "# Training loop with detailed debug information\n",
    "def train(data, model, criterion, optimizer, targets, epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        print(f'Output at epoch {epoch}: {out}')  # Debug: Print the model output\n",
    "        loss = criterion(out, targets)\n",
    "        print(f'Loss at epoch {epoch}: {loss}')  # Debug: Print the loss\n",
    "        loss.backward(retain_graph=True)  # Retain graph for debugging purposes\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "train(data_embeddings, model, criterion, optimizer, targets)\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(model, data, targets):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "        accuracy = accuracy_score(targets, pred)\n",
    "        precision = precision_score(targets, pred)\n",
    "        recall = recall_score(targets, pred)\n",
    "        f1 = f1_score(targets, pred)\n",
    "        print(f'Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}')\n",
    "\n",
    "evaluate(model, data_embeddings, targets)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
