{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import warnings\n",
    "import uuid\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch_geometric.nn import GCNConv\n",
    "from ast import literal_eval"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T23:44:08.646905Z",
     "start_time": "2024-05-24T23:44:08.640971Z"
    }
   },
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "source": [
    "nltk.download(['stopwords', 'wordnet'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T23:44:08.664248Z",
     "start_time": "2024-05-24T23:44:08.647416Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\idontwannawakeup\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\idontwannawakeup\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-24T23:44:08.669540Z",
     "start_time": "2024-05-24T23:44:08.664248Z"
    }
   },
   "source": [
    "# Example DataFrame structures for job descriptions and resumes\n",
    "# job_descriptions = pd.DataFrame({\n",
    "#     'job_id': [1, 2],\n",
    "#     'skills': [['python', 'ml'], ['java', 'spring']],\n",
    "#     'job_title': ['data scientist', 'backend developer'],\n",
    "#     'min_experience': [12, 24]\n",
    "# })\n",
    "#\n",
    "# resumes = pd.DataFrame({\n",
    "#     'job_title': ['data scientist', 'backend developer'],\n",
    "#     'skills': [['python', 'data analysis'], ['java', 'spring boot']],\n",
    "#     'experience': [24, 36]\n",
    "# })\n",
    "# resumes['candidate_id'] = range(1, len(resumes) + 1)"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T23:44:10.126090Z",
     "start_time": "2024-05-24T23:44:08.669540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# job_descriptions = pd.read_csv('./data/processed/job_descriptions_processed.csv', converters={'skills': literal_eval})\n",
    "# resumes = pd.read_csv('./data/processed/resume-dataset-processed.csv', converters={'skills': literal_eval})\n",
    "job_descriptions = pd.read_csv('./data/processed/job_descriptions_processed.csv')\n",
    "resumes = pd.read_csv('./data/processed/resume-dataset-processed.csv', converters={'skills': literal_eval})\n",
    "job_descriptions.head()\n",
    "resumes.head()\n",
    "print(\"Data is loaded\")\n",
    "\n",
    "job_descriptions = job_descriptions.head(1000)\n",
    "job_descriptions['skills'] = job_descriptions['skills'].apply(literal_eval)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is loaded\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T23:44:10.276349Z",
     "start_time": "2024-05-24T23:44:10.126090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# One-hot encoding skills\n",
    "all_skills = list(set(sum(job_descriptions['skills'].tolist() + resumes['skills'].tolist(), [])))\n",
    "mlb = MultiLabelBinarizer(classes=all_skills)\n",
    "job_skills_encoded = mlb.fit_transform(job_descriptions['skills'])\n",
    "resume_skills_encoded = mlb.fit_transform(resumes['skills'])\n",
    "\n",
    "job_skills_tensor = torch.tensor(job_skills_encoded, dtype=torch.float)\n",
    "resume_skills_tensor = torch.tensor(resume_skills_encoded, dtype=torch.float)\n",
    "\n",
    "# Function to create feature matrix from selected columns\n",
    "def create_feature_matrix(df, feature_columns):\n",
    "    features = []\n",
    "    for _, row in df.iterrows():\n",
    "        features.append(torch.tensor([row[col] for col in feature_columns], dtype=torch.float))\n",
    "    return torch.stack(features)\n",
    "\n",
    "# Create feature matrices for job descriptions and resumes\n",
    "job_exp_features = create_feature_matrix(job_descriptions, ['min_experience'])\n",
    "resume_exp_features = create_feature_matrix(resumes, ['experience'])\n",
    "\n",
    "# Ensure the dimensions of tensors match correctly for concatenation\n",
    "job_features = torch.cat([job_skills_tensor, job_exp_features], dim=1)\n",
    "resume_features = torch.cat([resume_skills_tensor, resume_exp_features], dim=1)\n",
    "\n",
    "x_one_hot = torch.cat([job_features, resume_features], dim=0)\n",
    "\n",
    "# Embedding skills using nn.Embedding\n",
    "skill_to_index = {skill: idx for idx, skill in enumerate(all_skills)}\n",
    "embedding_dim = 50\n",
    "embedding = nn.Embedding(len(all_skills), embedding_dim)\n",
    "\n",
    "# Function to get average embedding for a list of skills\n",
    "def get_skill_embedding(skills, embedding, skill_to_index):\n",
    "    if not skills:  # If the skills list is empty\n",
    "        return torch.zeros(embedding_dim)\n",
    "    skill_indices = [skill_to_index[skill] for skill in skills if skill in skill_to_index]\n",
    "    if not skill_indices:\n",
    "        return torch.zeros(embedding_dim)\n",
    "    skill_tensor = torch.tensor(skill_indices, dtype=torch.long)\n",
    "    skill_embeddings = embedding(skill_tensor)\n",
    "    return skill_embeddings.mean(dim=0)\n",
    "\n",
    "# Encode skills as embeddings\n",
    "job_skills_embedded = torch.stack([get_skill_embedding(skills, embedding, skill_to_index) for skills in job_descriptions['skills']])\n",
    "resume_skills_embedded = torch.stack([get_skill_embedding(skills, embedding, skill_to_index) for skills in resumes['skills']])\n",
    "\n",
    "# Ensure the dimensions of tensors match correctly for concatenation\n",
    "job_features_embedded = torch.cat([job_skills_embedded, job_exp_features], dim=1)\n",
    "resume_features_embedded = torch.cat([resume_skills_embedded, resume_exp_features], dim=1)\n",
    "\n",
    "x_embeddings = torch.cat([job_features_embedded, resume_features_embedded], dim=0)"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T23:44:25.436364Z",
     "start_time": "2024-05-24T23:44:10.276349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to create edge index for bipartite graph\n",
    "def create_edge_index(job_descriptions, resumes):\n",
    "    edges = []\n",
    "    num_jobs = len(job_descriptions)\n",
    "    num_resumes = len(resumes)\n",
    "\n",
    "    for i, job in job_descriptions.iterrows():\n",
    "        for j, resume in resumes.iterrows():\n",
    "            if set(job['skills']).intersection(set(resume['skills'])):\n",
    "                if i < num_jobs and (j + num_jobs) < (num_jobs + num_resumes):\n",
    "                    edges.append([i, j + num_jobs])  # Offset for bipartite graph\n",
    "\n",
    "    if not edges:  # Ensure there are edges\n",
    "        return torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    return torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "edge_index = create_edge_index(job_descriptions, resumes)\n",
    "\n",
    "# Create Data objects for GCN\n",
    "data_embeddings = Data(x=x_embeddings, edge_index=edge_index)"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T23:44:25.440763Z",
     "start_time": "2024-05-24T23:44:25.436364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T23:44:25.458197Z",
     "start_time": "2024-05-24T23:44:25.440763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_dim = x_embeddings.size(1)  # Number of input features (50 + 1 = 51)\n",
    "hidden_dim = 16  # Size of hidden layers\n",
    "output_dim = 2  # Size of the output layer\n",
    "\n",
    "model = GCN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Create realistic targets for binary classification\n",
    "num_jobs = len(job_descriptions)\n",
    "num_resumes = len(resumes)\n",
    "targets = torch.zeros(num_jobs + num_resumes, dtype=torch.long)\n",
    "targets[num_jobs:] = 1"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T23:44:31.649808Z",
     "start_time": "2024-05-24T23:44:25.458197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop with detailed debug information\n",
    "def train(data, model, criterion, optimizer, targets, epochs=100):\n",
    "    print(\"Train start\")\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        print(f'Output at epoch {epoch}: {out}')  # Debug: Print the model output\n",
    "        loss = criterion(out, targets)\n",
    "        print(f'Loss at epoch {epoch}: {loss}')  # Debug: Print the loss\n",
    "        loss.backward(retain_graph=True)  # Backward pass\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "    print(\"Train done\")\n",
    "\n",
    "train(data_embeddings, model, criterion, optimizer, targets)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train start\n",
      "Output at epoch 0: tensor([[ -0.8028,  -1.9630],\n",
      "        [ -0.5606,  -1.4222],\n",
      "        [ -0.1072,   0.6472],\n",
      "        ...,\n",
      "        [ -0.3958,  -3.2646],\n",
      "        [ -0.1667,   0.4853],\n",
      "        [ -4.1196, -10.8563]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 0: 2.507761001586914\n",
      "Epoch 0, Loss: 2.507761001586914\n",
      "Output at epoch 1: tensor([[-1.9773, -0.3470],\n",
      "        [-1.1136, -0.7303],\n",
      "        [-0.1406,  0.7823],\n",
      "        ...,\n",
      "        [-2.0282, -0.8590],\n",
      "        [-0.2523,  0.6624],\n",
      "        [-9.5281, -3.3557]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 1: 0.5744983553886414\n",
      "Epoch 1, Loss: 0.5744983553886414\n",
      "Output at epoch 2: tensor([[ -2.6845,   0.6221],\n",
      "        [ -1.4318,  -0.2815],\n",
      "        [ -0.1643,   0.8625],\n",
      "        ...,\n",
      "        [ -2.9917,   0.5603],\n",
      "        [ -0.3103,   0.7860],\n",
      "        [-12.7769,   1.1816]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 2: 0.8741853833198547\n",
      "Epoch 2, Loss: 0.8741853833198547\n",
      "Output at epoch 3: tensor([[-3.1046e+00,  1.1863e+00],\n",
      "        [-1.6243e+00, -1.0959e-02],\n",
      "        [-1.8011e-01,  9.0420e-01],\n",
      "        ...,\n",
      "        [-3.5561e+00,  1.3796e+00],\n",
      "        [-3.5081e-01,  8.8072e-01],\n",
      "        [-1.4740e+01,  3.9076e+00]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 3: 1.0847890377044678\n",
      "Epoch 3, Loss: 1.0847890377044678\n",
      "Output at epoch 4: tensor([[ -3.3256,   1.4677],\n",
      "        [ -1.7311,   0.1376],\n",
      "        [ -0.1891,   0.9208],\n",
      "        ...,\n",
      "        [ -3.8445,   1.7836],\n",
      "        [ -0.3797,   0.9562],\n",
      "        [-15.8191,   5.3620]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 4: 1.18999445438385\n",
      "Epoch 4, Loss: 1.18999445438385\n",
      "Output at epoch 5: tensor([[ -3.3981,   1.5381],\n",
      "        [ -1.7745,   0.1958],\n",
      "        [ -0.1931,   0.9188],\n",
      "        ...,\n",
      "        [ -3.9260,   1.8770],\n",
      "        [ -0.4001,   1.0175],\n",
      "        [-16.2412,   5.8735]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 5: 1.2101138830184937\n",
      "Epoch 5, Loss: 1.2101138830184937\n",
      "Output at epoch 6: tensor([[ -3.3556,   1.4457],\n",
      "        [ -1.7688,   0.1845],\n",
      "        [ -0.1935,   0.9027],\n",
      "        ...,\n",
      "        [ -3.8478,   1.7370],\n",
      "        [ -0.4137,   1.0674],\n",
      "        [-16.1537,   5.6595]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 6: 1.1640331745147705\n",
      "Epoch 6, Loss: 1.1640331745147705\n",
      "Output at epoch 7: tensor([[ -3.2222,   1.2256],\n",
      "        [ -1.7244,   0.1186],\n",
      "        [ -0.1912,   0.8760],\n",
      "        ...,\n",
      "        [ -3.6435,   1.4144],\n",
      "        [ -0.4219,   1.1076],\n",
      "        [-15.6630,   4.8743]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 7: 1.0676960945129395\n",
      "Epoch 7, Loss: 1.0676960945129395\n",
      "Output at epoch 8: tensor([[-3.0163e+00,  9.0531e-01],\n",
      "        [-1.6489e+00,  9.5886e-03],\n",
      "        [-1.8444e-01,  8.4332e-01],\n",
      "        ...,\n",
      "        [-3.3391e+00,  9.4845e-01],\n",
      "        [-4.2453e-01,  1.1387e+00],\n",
      "        [-1.4851e+01,  3.6376e+00]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 8: 0.9356116652488708\n",
      "Epoch 8, Loss: 0.9356116652488708\n",
      "Output at epoch 9: tensor([[ -2.7535,   0.5079],\n",
      "        [ -1.5491,  -0.1330],\n",
      "        [ -0.1713,   0.8098],\n",
      "        ...,\n",
      "        [ -2.9587,   0.3723],\n",
      "        [ -0.4220,   1.1613],\n",
      "        [-13.7861,   2.0515]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 9: 0.7830922603607178\n",
      "Epoch 9, Loss: 0.7830922603607178\n",
      "Output at epoch 10: tensor([[ -2.4487,   0.0551],\n",
      "        [ -1.4309,  -0.3002],\n",
      "        [ -0.1560,   0.7727],\n",
      "        ...,\n",
      "        [ -2.5177,  -0.2764],\n",
      "        [ -0.4133,   1.1745],\n",
      "        [-12.5322,   0.2090]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 10: 0.6295371055603027\n",
      "Epoch 10, Loss: 0.6295371055603027\n",
      "Output at epoch 11: tensor([[ -2.1184,  -0.4291],\n",
      "        [ -1.3012,  -0.4824],\n",
      "        [ -0.1394,   0.7339],\n",
      "        ...,\n",
      "        [ -2.0391,  -0.9649],\n",
      "        [ -0.4002,   1.1877],\n",
      "        [-11.1605,  -1.7875]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 11: 0.5044727921485901\n",
      "Epoch 11, Loss: 0.5044727921485901\n",
      "Output at epoch 12: tensor([[-1.7868, -0.9109],\n",
      "        [-1.1698, -0.6657],\n",
      "        [-0.1234,  0.6957],\n",
      "        ...,\n",
      "        [-1.5597, -1.6481],\n",
      "        [-0.3880,  1.2023],\n",
      "        [-9.7742, -3.7906]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 12: 0.46960529685020447\n",
      "Epoch 12, Loss: 0.46960529685020447\n",
      "Output at epoch 13: tensor([[-1.5262, -1.2948],\n",
      "        [-1.0667, -0.8107],\n",
      "        [-0.1117,  0.6645],\n",
      "        ...,\n",
      "        [-1.1815, -2.1847],\n",
      "        [-0.3879,  1.2316],\n",
      "        [-8.6842, -5.3864]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 13: 0.6082236170768738\n",
      "Epoch 13, Loss: 0.6082236170768738\n",
      "Output at epoch 14: tensor([[-1.4307, -1.4606],\n",
      "        [-1.0318, -0.8656],\n",
      "        [-0.1068,  0.6479],\n",
      "        ...,\n",
      "        [-1.0353, -2.3972],\n",
      "        [-0.4087,  1.2894],\n",
      "        [-8.3134, -6.0351]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 14: 0.7174605131149292\n",
      "Epoch 14, Loss: 0.7174605131149292\n",
      "Output at epoch 15: tensor([[-1.5311, -1.3691],\n",
      "        [-1.0800, -0.8107],\n",
      "        [-0.1095,  0.6489],\n",
      "        ...,\n",
      "        [-1.1671, -2.2406],\n",
      "        [-0.4501,  1.3751],\n",
      "        [-8.8109, -5.5391]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 15: 0.6154862642288208\n",
      "Epoch 15, Loss: 0.6154862642288208\n",
      "Output at epoch 16: tensor([[-1.7470, -1.1246],\n",
      "        [-1.1760, -0.6924],\n",
      "        [-0.1167,  0.6589],\n",
      "        ...,\n",
      "        [-1.4639, -1.8615],\n",
      "        [-0.5062,  1.4796],\n",
      "        [-9.8124, -4.3777]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 16: 0.4779892861843109\n",
      "Epoch 16, Loss: 0.4779892861843109\n",
      "Output at epoch 17: tensor([[ -1.9973,  -0.8318],\n",
      "        [ -1.2851,  -0.5562],\n",
      "        [ -0.1248,   0.6695],\n",
      "        ...,\n",
      "        [ -1.8114,  -1.4100],\n",
      "        [ -0.5696,   1.5914],\n",
      "        [-10.9555,  -3.0208]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 17: 0.4319515824317932\n",
      "Epoch 17, Loss: 0.4319515824317932\n",
      "Output at epoch 18: tensor([[ -2.2121,  -0.5809],\n",
      "        [ -1.3787,  -0.4390],\n",
      "        [ -0.1314,   0.6764],\n",
      "        ...,\n",
      "        [ -2.1105,  -1.0160],\n",
      "        [ -0.6218,   1.7148],\n",
      "        [-11.9399,  -1.8571]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 18: 0.4596537947654724\n",
      "Epoch 18, Loss: 0.4596537947654724\n",
      "Output at epoch 19: tensor([[ -2.3726,  -0.3967],\n",
      "        [ -1.4491,  -0.3509],\n",
      "        [ -0.1354,   0.6767],\n",
      "        ...,\n",
      "        [ -2.3316,  -0.7202],\n",
      "        [ -0.6653,   1.8287],\n",
      "        [-12.6844,  -0.9920]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 19: 0.49555402994155884\n",
      "Epoch 19, Loss: 0.49555402994155884\n",
      "Output at epoch 20: tensor([[ -2.4735,  -0.2863],\n",
      "        [ -1.4943,  -0.2946],\n",
      "        [ -0.1366,   0.6700],\n",
      "        ...,\n",
      "        [ -2.4683,  -0.5322],\n",
      "        [ -0.7014,   1.9298],\n",
      "        [-13.1666,  -0.4544]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 20: 0.5207371711730957\n",
      "Epoch 20, Loss: 0.5207371711730957\n",
      "Output at epoch 21: tensor([[ -2.5154,  -0.2493],\n",
      "        [ -1.5145,  -0.2697],\n",
      "        [ -0.1347,   0.6562],\n",
      "        ...,\n",
      "        [ -2.5225,  -0.4498],\n",
      "        [ -0.7301,   2.0176],\n",
      "        [-13.3897,  -0.2406]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 21: 0.5283550024032593\n",
      "Epoch 21, Loss: 0.5283550024032593\n",
      "Output at epoch 22: tensor([[ -2.5022,  -0.2808],\n",
      "        [ -1.5115,  -0.2742],\n",
      "        [ -0.1300,   0.6357],\n",
      "        ...,\n",
      "        [ -2.4989,  -0.4667],\n",
      "        [ -0.7520,   2.0930],\n",
      "        [-13.3710,  -0.3291]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 22: 0.5178136825561523\n",
      "Epoch 22, Loss: 0.5178136825561523\n",
      "Output at epoch 23: tensor([[ -2.4398,  -0.3734],\n",
      "        [ -1.4876,  -0.3049],\n",
      "        [ -0.1229,   0.6100],\n",
      "        ...,\n",
      "        [ -2.4062,  -0.5717],\n",
      "        [ -0.7685,   2.1575],\n",
      "        [-13.1362,  -0.6863]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 23: 0.4920516610145569\n",
      "Epoch 23, Loss: 0.4920516610145569\n",
      "Output at epoch 24: tensor([[ -2.3359,  -0.5171],\n",
      "        [ -1.4462,  -0.3577],\n",
      "        [ -0.1136,   0.5796],\n",
      "        ...,\n",
      "        [ -2.2554,  -0.7506],\n",
      "        [ -0.7801,   2.2119],\n",
      "        [-12.7188,  -1.2693]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 24: 0.4566642642021179\n",
      "Epoch 24, Loss: 0.4566642642021179\n",
      "Output at epoch 25: tensor([[ -2.2001,  -0.6996],\n",
      "        [ -1.3910,  -0.4275],\n",
      "        [ -0.1025,   0.5481],\n",
      "        ...,\n",
      "        [ -2.0601,  -0.9853],\n",
      "        [ -0.7883,   2.2575],\n",
      "        [-12.1605,  -2.0253]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 25: 0.41949698328971863\n",
      "Epoch 25, Loss: 0.41949698328971863\n",
      "Output at epoch 26: tensor([[ -2.0445,  -0.9056],\n",
      "        [ -1.3273,  -0.5079],\n",
      "        [ -0.0886,   0.5209],\n",
      "        ...,\n",
      "        [ -1.8378,  -1.2535],\n",
      "        [ -0.7973,   2.2889],\n",
      "        [-11.5133,  -2.8868]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 26: 0.39039182662963867\n",
      "Epoch 26, Loss: 0.39039182662963867\n",
      "Output at epoch 27: tensor([[ -1.8857,  -1.1144],\n",
      "        [ -1.2618,  -0.5904],\n",
      "        [ -0.0720,   0.4994],\n",
      "        ...,\n",
      "        [ -1.6119,  -1.5256],\n",
      "        [ -0.8079,   2.3153],\n",
      "        [-10.8492,  -3.7638]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 27: 0.3861943483352661\n",
      "Epoch 27, Loss: 0.3861943483352661\n",
      "Output at epoch 28: tensor([[ -1.7665,  -1.2727],\n",
      "        [ -1.2120,  -0.6532],\n",
      "        [ -0.0563,   0.4795],\n",
      "        ...,\n",
      "        [ -1.4420,  -1.7196],\n",
      "        [ -0.8240,   2.3448],\n",
      "        [-10.3534,  -4.4285]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 28: 0.4127684533596039\n",
      "Epoch 28, Loss: 0.4127684533596039\n",
      "Output at epoch 29: tensor([[ -1.7157,  -1.3456],\n",
      "        [ -1.1896,  -0.6821],\n",
      "        [ -0.0430,   0.4630],\n",
      "        ...,\n",
      "        [ -1.3655,  -1.7868],\n",
      "        [ -0.8487,   2.3871],\n",
      "        [-10.1517,  -4.7277]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 29: 0.4278052747249603\n",
      "Epoch 29, Loss: 0.4278052747249603\n",
      "Output at epoch 30: tensor([[ -1.7415,  -1.3236],\n",
      "        [ -1.1981,  -0.6728],\n",
      "        [ -0.0325,   0.4508],\n",
      "        ...,\n",
      "        [ -1.3993,  -1.7136],\n",
      "        [ -0.8832,   2.4447],\n",
      "        [-10.2807,  -4.6183]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 30: 0.41087806224823\n",
      "Epoch 30, Loss: 0.41087806224823\n",
      "Output at epoch 31: tensor([[ -1.8284,  -1.2260],\n",
      "        [ -1.2311,  -0.6333],\n",
      "        [ -0.0241,   0.4416],\n",
      "        ...,\n",
      "        [ -1.5215,  -1.5287],\n",
      "        [ -0.9260,   2.5140],\n",
      "        [-10.6724,  -4.1841]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 31: 0.3775649964809418\n",
      "Epoch 31, Loss: 0.3775649964809418\n",
      "Output at epoch 32: tensor([[ -1.9459,  -1.0896],\n",
      "        [ -1.2762,  -0.5787],\n",
      "        [ -0.0163,   0.4332],\n",
      "        ...,\n",
      "        [ -1.6884,  -1.2872],\n",
      "        [ -0.9729,   2.5873],\n",
      "        [-11.1945,  -3.5861]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 32: 0.35953330993652344\n",
      "Epoch 32, Loss: 0.35953330993652344\n",
      "Output at epoch 33: tensor([[-2.0479e+00, -9.7129e-01],\n",
      "        [-1.3146e+00, -5.3216e-01],\n",
      "        [-7.3997e-03,  4.2335e-01],\n",
      "        ...,\n",
      "        [-1.8337e+00, -1.0773e+00],\n",
      "        [-1.0187e+00,  2.6560e+00],\n",
      "        [-1.1648e+01, -3.0679e+00]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 33: 0.36425721645355225\n",
      "Epoch 33, Loss: 0.36425721645355225\n",
      "Output at epoch 34: tensor([[-2.1190e+00, -8.8999e-01],\n",
      "        [-1.3401e+00, -5.0127e-01],\n",
      "        [ 3.1185e-03,  4.1112e-01],\n",
      "        ...,\n",
      "        [-1.9356e+00, -9.2170e-01],\n",
      "        [-1.0612e+00,  2.7176e+00],\n",
      "        [-1.1966e+01, -2.7114e+00]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 34: 0.3717830777168274\n",
      "Epoch 34, Loss: 0.3717830777168274\n",
      "Output at epoch 35: tensor([[ -2.1543,  -0.8519],\n",
      "        [ -1.3507,  -0.4886],\n",
      "        [  0.0155,   0.3962],\n",
      "        ...,\n",
      "        [ -1.9869,  -0.8286],\n",
      "        [ -1.0991,   2.7704],\n",
      "        [-12.1273,  -2.5436]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 35: 0.37547171115875244\n",
      "Epoch 35, Loss: 0.37547171115875244\n",
      "Output at epoch 36: tensor([[ -2.1535,  -0.8575],\n",
      "        [ -1.3462,  -0.4943],\n",
      "        [  0.0299,   0.3786],\n",
      "        ...,\n",
      "        [ -1.9868,  -0.7992],\n",
      "        [ -1.1314,   2.8140],\n",
      "        [-12.1305,  -2.5667]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 36: 0.37282243371009827\n",
      "Epoch 36, Loss: 0.37282243371009827\n",
      "Output at epoch 37: tensor([[ -2.1192,  -0.9035],\n",
      "        [ -1.3277,  -0.5171],\n",
      "        [  0.0461,   0.3598],\n",
      "        ...,\n",
      "        [ -1.9391,  -0.8289],\n",
      "        [ -1.1555,   2.8472],\n",
      "        [-11.9876,  -2.7662]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 37: 0.3641164302825928\n",
      "Epoch 37, Loss: 0.3641164302825928\n",
      "Output at epoch 38: tensor([[ -2.0567,  -0.9834],\n",
      "        [ -1.2974,  -0.5542],\n",
      "        [  0.0638,   0.3384],\n",
      "        ...,\n",
      "        [ -1.8514,  -0.9085],\n",
      "        [ -1.1716,   2.8651],\n",
      "        [-11.7213,  -3.1140]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 38: 0.3516335189342499\n",
      "Epoch 38, Loss: 0.3516335189342499\n",
      "Output at epoch 39: tensor([[ -1.9736,  -1.0879],\n",
      "        [ -1.2585,  -0.6016],\n",
      "        [  0.0826,   0.3148],\n",
      "        ...,\n",
      "        [ -1.7346,  -1.0239],\n",
      "        [ -1.1847,   2.8772],\n",
      "        [-11.3645,  -3.5680]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 39: 0.339120477437973\n",
      "Epoch 39, Loss: 0.339120477437973\n",
      "Output at epoch 40: tensor([[ -1.8808,  -1.2038],\n",
      "        [ -1.2155,  -0.6541],\n",
      "        [  0.1019,   0.2900],\n",
      "        ...,\n",
      "        [ -1.6041,  -1.1557],\n",
      "        [ -1.1970,   2.8864],\n",
      "        [-10.9643,  -4.0718]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 40: 0.33139556646347046\n",
      "Epoch 40, Loss: 0.33139556646347046\n",
      "Output at epoch 41: tensor([[ -1.7915,  -1.3058],\n",
      "        [ -1.1753,  -0.7031],\n",
      "        [  0.1208,   0.2654],\n",
      "        ...,\n",
      "        [ -1.4845,  -1.2735],\n",
      "        [ -1.2124,   2.8977],\n",
      "        [-10.5955,  -4.5355]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 41: 0.33490249514579773\n",
      "Epoch 41, Loss: 0.33490249514579773\n",
      "Output at epoch 42: tensor([[ -1.7439,  -1.3585],\n",
      "        [ -1.1516,  -0.7319],\n",
      "        [  0.1383,   0.2430],\n",
      "        ...,\n",
      "        [ -1.4232,  -1.3186],\n",
      "        [ -1.2356,   2.9170],\n",
      "        [-10.4042,  -4.7823]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 42: 0.3405071198940277\n",
      "Epoch 42, Loss: 0.3405071198940277\n",
      "Output at epoch 43: tensor([[ -1.7522,  -1.3508],\n",
      "        [ -1.1494,  -0.7346],\n",
      "        [  0.1540,   0.2235],\n",
      "        ...,\n",
      "        [ -1.4378,  -1.2714],\n",
      "        [ -1.2686,   2.9471],\n",
      "        [-10.4423,  -4.7506]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 43: 0.3338750898838043\n",
      "Epoch 43, Loss: 0.3338750898838043\n",
      "Output at epoch 44: tensor([[ -1.8061,  -1.2938],\n",
      "        [ -1.1646,  -0.7160],\n",
      "        [  0.1682,   0.2063],\n",
      "        ...,\n",
      "        [ -1.5149,  -1.1493],\n",
      "        [ -1.3086,   2.9851],\n",
      "        [-10.6676,  -4.4909]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 44: 0.3214568793773651\n",
      "Epoch 44, Loss: 0.3214568793773651\n",
      "Output at epoch 45: tensor([[ -1.8721,  -1.2237],\n",
      "        [ -1.1844,  -0.6918],\n",
      "        [  0.1819,   0.1898],\n",
      "        ...,\n",
      "        [ -1.6084,  -1.0055],\n",
      "        [ -1.3391,   3.0172],\n",
      "        [-10.9424,  -4.1693]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 45: 0.3171986937522888\n",
      "Epoch 45, Loss: 0.3171986937522888\n",
      "Output at epoch 46: tensor([[ -1.9239,  -1.1639],\n",
      "        [ -1.1993,  -0.6734],\n",
      "        [  0.1958,   0.1726],\n",
      "        ...,\n",
      "        [ -1.6860,  -0.8809],\n",
      "        [ -1.3660,   3.0452],\n",
      "        [-11.1670,  -3.9065]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 46: 0.31748640537261963\n",
      "Epoch 46, Loss: 0.31748640537261963\n",
      "Output at epoch 47: tensor([[ -1.9546,  -1.1277],\n",
      "        [ -1.2059,  -0.6651],\n",
      "        [  0.2103,   0.1539],\n",
      "        ...,\n",
      "        [ -1.7350,  -0.7920],\n",
      "        [ -1.3905,   3.0672],\n",
      "        [-11.3029,  -3.7495]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 47: 0.31802627444267273\n",
      "Epoch 47, Loss: 0.31802627444267273\n",
      "Output at epoch 48: tensor([[ -1.9617,  -1.1199],\n",
      "        [ -1.2027,  -0.6685],\n",
      "        [  0.2255,   0.1335],\n",
      "        ...,\n",
      "        [ -1.7506,  -0.7445],\n",
      "        [ -1.4115,   3.0842],\n",
      "        [-11.3357,  -3.7156]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 48: 0.3165924549102783\n",
      "Epoch 48, Loss: 0.3165924549102783\n",
      "Output at epoch 49: tensor([[ -1.9458,  -1.1397],\n",
      "        [ -1.1901,  -0.6833],\n",
      "        [  0.2413,   0.1115],\n",
      "        ...,\n",
      "        [ -1.7334,  -0.7379],\n",
      "        [ -1.4287,   3.0961],\n",
      "        [-11.2681,  -3.8021]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 49: 0.3126789629459381\n",
      "Epoch 49, Loss: 0.3126789629459381\n",
      "Output at epoch 50: tensor([[ -1.9103,  -1.1831],\n",
      "        [ -1.1695,  -0.7078],\n",
      "        [  0.2574,   0.0883],\n",
      "        ...,\n",
      "        [ -1.6884,  -0.7658],\n",
      "        [ -1.4428,   3.1034],\n",
      "        [-11.1155,  -3.9904]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 50: 0.30714118480682373\n",
      "Epoch 50, Loss: 0.30714118480682373\n",
      "Output at epoch 51: tensor([[ -1.8606,  -1.2413],\n",
      "        [ -1.1434,  -0.7389],\n",
      "        [  0.2736,   0.0643],\n",
      "        ...,\n",
      "        [ -1.6245,  -0.8172],\n",
      "        [ -1.4545,   3.1074],\n",
      "        [-10.9048,  -4.2477]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 51: 0.30170461535453796\n",
      "Epoch 51, Loss: 0.30170461535453796\n",
      "Output at epoch 52: tensor([[ -1.8044,  -1.3026],\n",
      "        [ -1.1154,  -0.7722],\n",
      "        [  0.2895,   0.0412],\n",
      "        ...,\n",
      "        [ -1.5539,  -0.8757],\n",
      "        [ -1.4656,   3.1082],\n",
      "        [-10.6745,  -4.5272]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 52: 0.2981860041618347\n",
      "Epoch 52, Loss: 0.2981860041618347\n",
      "Output at epoch 53: tensor([[ -1.7549,  -1.3565],\n",
      "        [ -1.0901,  -0.8023],\n",
      "        [  0.3045,   0.0207],\n",
      "        ...,\n",
      "        [ -1.4930,  -0.9217],\n",
      "        [ -1.4771,   3.1101],\n",
      "        [-10.4741,  -4.7698]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 53: 0.29723116755485535\n",
      "Epoch 53, Loss: 0.29723116755485535\n",
      "Output at epoch 54: tensor([[-1.7253e+00, -1.3889e+00],\n",
      "        [-1.0727e+00, -8.2285e-01],\n",
      "        [ 3.1840e-01,  1.9584e-03],\n",
      "        ...,\n",
      "        [-1.4603e+00, -9.3362e-01],\n",
      "        [-1.4906e+00,  3.1153e+00],\n",
      "        [-1.0359e+01, -4.9093e+00]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 54: 0.2968251705169678\n",
      "Epoch 54, Loss: 0.2968251705169678\n",
      "Output at epoch 55: tensor([[ -1.7247,  -1.3900],\n",
      "        [ -1.0666,  -0.8297],\n",
      "        [  0.3309,  -0.0149],\n",
      "        ...,\n",
      "        [ -1.4683,  -0.8969],\n",
      "        [ -1.5069,   3.1251],\n",
      "        [-10.3661,  -4.9006]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 55: 0.29362648725509644\n",
      "Epoch 55, Loss: 0.29362648725509644\n",
      "Output at epoch 56: tensor([[ -1.7478,  -1.3656],\n",
      "        [ -1.0698,  -0.8252],\n",
      "        [  0.3424,  -0.0299],\n",
      "        ...,\n",
      "        [ -1.5097,  -0.8200],\n",
      "        [ -1.5255,   3.1393],\n",
      "        [-10.4742,  -4.7702]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 56: 0.2887405753135681\n",
      "Epoch 56, Loss: 0.2887405753135681\n",
      "Output at epoch 57: tensor([[ -1.7808,  -1.3302],\n",
      "        [ -1.0771,  -0.8158],\n",
      "        [  0.3531,  -0.0439],\n",
      "        ...,\n",
      "        [ -1.5643,  -0.7328],\n",
      "        [ -1.5450,   3.1560],\n",
      "        [-10.6259,  -4.5865]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 57: 0.28498145937919617\n",
      "Epoch 57, Loss: 0.28498145937919617\n",
      "Output at epoch 58: tensor([[ -1.8122,  -1.2964],\n",
      "        [ -1.0838,  -0.8070],\n",
      "        [  0.3636,  -0.0573],\n",
      "        ...,\n",
      "        [ -1.6172,  -0.6482],\n",
      "        [ -1.5553,   3.1670],\n",
      "        [-10.7726,  -4.4083]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 58: 0.28271418809890747\n",
      "Epoch 58, Loss: 0.28271418809890747\n",
      "Output at epoch 59: tensor([[ -1.8343,  -1.2727],\n",
      "        [ -1.0869,  -0.8025],\n",
      "        [  0.3743,  -0.0709],\n",
      "        ...,\n",
      "        [ -1.6575,  -0.5801],\n",
      "        [ -1.5648,   3.1754],\n",
      "        [-10.8807,  -4.2759]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 59: 0.28110048174858093\n",
      "Epoch 59, Loss: 0.28110048174858093\n",
      "Output at epoch 60: tensor([[ -1.8427,  -1.2637],\n",
      "        [ -1.0848,  -0.8043],\n",
      "        [  0.3855,  -0.0849],\n",
      "        ...,\n",
      "        [ -1.6773,  -0.5374],\n",
      "        [ -1.5729,   3.1810],\n",
      "        [-10.9324,  -4.2111]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 60: 0.2790549695491791\n",
      "Epoch 60, Loss: 0.2790549695491791\n",
      "Output at epoch 61: tensor([[ -1.8367,  -1.2701],\n",
      "        [ -1.0770,  -0.8127],\n",
      "        [  0.3971,  -0.0994],\n",
      "        ...,\n",
      "        [ -1.6775,  -0.5206],\n",
      "        [ -1.5781,   3.1846],\n",
      "        [-10.9235,  -4.2213]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 61: 0.27621254324913025\n",
      "Epoch 61, Loss: 0.27621254324913025\n",
      "Output at epoch 62: tensor([[ -1.8185,  -1.2898],\n",
      "        [ -1.0646,  -0.8269],\n",
      "        [  0.4093,  -0.1145],\n",
      "        ...,\n",
      "        [ -1.6616,  -0.5251],\n",
      "        [ -1.5801,   3.1861],\n",
      "        [-10.8635,  -4.2934]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 62: 0.2730119824409485\n",
      "Epoch 62, Loss: 0.2730119824409485\n",
      "Output at epoch 63: tensor([[ -1.7925,  -1.3178],\n",
      "        [ -1.0492,  -0.8445],\n",
      "        [  0.4219,  -0.1299],\n",
      "        ...,\n",
      "        [ -1.6362,  -0.5422],\n",
      "        [ -1.5803,   3.1867],\n",
      "        [-10.7715,  -4.4045]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 63: 0.26997166872024536\n",
      "Epoch 63, Loss: 0.26997166872024536\n",
      "Output at epoch 64: tensor([[ -1.7650,  -1.3474],\n",
      "        [ -1.0332,  -0.8628],\n",
      "        [  0.4347,  -0.1453],\n",
      "        ...,\n",
      "        [ -1.6090,  -0.5605],\n",
      "        [ -1.5802,   3.1882],\n",
      "        [-10.6733,  -4.5253]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 64: 0.2677438259124756\n",
      "Epoch 64, Loss: 0.2677438259124756\n",
      "Output at epoch 65: tensor([[ -1.7427,  -1.3714],\n",
      "        [ -1.0194,  -0.8786],\n",
      "        [  0.4472,  -0.1603],\n",
      "        ...,\n",
      "        [ -1.5893,  -0.5676],\n",
      "        [ -1.5847,   3.1954],\n",
      "        [-10.5992,  -4.6145]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 65: 0.2659672796726227\n",
      "Epoch 65, Loss: 0.2659672796726227\n",
      "Output at epoch 66: tensor([[ -1.7303,  -1.3848],\n",
      "        [ -1.0095,  -0.8896],\n",
      "        [  0.4592,  -0.1745],\n",
      "        ...,\n",
      "        [ -1.5851,  -0.5532],\n",
      "        [ -1.5952,   3.2097],\n",
      "        [-10.5699,  -4.6467]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 66: 0.26379257440567017\n",
      "Epoch 66, Loss: 0.26379257440567017\n",
      "Output at epoch 67: tensor([[ -1.7288,  -1.3863],\n",
      "        [ -1.0040,  -0.8953],\n",
      "        [  0.4707,  -0.1879],\n",
      "        ...,\n",
      "        [ -1.5982,  -0.5156],\n",
      "        [ -1.6101,   3.2297],\n",
      "        [-10.5892,  -4.6173]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 67: 0.2609611749649048\n",
      "Epoch 67, Loss: 0.2609611749649048\n",
      "Output at epoch 68: tensor([[ -1.7352,  -1.3794],\n",
      "        [ -1.0018,  -0.8972],\n",
      "        [  0.4819,  -0.2007],\n",
      "        ...,\n",
      "        [ -1.6225,  -0.4663],\n",
      "        [ -1.6283,   3.2538],\n",
      "        [-10.6436,  -4.5444]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 68: 0.2580980062484741\n",
      "Epoch 68, Loss: 0.2580980062484741\n",
      "Output at epoch 69: tensor([[ -1.7443,  -1.3696],\n",
      "        [ -1.0007,  -0.8976],\n",
      "        [  0.4928,  -0.2130],\n",
      "        ...,\n",
      "        [ -1.6509,  -0.4129],\n",
      "        [ -1.6476,   3.2797],\n",
      "        [-10.7100,  -4.4568]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 69: 0.25575992465019226\n",
      "Epoch 69, Loss: 0.25575992465019226\n",
      "Output at epoch 70: tensor([[ -1.7509,  -1.3626],\n",
      "        [ -0.9987,  -0.8991],\n",
      "        [  0.5014,  -0.2250],\n",
      "        ...,\n",
      "        [ -1.6760,  -0.3648],\n",
      "        [ -1.6659,   3.3047],\n",
      "        [-10.7657,  -4.3829]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 70: 0.2538689374923706\n",
      "Epoch 70, Loss: 0.2538689374923706\n",
      "Output at epoch 71: tensor([[ -1.7514,  -1.3622],\n",
      "        [ -0.9944,  -0.9032],\n",
      "        [  0.5086,  -0.2369],\n",
      "        ...,\n",
      "        [ -1.6921,  -0.3292],\n",
      "        [ -1.6819,   3.3274],\n",
      "        [-10.7950,  -4.3419]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 71: 0.2520539164543152\n",
      "Epoch 71, Loss: 0.2520539164543152\n",
      "Output at epoch 72: tensor([[ -1.7443,  -1.3701],\n",
      "        [ -0.9873,  -0.9106],\n",
      "        [  0.5157,  -0.2488],\n",
      "        ...,\n",
      "        [ -1.6939,  -0.3122],\n",
      "        [ -1.6948,   3.3449],\n",
      "        [-10.7916,  -4.3403]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 72: 0.25002744793891907\n",
      "Epoch 72, Loss: 0.25002744793891907\n",
      "Output at epoch 73: tensor([[ -1.7301,  -1.3855],\n",
      "        [ -0.9775,  -0.9211],\n",
      "        [  0.5227,  -0.2606],\n",
      "        ...,\n",
      "        [ -1.6852,  -0.3103],\n",
      "        [ -1.7041,   3.3568],\n",
      "        [-10.7581,  -4.3749]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 73: 0.2477950155735016\n",
      "Epoch 73, Loss: 0.2477950155735016\n",
      "Output at epoch 74: tensor([[ -1.7114,  -1.4059],\n",
      "        [ -0.9661,  -0.9335],\n",
      "        [  0.5298,  -0.2725],\n",
      "        ...,\n",
      "        [ -1.6723,  -0.3168],\n",
      "        [ -1.7118,   3.3671],\n",
      "        [-10.7055,  -4.4327]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 74: 0.24553056061267853\n",
      "Epoch 74, Loss: 0.24553056061267853\n",
      "Output at epoch 75: tensor([[ -1.6918,  -1.4273],\n",
      "        [ -0.9544,  -0.9461],\n",
      "        [  0.5368,  -0.2827],\n",
      "        ...,\n",
      "        [ -1.6607,  -0.3240],\n",
      "        [ -1.7187,   3.3757],\n",
      "        [-10.6491,  -4.4963]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 75: 0.24345621466636658\n",
      "Epoch 75, Loss: 0.24345621466636658\n",
      "Output at epoch 76: tensor([[ -1.6753,  -1.4453],\n",
      "        [ -0.9441,  -0.9570],\n",
      "        [  0.5438,  -0.2912],\n",
      "        ...,\n",
      "        [ -1.6527,  -0.3305],\n",
      "        [ -1.7246,   3.3828],\n",
      "        [-10.6048,  -4.5466]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 76: 0.241603821516037\n",
      "Epoch 76, Loss: 0.241603821516037\n",
      "Output at epoch 77: tensor([[ -1.6650,  -1.4567],\n",
      "        [ -0.9364,  -0.9648],\n",
      "        [  0.5508,  -0.2995],\n",
      "        ...,\n",
      "        [ -1.6512,  -0.3270],\n",
      "        [ -1.7318,   3.3910],\n",
      "        [-10.5874,  -4.5643]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 77: 0.23983097076416016\n",
      "Epoch 77, Loss: 0.23983097076416016\n",
      "Output at epoch 78: tensor([[ -1.6622,  -1.4600],\n",
      "        [ -0.9317,  -0.9688],\n",
      "        [  0.5576,  -0.3075],\n",
      "        ...,\n",
      "        [ -1.6625,  -0.3042],\n",
      "        [ -1.7409,   3.4004],\n",
      "        [-10.6029,  -4.5404]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 78: 0.2378672957420349\n",
      "Epoch 78, Loss: 0.2378672957420349\n",
      "Output at epoch 79: tensor([[ -1.6655,  -1.4568],\n",
      "        [ -0.9295,  -0.9698],\n",
      "        [  0.5642,  -0.3153],\n",
      "        ...,\n",
      "        [ -1.6843,  -0.2656],\n",
      "        [ -1.7509,   3.4103],\n",
      "        [-10.6451,  -4.4829]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 79: 0.2357565313577652\n",
      "Epoch 79, Loss: 0.2357565313577652\n",
      "Output at epoch 80: tensor([[ -1.6710,  -1.4511],\n",
      "        [ -0.9284,  -0.9695],\n",
      "        [  0.5707,  -0.3230],\n",
      "        ...,\n",
      "        [ -1.7105,  -0.2202],\n",
      "        [ -1.7604,   3.4194],\n",
      "        [-10.6973,  -4.4123]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 80: 0.2338167428970337\n",
      "Epoch 80, Loss: 0.2338167428970337\n",
      "Output at epoch 81: tensor([[ -1.6748,  -1.4474],\n",
      "        [ -0.9266,  -0.9699],\n",
      "        [  0.5772,  -0.3307],\n",
      "        ...,\n",
      "        [ -1.7341,  -0.1787],\n",
      "        [ -1.7672,   3.4252],\n",
      "        [-10.7418,  -4.3513]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 81: 0.23208266496658325\n",
      "Epoch 81, Loss: 0.23208266496658325\n",
      "Output at epoch 82: tensor([[ -1.6739,  -1.4488],\n",
      "        [ -0.9232,  -0.9723],\n",
      "        [  0.5839,  -0.3385],\n",
      "        ...,\n",
      "        [ -1.7500,  -0.1488],\n",
      "        [ -1.7713,   3.4273],\n",
      "        [-10.7650,  -4.3167]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 82: 0.23038972914218903\n",
      "Epoch 82, Loss: 0.23038972914218903\n",
      "Output at epoch 83: tensor([[ -1.6670,  -1.4564],\n",
      "        [ -0.9175,  -0.9772],\n",
      "        [  0.5909,  -0.3467],\n",
      "        ...,\n",
      "        [ -1.7555,  -0.1341],\n",
      "        [ -1.7724,   3.4272],\n",
      "        [-10.7614,  -4.3159]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 83: 0.22858214378356934\n",
      "Epoch 83, Loss: 0.22858214378356934\n",
      "Output at epoch 84: tensor([[ -1.6552,  -1.4695],\n",
      "        [ -0.9099,  -0.9843],\n",
      "        [  0.5981,  -0.3552],\n",
      "        ...,\n",
      "        [ -1.7487,  -0.1366],\n",
      "        [ -1.7705,   3.4249],\n",
      "        [-10.7327,  -4.3510]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 84: 0.22664113342761993\n",
      "Epoch 84, Loss: 0.22664113342761993\n",
      "Output at epoch 85: tensor([[ -1.6411,  -1.4850],\n",
      "        [ -0.9015,  -0.9923],\n",
      "        [  0.6051,  -0.3635],\n",
      "        ...,\n",
      "        [ -1.7383,  -0.1462],\n",
      "        [ -1.7662,   3.4209],\n",
      "        [-10.6905,  -4.4083]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 85: 0.22482450306415558\n",
      "Epoch 85, Loss: 0.22482450306415558\n",
      "Output at epoch 86: tensor([[ -1.6288,  -1.4986],\n",
      "        [ -0.8940,  -0.9993],\n",
      "        [  0.6092,  -0.3686],\n",
      "        ...,\n",
      "        [ -1.7333,  -0.1497],\n",
      "        [ -1.7622,   3.4175],\n",
      "        [-10.6552,  -4.4588]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 86: 0.22325100004673004\n",
      "Epoch 86, Loss: 0.22325100004673004\n",
      "Output at epoch 87: tensor([[ -1.6209,  -1.5069],\n",
      "        [ -0.8884,  -1.0038],\n",
      "        [  0.6133,  -0.3737],\n",
      "        ...,\n",
      "        [ -1.7386,  -0.1381],\n",
      "        [ -1.7573,   3.4125],\n",
      "        [-10.6475,  -4.4639]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 87: 0.22155287861824036\n",
      "Epoch 87, Loss: 0.22155287861824036\n",
      "Output at epoch 88: tensor([[ -1.6176,  -1.5096],\n",
      "        [ -0.8849,  -1.0058],\n",
      "        [  0.6174,  -0.3787],\n",
      "        ...,\n",
      "        [ -1.7537,  -0.1127],\n",
      "        [ -1.7521,   3.4060],\n",
      "        [-10.6676,  -4.4246]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 88: 0.2197561264038086\n",
      "Epoch 88, Loss: 0.2197561264038086\n",
      "Output at epoch 89: tensor([[ -1.6167,  -1.5093],\n",
      "        [ -0.8825,  -1.0064],\n",
      "        [  0.6216,  -0.3835],\n",
      "        ...,\n",
      "        [ -1.7698,  -0.0843],\n",
      "        [ -1.7467,   3.4005],\n",
      "        [-10.7014,  -4.3651]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 89: 0.218048095703125\n",
      "Epoch 89, Loss: 0.218048095703125\n",
      "Output at epoch 90: tensor([[ -1.6155,  -1.5096],\n",
      "        [ -0.8800,  -1.0072],\n",
      "        [  0.6280,  -0.3872],\n",
      "        ...,\n",
      "        [ -1.7837,  -0.0601],\n",
      "        [ -1.7402,   3.3946],\n",
      "        [-10.7303,  -4.3165]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 90: 0.21649818122386932\n",
      "Epoch 90, Loss: 0.21649818122386932\n",
      "Output at epoch 91: tensor([[ -1.6118,  -1.5129],\n",
      "        [ -0.8765,  -1.0092],\n",
      "        [  0.6345,  -0.3908],\n",
      "        ...,\n",
      "        [ -1.7911,  -0.0475],\n",
      "        [ -1.7321,   3.3879],\n",
      "        [-10.7425,  -4.2963]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 91: 0.21490360796451569\n",
      "Epoch 91, Loss: 0.21490360796451569\n",
      "Output at epoch 92: tensor([[ -1.6055,  -1.5193],\n",
      "        [ -0.8718,  -1.0126],\n",
      "        [  0.6409,  -0.3945],\n",
      "        ...,\n",
      "        [ -1.7856,  -0.0626],\n",
      "        [ -1.7245,   3.3819],\n",
      "        [-10.7342,  -4.3143]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 92: 0.21322926878929138\n",
      "Epoch 92, Loss: 0.21322926878929138\n",
      "Output at epoch 93: tensor([[ -1.5981,  -1.5272],\n",
      "        [ -0.8667,  -1.0166],\n",
      "        [  0.6474,  -0.3981],\n",
      "        ...,\n",
      "        [ -1.7731,  -0.0931],\n",
      "        [ -1.7159,   3.3746],\n",
      "        [-10.7075,  -4.3724]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 93: 0.21166490018367767\n",
      "Epoch 93, Loss: 0.21166490018367767\n",
      "Output at epoch 94: tensor([[ -1.5917,  -1.5340],\n",
      "        [ -0.8619,  -1.0201],\n",
      "        [  0.6538,  -0.4017],\n",
      "        ...,\n",
      "        [ -1.7703,  -0.0988],\n",
      "        [ -1.7069,   3.3662],\n",
      "        [-10.6958,  -4.3964]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 94: 0.21023373305797577\n",
      "Epoch 94, Loss: 0.21023373305797577\n",
      "Output at epoch 95: tensor([[ -1.5869,  -1.5389],\n",
      "        [ -0.8577,  -1.0229],\n",
      "        [  0.6601,  -0.4048],\n",
      "        ...,\n",
      "        [ -1.7794,  -0.0763],\n",
      "        [ -1.6982,   3.3575],\n",
      "        [-10.7101,  -4.3624]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 95: 0.20867814123630524\n",
      "Epoch 95, Loss: 0.20867814123630524\n",
      "Output at epoch 96: tensor([[ -1.5822,  -1.5438],\n",
      "        [ -0.8535,  -1.0259],\n",
      "        [  0.6668,  -0.4071],\n",
      "        ...,\n",
      "        [ -1.7947,  -0.0376],\n",
      "        [ -1.6895,   3.3481],\n",
      "        [-10.7325,  -4.3081]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 96: 0.20719477534294128\n",
      "Epoch 96, Loss: 0.20719477534294128\n",
      "Output at epoch 97: tensor([[ -1.5754,  -1.5512],\n",
      "        [ -0.8482,  -1.0301],\n",
      "        [  0.6743,  -0.4123],\n",
      "        ...,\n",
      "        [ -1.7977,  -0.0255],\n",
      "        [ -1.6821,   3.3389],\n",
      "        [-10.7284,  -4.3103]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 97: 0.20576080679893494\n",
      "Epoch 97, Loss: 0.20576080679893494\n",
      "Output at epoch 98: tensor([[ -1.5668,  -1.5608],\n",
      "        [ -0.8420,  -1.0355],\n",
      "        [  0.6818,  -0.4177],\n",
      "        ...,\n",
      "        [ -1.7877,  -0.0417],\n",
      "        [ -1.6735,   3.3285],\n",
      "        [-10.6976,  -4.3651]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 98: 0.20432673394680023\n",
      "Epoch 98, Loss: 0.20432673394680023\n",
      "Output at epoch 99: tensor([[ -1.5582,  -1.5705],\n",
      "        [ -0.8356,  -1.0412],\n",
      "        [  0.6893,  -0.4231],\n",
      "        ...,\n",
      "        [ -1.7810,  -0.0490],\n",
      "        [ -1.6646,   3.3178],\n",
      "        [-10.6691,  -4.4129]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 99: 0.20296750962734222\n",
      "Epoch 99, Loss: 0.20296750962734222\n",
      "Train done\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T23:44:31.663950Z",
     "start_time": "2024-05-24T23:44:31.649808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Enhanced Evaluation Function\n",
    "def evaluate(model, data, job_descriptions, resumes):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        probabilities = F.softmax(out, dim=1)  # Get probabilities\n",
    "        pred = probabilities.argmax(dim=1)\n",
    "\n",
    "        accuracy = accuracy_score(targets, pred)\n",
    "        precision = precision_score(targets, pred)\n",
    "        recall = recall_score(targets, pred)\n",
    "        f1 = f1_score(targets, pred)\n",
    "\n",
    "        print(f'Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}')\n",
    "        torch.save(model.state_dict(), f\"./models/gcn-recommendation-system-{accuracy}-acc-{uuid.uuid4()}-v1.pth\")\n",
    "\n",
    "        # Detailed Matching Results\n",
    "        # num_jobs = len(job_descriptions)\n",
    "        # num_resumes = len(resumes)\n",
    "        # matches = []\n",
    "        # for i in range(num_jobs):\n",
    "        #     for j in range(num_resumes):\n",
    "        #         candidate_index = j + num_jobs\n",
    "        #         match_percentage = probabilities[candidate_index][1].item() * 100  # Match percentage for the positive class\n",
    "        #         if pred[candidate_index] == 1:  # If candidate is predicted to match a job\n",
    "        #             matches.append((job_descriptions.iloc[i], resumes.iloc[j], match_percentage))\n",
    "        # \n",
    "        # print(\"Matching Results:\")\n",
    "        # for job, candidate, match_percentage in matches:\n",
    "        #     print(f\"Job: {job['job_id']} - {job['job_title']}, Candidate: {candidate['candidate_id']} - {candidate['job_title']}, Match Percentage: {match_percentage:.2f}%\")\n",
    "        #     break\n",
    "\n",
    "evaluate(model, data_embeddings, job_descriptions, resumes)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9505606523955148, Precision: 0.926949654491609, Recall: 0.9760914760914761, F1 Score: 0.9508860759493671\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T23:44:31.670756Z",
     "start_time": "2024-05-24T23:44:31.663950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T23:44:31.673155Z",
     "start_time": "2024-05-24T23:44:31.670756Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 57
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
