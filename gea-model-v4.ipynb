{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# GAE",
   "id": "74f7ed965b90fc08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Set random seed for reproducibility\n",
    "# random_seed = 42\n",
    "# np.random.seed(random_seed)\n",
    "# \n",
    "# # Load datasets\n",
    "# job_descriptions = pd.read_csv('./data/processed/job_descriptions_processed.csv')\n",
    "# resumes = pd.read_csv('./data/processed/resume-dataset-processed.csv', converters={'skills': literal_eval})\n",
    "# \n",
    "# # Shuffle job_descriptions and select the first 100 rows\n",
    "# job_descriptions = job_descriptions.sample(frac=1, random_state=random_seed).head(100)\n",
    "# \n",
    "# # Convert 'skills' column to list\n",
    "# job_descriptions['skills'] = job_descriptions['skills'].apply(literal_eval)"
   ],
   "id": "4991f8d84ef5ee92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, VGAE\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import train_test_split_edges, negative_sampling\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.nn import Node2Vec\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "a511aa2d122e9de1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Load datasets\n",
    "job_descriptions = pd.read_csv('./data/processed/job_descriptions_processed.csv')\n",
    "resumes = pd.read_csv('./data/processed/general-resume-dataset-processed-v1.csv', converters={'skills': literal_eval})\n",
    "\n",
    "# Shuffle job_descriptions and select the first N rows\n",
    "job_descriptions = job_descriptions.sample(frac=1, random_state=random_seed).head(10000)\n",
    "\n",
    "# Convert 'skills' column to list\n",
    "job_descriptions['skills'] = job_descriptions['skills'].apply(literal_eval)"
   ],
   "id": "fa9cfddac8b5ada2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Replace None values in job_title and category with a default value before encoding\n",
    "job_descriptions['job_title'].fillna('unknown', inplace=True)\n",
    "resumes['job_title'].fillna('unknown', inplace=True)\n",
    "resumes['category'].fillna('unknown', inplace=True)\n",
    "\n",
    "# Ensure job_ids and candidate_ids are correctly assigned\n",
    "job_descriptions['job_id'] = range(1, len(job_descriptions) + 1)\n",
    "resumes['candidate_id'] = range(1, len(resumes) + 1)\n",
    "\n",
    "# Add 'unknown' to the list of all titles and categories to handle unseen labels\n",
    "all_titles = job_descriptions['job_title'].tolist() + resumes['job_title'].tolist()\n",
    "all_titles.append('unknown')\n",
    "all_categories = resumes['category'].tolist()\n",
    "all_categories.append('unknown')"
   ],
   "id": "b70a742ea5564a74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fit the label encoders\n",
    "le_job_title = LabelEncoder()\n",
    "le_category = LabelEncoder()\n",
    "le_job_title.fit(all_titles)\n",
    "le_category.fit(all_categories)\n",
    "\n",
    "# Transform the columns\n",
    "job_descriptions['job_title'] = le_job_title.transform(job_descriptions['job_title'])\n",
    "resumes['job_title'] = le_job_title.transform(resumes['job_title'])\n",
    "resumes['category'] = le_category.transform(resumes['category'])\n",
    "\n",
    "# Encode skills\n",
    "all_skills = set(skill for skills in job_descriptions['skills'].tolist() + resumes['skills'].tolist() for skill in skills)\n",
    "le_skills = {skill: i for i, skill in enumerate(all_skills)}"
   ],
   "id": "c49775725ec99b91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create nodes and edges for the graph\n",
    "nodes = []\n",
    "edges = []\n",
    "node_features = []\n",
    "\n",
    "# Add job nodes\n",
    "for i, row in job_descriptions.iterrows():\n",
    "    nodes.append(row['job_id'])\n",
    "    skills_vector = [0] * len(le_skills)\n",
    "    if row['skills']:  # Check if skills are not empty\n",
    "        for skill in row['skills']:\n",
    "            skills_vector[le_skills[skill]] = 1\n",
    "    node_features.append([row['job_title']] + skills_vector)\n",
    "\n",
    "# Add resume nodes, using 'category' instead of 'job_title'\n",
    "for i, row in resumes.iterrows():\n",
    "    nodes.append(row['candidate_id'] + len(job_descriptions))\n",
    "    skills_vector = [0] * len(le_skills)\n",
    "    if row['skills']:  # Check if skills are not empty\n",
    "        for skill in row['skills']:\n",
    "            skills_vector[le_skills[skill]] = 1\n",
    "    node_features.append([row['job_title']] + skills_vector)\n",
    "\n",
    "# Add edges based on job_title overlap\n",
    "# for i, job in job_descriptions.iterrows():\n",
    "#     for j, resume in resumes.iterrows():\n",
    "#         if job['job_title'] == resume['job_title']:  # Changed from resume['job_title'] to resume['category']\n",
    "#             edges.append((job['job_id'], resume['candidate_id'] + len(job_descriptions)))\n",
    "\n",
    "def skills_overlap(job_skills, resume_skills):\n",
    "    return len(set(job_skills).intersection(set(resume_skills)))\n",
    "\n",
    "threshold = 1  # Set a threshold for the minimum number of overlapping skills\n",
    "\n",
    "# for i, job in job_descriptions.iterrows():\n",
    "#     for j, resume in resumes.iterrows():\n",
    "#         overlap = skills_overlap(job['skills'], resume['skills'])\n",
    "#         if overlap >= threshold:\n",
    "#             edges.append((job['job_id'], resume['candidate_id'] + len(job_descriptions)))\n",
    "\n",
    "for i, job in job_descriptions.iterrows():\n",
    "    for j, resume in resumes.iterrows():\n",
    "        if job['job_title'] == resume['job_title'] or skills_overlap(job['skills'], resume['skills']) >= threshold:\n",
    "            edges.append((job['job_id'], resume['candidate_id'] + len(job_descriptions)))"
   ],
   "id": "f4b872c380c1063b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Correct node indices\n",
    "num_job_nodes = len(job_descriptions)\n",
    "num_resume_nodes = len(resumes)\n",
    "total_nodes = num_job_nodes + num_resume_nodes\n",
    "\n",
    "# Reindex edges to ensure correct range\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "edge_index[0] = edge_index[0].clamp(0, total_nodes - 1)\n",
    "edge_index[1] = edge_index[1].clamp(0, total_nodes - 1)\n",
    "\n",
    "# Convert to torch tensors\n",
    "x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "# Create PyTorch Geometric data object\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# Ensure edge indices are within range\n",
    "data.edge_index = edge_index\n",
    "data.num_nodes = total_nodes\n",
    "print(data.edge_index)\n",
    "print(data.num_nodes)\n",
    "\n",
    "# Splitting edges for training/validation\n",
    "original_edge_index = data.edge_index.clone()\n",
    "original_pos_edge_index = data.edge_index.clone()\n",
    "original_neg_edge_index = data.edge_index.clone()\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "# Manually create negative edges for training\n",
    "neg_edge_index_train = negative_sampling(\n",
    "    edge_index=data.train_pos_edge_index,\n",
    "    num_nodes=data.num_nodes,\n",
    "    num_neg_samples=data.train_pos_edge_index.size(1)\n",
    ")\n",
    "data.train_neg_edge_index = neg_edge_index_train\n",
    "\n",
    "# Manually create negative edges for testing\n",
    "neg_edge_index_test = negative_sampling(\n",
    "    edge_index=data.test_pos_edge_index,\n",
    "    num_nodes=data.num_nodes,\n",
    "    num_neg_samples=data.test_pos_edge_index.size(1)\n",
    ")\n",
    "data.test_neg_edge_index = neg_edge_index_test"
   ],
   "id": "91f230b61ba4cc8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T23:40:33.628915Z",
     "start_time": "2024-05-25T23:40:33.618550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define number of nodes\n",
    "num_nodes = data.num_nodes\n",
    "\n",
    "# Node2Vec parameters\n",
    "embedding_dim = 64\n",
    "walk_length = 20\n",
    "context_size = 10\n",
    "walks_per_node = 10\n",
    "batch_size = 64\n",
    "lr = 0.1\n",
    "num_epochs = 100"
   ],
   "id": "fba21fbb8d038909",
   "outputs": [],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T23:40:34.239832Z",
     "start_time": "2024-05-25T23:40:34.199761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize Node2Vec\n",
    "node2vec = Node2Vec(\n",
    "    edge_index=original_edge_index,\n",
    "    embedding_dim=embedding_dim,\n",
    "    walk_length=walk_length,\n",
    "    context_size=context_size,\n",
    "    walks_per_node=walks_per_node,\n",
    "    num_negative_samples=1,\n",
    "    p=1,\n",
    "    q=1,\n",
    "    sparse=True,\n",
    "    num_nodes=num_nodes  # Specify number of nodes\n",
    ")\n",
    "\n",
    "# Move to the appropriate device (CPU/GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "node2vec = node2vec.to(device)"
   ],
   "id": "6f325c1adced2d3c",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T23:40:35.421824Z",
     "start_time": "2024-05-25T23:40:35.412867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Optimizer for Node2Vec\n",
    "optimizer = torch.optim.SparseAdam(node2vec.parameters(), lr=lr)"
   ],
   "id": "d2b1d3e64f0c57b7",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T23:40:35.950117Z",
     "start_time": "2024-05-25T23:40:35.940523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop for Node2Vec\n",
    "def train_node2vec(num_epochs):\n",
    "    node2vec.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        loader = node2vec.loader(batch_size=batch_size, shuffle=True, num_workers=0)  # Set num_workers=0\n",
    "        for i, (pos_rw, neg_rw) in enumerate(loader):\n",
    "            optimizer.zero_grad()\n",
    "            loss = node2vec.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            if i % 10 == 0:\n",
    "                print(f'Epoch {epoch + 1}, Iteration {i}, Loss: {total_loss / 10}')\n",
    "                total_loss = 0"
   ],
   "id": "a4673e0d68813981",
   "outputs": [],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T23:41:31.663901Z",
     "start_time": "2024-05-25T23:40:40.517396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train Node2Vec model\n",
    "train_node2vec(num_epochs)"
   ],
   "id": "36416a190e418fdb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 0, Loss: 0.3731998443603516\n",
      "Epoch 1, Iteration 10, Loss: 3.2722758769989015\n",
      "Epoch 1, Iteration 20, Loss: 2.6165997266769407\n",
      "Epoch 1, Iteration 30, Loss: 2.043922543525696\n",
      "Epoch 1, Iteration 40, Loss: 1.6112670063972474\n",
      "Epoch 1, Iteration 50, Loss: 1.29803067445755\n",
      "Epoch 1, Iteration 60, Loss: 1.0976505279541016\n",
      "Epoch 1, Iteration 70, Loss: 0.9791308343410492\n",
      "Epoch 1, Iteration 80, Loss: 0.9161386787891388\n",
      "Epoch 1, Iteration 90, Loss: 0.8717039287090301\n",
      "Epoch 1, Iteration 100, Loss: 0.8507448554039001\n",
      "Epoch 1, Iteration 110, Loss: 0.839344573020935\n",
      "Epoch 1, Iteration 120, Loss: 0.8344492435455322\n",
      "Epoch 1, Iteration 130, Loss: 0.8386867642402649\n",
      "Epoch 1, Iteration 140, Loss: 0.8440695941448212\n",
      "Epoch 1, Iteration 150, Loss: 0.8507992148399353\n",
      "Epoch 1, Iteration 160, Loss: 0.8593101918697357\n",
      "Epoch 1, Iteration 170, Loss: 0.869745534658432\n",
      "Epoch 1, Iteration 180, Loss: 0.8807528734207153\n",
      "Epoch 1, Iteration 190, Loss: 0.8956387758255004\n",
      "Epoch 2, Iteration 0, Loss: 0.08876135349273681\n",
      "Epoch 2, Iteration 10, Loss: 0.8969107925891876\n",
      "Epoch 2, Iteration 20, Loss: 0.9107026338577271\n",
      "Epoch 2, Iteration 30, Loss: 0.9088997840881348\n",
      "Epoch 2, Iteration 40, Loss: 0.8999141216278076\n",
      "Epoch 2, Iteration 50, Loss: 0.8955535471439362\n",
      "Epoch 2, Iteration 60, Loss: 0.8861784636974335\n",
      "Epoch 2, Iteration 70, Loss: 0.8729147374629974\n",
      "Epoch 2, Iteration 80, Loss: 0.8631007850170136\n",
      "Epoch 2, Iteration 90, Loss: 0.8568298876285553\n",
      "Epoch 2, Iteration 100, Loss: 0.852010840177536\n",
      "Epoch 2, Iteration 110, Loss: 0.8475699901580811\n",
      "Epoch 2, Iteration 120, Loss: 0.8443204402923584\n",
      "Epoch 2, Iteration 130, Loss: 0.845173716545105\n",
      "Epoch 2, Iteration 140, Loss: 0.8430366277694702\n",
      "Epoch 2, Iteration 150, Loss: 0.8472988665103912\n",
      "Epoch 2, Iteration 160, Loss: 0.8444841504096985\n",
      "Epoch 2, Iteration 170, Loss: 0.8475543260574341\n",
      "Epoch 2, Iteration 180, Loss: 0.855126142501831\n",
      "Epoch 2, Iteration 190, Loss: 0.8559129953384399\n",
      "Epoch 3, Iteration 0, Loss: 0.08593318462371827\n",
      "Epoch 3, Iteration 10, Loss: 0.8625747680664062\n",
      "Epoch 3, Iteration 20, Loss: 0.8740011870861053\n",
      "Epoch 3, Iteration 30, Loss: 0.8719708383083343\n",
      "Epoch 3, Iteration 40, Loss: 0.8715792953968048\n",
      "Epoch 3, Iteration 50, Loss: 0.8690884113311768\n",
      "Epoch 3, Iteration 60, Loss: 0.8588458180427552\n",
      "Epoch 3, Iteration 70, Loss: 0.8597167372703552\n",
      "Epoch 3, Iteration 80, Loss: 0.8550047159194947\n",
      "Epoch 3, Iteration 90, Loss: 0.8531628489494324\n",
      "Epoch 3, Iteration 100, Loss: 0.8510494470596314\n",
      "Epoch 3, Iteration 110, Loss: 0.8488741040229797\n",
      "Epoch 3, Iteration 120, Loss: 0.8527926623821258\n",
      "Epoch 3, Iteration 130, Loss: 0.8536775290966034\n",
      "Epoch 3, Iteration 140, Loss: 0.8544308125972748\n",
      "Epoch 3, Iteration 150, Loss: 0.8596902847290039\n",
      "Epoch 3, Iteration 160, Loss: 0.8632291257381439\n",
      "Epoch 3, Iteration 170, Loss: 0.8655287742614746\n",
      "Epoch 3, Iteration 180, Loss: 0.8726254343986511\n",
      "Epoch 3, Iteration 190, Loss: 0.8764685928821564\n",
      "Epoch 4, Iteration 0, Loss: 0.08677502870559692\n",
      "Epoch 4, Iteration 10, Loss: 0.8791345059871674\n",
      "Epoch 4, Iteration 20, Loss: 0.8928659796714783\n",
      "Epoch 4, Iteration 30, Loss: 0.8949392557144165\n",
      "Epoch 4, Iteration 40, Loss: 0.8879766345024109\n",
      "Epoch 4, Iteration 50, Loss: 0.8784418165683746\n",
      "Epoch 4, Iteration 60, Loss: 0.8728266835212708\n",
      "Epoch 4, Iteration 70, Loss: 0.8712850272655487\n",
      "Epoch 4, Iteration 80, Loss: 0.8663936018943786\n",
      "Epoch 4, Iteration 90, Loss: 0.8613788843154907\n",
      "Epoch 4, Iteration 100, Loss: 0.8598802566528321\n",
      "Epoch 4, Iteration 110, Loss: 0.8574010789394378\n",
      "Epoch 4, Iteration 120, Loss: 0.858458411693573\n",
      "Epoch 4, Iteration 130, Loss: 0.860762894153595\n",
      "Epoch 4, Iteration 140, Loss: 0.86168133020401\n",
      "Epoch 4, Iteration 150, Loss: 0.8644393920898438\n",
      "Epoch 4, Iteration 160, Loss: 0.8689764440059662\n",
      "Epoch 4, Iteration 170, Loss: 0.869790256023407\n",
      "Epoch 4, Iteration 180, Loss: 0.874554842710495\n",
      "Epoch 4, Iteration 190, Loss: 0.8780353903770447\n",
      "Epoch 5, Iteration 0, Loss: 0.08776113390922546\n",
      "Epoch 5, Iteration 10, Loss: 0.8876447081565857\n",
      "Epoch 5, Iteration 20, Loss: 0.8988811433315277\n",
      "Epoch 5, Iteration 30, Loss: 0.9027725160121918\n",
      "Epoch 5, Iteration 40, Loss: 0.9039006054401397\n",
      "Epoch 5, Iteration 50, Loss: 0.8949249684810638\n",
      "Epoch 5, Iteration 60, Loss: 0.8888786435127258\n",
      "Epoch 5, Iteration 70, Loss: 0.8825859963893891\n",
      "Epoch 5, Iteration 80, Loss: 0.878994369506836\n",
      "Epoch 5, Iteration 90, Loss: 0.8705190598964692\n",
      "Epoch 5, Iteration 100, Loss: 0.8703790247440338\n",
      "Epoch 5, Iteration 110, Loss: 0.8646340191364288\n",
      "Epoch 5, Iteration 120, Loss: 0.8696724891662597\n",
      "Epoch 5, Iteration 130, Loss: 0.8675383746623992\n",
      "Epoch 5, Iteration 140, Loss: 0.8713151454925537\n",
      "Epoch 5, Iteration 150, Loss: 0.8759171366691589\n",
      "Epoch 5, Iteration 160, Loss: 0.8770811975002288\n",
      "Epoch 5, Iteration 170, Loss: 0.8803113341331482\n",
      "Epoch 5, Iteration 180, Loss: 0.8848420679569244\n",
      "Epoch 5, Iteration 190, Loss: 0.8857641398906708\n",
      "Epoch 6, Iteration 0, Loss: 0.08901519775390625\n",
      "Epoch 6, Iteration 10, Loss: 0.8978909134864808\n",
      "Epoch 6, Iteration 20, Loss: 0.9128720879554748\n",
      "Epoch 6, Iteration 30, Loss: 0.9177440345287323\n",
      "Epoch 6, Iteration 40, Loss: 0.9165073931217194\n",
      "Epoch 6, Iteration 50, Loss: 0.9094498634338379\n",
      "Epoch 6, Iteration 60, Loss: 0.8997600018978119\n",
      "Epoch 6, Iteration 70, Loss: 0.8949871301651001\n",
      "Epoch 6, Iteration 80, Loss: 0.8883582472801208\n",
      "Epoch 6, Iteration 90, Loss: 0.8877562582492828\n",
      "Epoch 6, Iteration 100, Loss: 0.8806246757507324\n",
      "Epoch 6, Iteration 110, Loss: 0.8830136060714722\n",
      "Epoch 6, Iteration 120, Loss: 0.8751445233821868\n",
      "Epoch 6, Iteration 130, Loss: 0.8762053787708283\n",
      "Epoch 6, Iteration 140, Loss: 0.8750386238098145\n",
      "Epoch 6, Iteration 150, Loss: 0.8799321830272675\n",
      "Epoch 6, Iteration 160, Loss: 0.8764789879322052\n",
      "Epoch 6, Iteration 170, Loss: 0.8810478925704956\n",
      "Epoch 6, Iteration 180, Loss: 0.8825285077095032\n",
      "Epoch 6, Iteration 190, Loss: 0.8853836774826049\n",
      "Epoch 7, Iteration 0, Loss: 0.08830313086509704\n",
      "Epoch 7, Iteration 10, Loss: 0.8920066654682159\n",
      "Epoch 7, Iteration 20, Loss: 0.904704213142395\n",
      "Epoch 7, Iteration 30, Loss: 0.9079104065895081\n",
      "Epoch 7, Iteration 40, Loss: 0.9068927228450775\n",
      "Epoch 7, Iteration 50, Loss: 0.9025789856910705\n",
      "Epoch 7, Iteration 60, Loss: 0.9001893520355224\n",
      "Epoch 7, Iteration 70, Loss: 0.8902913570404053\n",
      "Epoch 7, Iteration 80, Loss: 0.8823907792568206\n",
      "Epoch 7, Iteration 90, Loss: 0.8854507803916931\n",
      "Epoch 7, Iteration 100, Loss: 0.8757251143455506\n",
      "Epoch 7, Iteration 110, Loss: 0.873054051399231\n",
      "Epoch 7, Iteration 120, Loss: 0.8727006494998932\n",
      "Epoch 7, Iteration 130, Loss: 0.8704404413700104\n",
      "Epoch 7, Iteration 140, Loss: 0.8739376485347747\n",
      "Epoch 7, Iteration 150, Loss: 0.8743071138858796\n",
      "Epoch 7, Iteration 160, Loss: 0.8776479840278626\n",
      "Epoch 7, Iteration 170, Loss: 0.877427589893341\n",
      "Epoch 7, Iteration 180, Loss: 0.881086403131485\n",
      "Epoch 7, Iteration 190, Loss: 0.8819184839725495\n",
      "Epoch 8, Iteration 0, Loss: 0.08781623840332031\n",
      "Epoch 8, Iteration 10, Loss: 0.8895910441875458\n",
      "Epoch 8, Iteration 20, Loss: 0.9035662353038788\n",
      "Epoch 8, Iteration 30, Loss: 0.9076487720012665\n",
      "Epoch 8, Iteration 40, Loss: 0.9077781975269318\n",
      "Epoch 8, Iteration 50, Loss: 0.9006223082542419\n",
      "Epoch 8, Iteration 60, Loss: 0.8973397612571716\n",
      "Epoch 8, Iteration 70, Loss: 0.890018743276596\n",
      "Epoch 8, Iteration 80, Loss: 0.8834556341171265\n",
      "Epoch 8, Iteration 90, Loss: 0.8800757646560669\n",
      "Epoch 8, Iteration 100, Loss: 0.8789692521095276\n",
      "Epoch 8, Iteration 110, Loss: 0.8718300104141236\n",
      "Epoch 8, Iteration 120, Loss: 0.870744377374649\n",
      "Epoch 8, Iteration 130, Loss: 0.8698438048362732\n",
      "Epoch 8, Iteration 140, Loss: 0.8691015839576721\n",
      "Epoch 8, Iteration 150, Loss: 0.8710492551326752\n",
      "Epoch 8, Iteration 160, Loss: 0.8737963080406189\n",
      "Epoch 8, Iteration 170, Loss: 0.8744938194751739\n",
      "Epoch 8, Iteration 180, Loss: 0.8749907732009887\n",
      "Epoch 8, Iteration 190, Loss: 0.8808362126350403\n",
      "Epoch 9, Iteration 0, Loss: 0.08669719696044922\n",
      "Epoch 9, Iteration 10, Loss: 0.8868694722652435\n",
      "Epoch 9, Iteration 20, Loss: 0.9013343453407288\n",
      "Epoch 9, Iteration 30, Loss: 0.9052340090274811\n",
      "Epoch 9, Iteration 40, Loss: 0.8986549377441406\n",
      "Epoch 9, Iteration 50, Loss: 0.8952417254447937\n",
      "Epoch 9, Iteration 60, Loss: 0.8862026453018188\n",
      "Epoch 9, Iteration 70, Loss: 0.8846139788627625\n",
      "Epoch 9, Iteration 80, Loss: 0.8782998442649841\n",
      "Epoch 9, Iteration 90, Loss: 0.879041588306427\n",
      "Epoch 9, Iteration 100, Loss: 0.8712492644786834\n",
      "Epoch 9, Iteration 110, Loss: 0.8676815450191497\n",
      "Epoch 9, Iteration 120, Loss: 0.8696419835090637\n",
      "Epoch 9, Iteration 130, Loss: 0.87002312541008\n",
      "Epoch 9, Iteration 140, Loss: 0.8686629235744476\n",
      "Epoch 9, Iteration 150, Loss: 0.8674655139446259\n",
      "Epoch 9, Iteration 160, Loss: 0.8718513071537017\n",
      "Epoch 9, Iteration 170, Loss: 0.8717345237731934\n",
      "Epoch 9, Iteration 180, Loss: 0.8747791409492492\n",
      "Epoch 9, Iteration 190, Loss: 0.8776743710041046\n",
      "Epoch 10, Iteration 0, Loss: 0.08739696145057678\n",
      "Epoch 10, Iteration 10, Loss: 0.8837581992149353\n",
      "Epoch 10, Iteration 20, Loss: 0.9017070472240448\n",
      "Epoch 10, Iteration 30, Loss: 0.9038268148899078\n",
      "Epoch 10, Iteration 40, Loss: 0.9059892475605011\n",
      "Epoch 10, Iteration 50, Loss: 0.8985926747322083\n",
      "Epoch 10, Iteration 60, Loss: 0.8921261966228485\n",
      "Epoch 10, Iteration 70, Loss: 0.8861335217952728\n",
      "Epoch 10, Iteration 80, Loss: 0.8828734517097473\n",
      "Epoch 10, Iteration 90, Loss: 0.8772508323192596\n",
      "Epoch 10, Iteration 100, Loss: 0.8737848162651062\n",
      "Epoch 10, Iteration 110, Loss: 0.8705602049827575\n",
      "Epoch 10, Iteration 120, Loss: 0.8679177582263946\n",
      "Epoch 10, Iteration 130, Loss: 0.8693251252174378\n",
      "Epoch 10, Iteration 140, Loss: 0.8661641001701355\n",
      "Epoch 10, Iteration 150, Loss: 0.8690614879131318\n",
      "Epoch 10, Iteration 160, Loss: 0.868802523612976\n",
      "Epoch 10, Iteration 170, Loss: 0.8697190463542939\n",
      "Epoch 10, Iteration 180, Loss: 0.8696809887886048\n",
      "Epoch 10, Iteration 190, Loss: 0.8755203306674957\n",
      "Epoch 11, Iteration 0, Loss: 0.08735715746879577\n",
      "Epoch 11, Iteration 10, Loss: 0.8810657918453216\n",
      "Epoch 11, Iteration 20, Loss: 0.8927838504314423\n",
      "Epoch 11, Iteration 30, Loss: 0.8980094373226166\n",
      "Epoch 11, Iteration 40, Loss: 0.8918876230716706\n",
      "Epoch 11, Iteration 50, Loss: 0.8890797138214112\n",
      "Epoch 11, Iteration 60, Loss: 0.8846591591835022\n",
      "Epoch 11, Iteration 70, Loss: 0.8821267068386078\n",
      "Epoch 11, Iteration 80, Loss: 0.8749931752681732\n",
      "Epoch 11, Iteration 90, Loss: 0.872098708152771\n",
      "Epoch 11, Iteration 100, Loss: 0.8667108833789825\n",
      "Epoch 11, Iteration 110, Loss: 0.868180912733078\n",
      "Epoch 11, Iteration 120, Loss: 0.8644281089305877\n",
      "Epoch 11, Iteration 130, Loss: 0.8639508306980133\n",
      "Epoch 11, Iteration 140, Loss: 0.8639848947525024\n",
      "Epoch 11, Iteration 150, Loss: 0.868841803073883\n",
      "Epoch 11, Iteration 160, Loss: 0.8672837734222412\n",
      "Epoch 11, Iteration 170, Loss: 0.8713637351989746\n",
      "Epoch 11, Iteration 180, Loss: 0.8699562072753906\n",
      "Epoch 11, Iteration 190, Loss: 0.8708300113677978\n",
      "Epoch 12, Iteration 0, Loss: 0.08790472745895386\n",
      "Epoch 12, Iteration 10, Loss: 0.882276576757431\n",
      "Epoch 12, Iteration 20, Loss: 0.8963099598884583\n",
      "Epoch 12, Iteration 30, Loss: 0.8939279615879059\n",
      "Epoch 12, Iteration 40, Loss: 0.8933251440525055\n",
      "Epoch 12, Iteration 50, Loss: 0.8895520329475403\n",
      "Epoch 12, Iteration 60, Loss: 0.8817346453666687\n",
      "Epoch 12, Iteration 70, Loss: 0.8728587448596954\n",
      "Epoch 12, Iteration 80, Loss: 0.8705352306365967\n",
      "Epoch 12, Iteration 90, Loss: 0.8587619006633759\n",
      "Epoch 12, Iteration 100, Loss: 0.8623153567314148\n",
      "Epoch 12, Iteration 110, Loss: 0.8558515846729279\n",
      "Epoch 12, Iteration 120, Loss: 0.850048565864563\n",
      "Epoch 12, Iteration 130, Loss: 0.8541612565517426\n",
      "Epoch 12, Iteration 140, Loss: 0.8499715745449066\n",
      "Epoch 12, Iteration 150, Loss: 0.8500598430633545\n",
      "Epoch 12, Iteration 160, Loss: 0.8545174658298492\n",
      "Epoch 12, Iteration 170, Loss: 0.8596088528633118\n",
      "Epoch 12, Iteration 180, Loss: 0.8602521181106567\n",
      "Epoch 12, Iteration 190, Loss: 0.8609948873519897\n",
      "Epoch 13, Iteration 0, Loss: 0.08555876016616822\n",
      "Epoch 13, Iteration 10, Loss: 0.8734296441078186\n",
      "Epoch 13, Iteration 20, Loss: 0.8819193005561828\n",
      "Epoch 13, Iteration 30, Loss: 0.8902783989906311\n",
      "Epoch 13, Iteration 40, Loss: 0.8875632226467133\n",
      "Epoch 13, Iteration 50, Loss: 0.8824967205524444\n",
      "Epoch 13, Iteration 60, Loss: 0.8757975280284882\n",
      "Epoch 13, Iteration 70, Loss: 0.870501846075058\n",
      "Epoch 13, Iteration 80, Loss: 0.8623004794120789\n",
      "Epoch 13, Iteration 90, Loss: 0.8585601329803467\n",
      "Epoch 13, Iteration 100, Loss: 0.8574371874332428\n",
      "Epoch 13, Iteration 110, Loss: 0.8545708119869232\n",
      "Epoch 13, Iteration 120, Loss: 0.8523892819881439\n",
      "Epoch 13, Iteration 130, Loss: 0.8522619783878327\n",
      "Epoch 13, Iteration 140, Loss: 0.8533051967620849\n",
      "Epoch 13, Iteration 150, Loss: 0.8526157915592194\n",
      "Epoch 13, Iteration 160, Loss: 0.859044486284256\n",
      "Epoch 13, Iteration 170, Loss: 0.8579420864582061\n",
      "Epoch 13, Iteration 180, Loss: 0.8619687855243683\n",
      "Epoch 13, Iteration 190, Loss: 0.8639329433441162\n",
      "Epoch 14, Iteration 0, Loss: 0.08675442337989807\n",
      "Epoch 14, Iteration 10, Loss: 0.8714888274669648\n",
      "Epoch 14, Iteration 20, Loss: 0.8856853008270263\n",
      "Epoch 14, Iteration 30, Loss: 0.8864306032657623\n",
      "Epoch 14, Iteration 40, Loss: 0.8824565410614014\n",
      "Epoch 14, Iteration 50, Loss: 0.8756754040718079\n",
      "Epoch 14, Iteration 60, Loss: 0.873817753791809\n",
      "Epoch 14, Iteration 70, Loss: 0.8653453886508942\n",
      "Epoch 14, Iteration 80, Loss: 0.8601134717464447\n",
      "Epoch 14, Iteration 90, Loss: 0.8543525457382202\n",
      "Epoch 14, Iteration 100, Loss: 0.8535865128040314\n",
      "Epoch 14, Iteration 110, Loss: 0.8497106075286865\n",
      "Epoch 14, Iteration 120, Loss: 0.8514339625835419\n",
      "Epoch 14, Iteration 130, Loss: 0.8473631203174591\n",
      "Epoch 14, Iteration 140, Loss: 0.8506244480609894\n",
      "Epoch 14, Iteration 150, Loss: 0.8518117725849151\n",
      "Epoch 14, Iteration 160, Loss: 0.8518534958362579\n",
      "Epoch 14, Iteration 170, Loss: 0.8564985275268555\n",
      "Epoch 14, Iteration 180, Loss: 0.8595856070518494\n",
      "Epoch 14, Iteration 190, Loss: 0.8616517543792724\n",
      "Epoch 15, Iteration 0, Loss: 0.08650547862052918\n",
      "Epoch 15, Iteration 10, Loss: 0.8719526946544647\n",
      "Epoch 15, Iteration 20, Loss: 0.8842639327049255\n",
      "Epoch 15, Iteration 30, Loss: 0.8861127912998199\n",
      "Epoch 15, Iteration 40, Loss: 0.8834920346736908\n",
      "Epoch 15, Iteration 50, Loss: 0.8787342965602875\n",
      "Epoch 15, Iteration 60, Loss: 0.8758717834949493\n",
      "Epoch 15, Iteration 70, Loss: 0.8671701610088348\n",
      "Epoch 15, Iteration 80, Loss: 0.864905321598053\n",
      "Epoch 15, Iteration 90, Loss: 0.8580771625041962\n",
      "Epoch 15, Iteration 100, Loss: 0.8573517739772797\n",
      "Epoch 15, Iteration 110, Loss: 0.8523914039134979\n",
      "Epoch 15, Iteration 120, Loss: 0.8520482301712036\n",
      "Epoch 15, Iteration 130, Loss: 0.8520039200782776\n",
      "Epoch 15, Iteration 140, Loss: 0.85484858751297\n",
      "Epoch 15, Iteration 150, Loss: 0.8545974314212799\n",
      "Epoch 15, Iteration 160, Loss: 0.8558222711086273\n",
      "Epoch 15, Iteration 170, Loss: 0.8615694940090179\n",
      "Epoch 15, Iteration 180, Loss: 0.8624460399150848\n",
      "Epoch 15, Iteration 190, Loss: 0.8654529988765717\n",
      "Epoch 16, Iteration 0, Loss: 0.08655081391334533\n",
      "Epoch 16, Iteration 10, Loss: 0.8783639967441559\n",
      "Epoch 16, Iteration 20, Loss: 0.8933968901634216\n",
      "Epoch 16, Iteration 30, Loss: 0.8959347426891326\n",
      "Epoch 16, Iteration 40, Loss: 0.8928171575069428\n",
      "Epoch 16, Iteration 50, Loss: 0.888717383146286\n",
      "Epoch 16, Iteration 60, Loss: 0.8825296938419342\n",
      "Epoch 16, Iteration 70, Loss: 0.8757588505744934\n",
      "Epoch 16, Iteration 80, Loss: 0.8675628185272217\n",
      "Epoch 16, Iteration 90, Loss: 0.8644592821598053\n",
      "Epoch 16, Iteration 100, Loss: 0.8561097621917725\n",
      "Epoch 16, Iteration 110, Loss: 0.8574495494365693\n",
      "Epoch 16, Iteration 120, Loss: 0.8548472821712494\n",
      "Epoch 16, Iteration 130, Loss: 0.8530717730522156\n",
      "Epoch 16, Iteration 140, Loss: 0.8567379474639892\n",
      "Epoch 16, Iteration 150, Loss: 0.8565129101276397\n",
      "Epoch 16, Iteration 160, Loss: 0.8566973865032196\n",
      "Epoch 16, Iteration 170, Loss: 0.8614095866680145\n",
      "Epoch 16, Iteration 180, Loss: 0.8631172060966492\n",
      "Epoch 16, Iteration 190, Loss: 0.8643270254135131\n",
      "Epoch 17, Iteration 0, Loss: 0.0876485288143158\n",
      "Epoch 17, Iteration 10, Loss: 0.8768654644489289\n",
      "Epoch 17, Iteration 20, Loss: 0.8900805711746216\n",
      "Epoch 17, Iteration 30, Loss: 0.8927203297615052\n",
      "Epoch 17, Iteration 40, Loss: 0.8894652307033539\n",
      "Epoch 17, Iteration 50, Loss: 0.8840389251708984\n",
      "Epoch 17, Iteration 60, Loss: 0.8807483911514282\n",
      "Epoch 17, Iteration 70, Loss: 0.874140465259552\n",
      "Epoch 17, Iteration 80, Loss: 0.865897822380066\n",
      "Epoch 17, Iteration 90, Loss: 0.8625986218452454\n",
      "Epoch 17, Iteration 100, Loss: 0.8559163331985473\n",
      "Epoch 17, Iteration 110, Loss: 0.8542226433753968\n",
      "Epoch 17, Iteration 120, Loss: 0.8547769844532013\n",
      "Epoch 17, Iteration 130, Loss: 0.8520752012729644\n",
      "Epoch 17, Iteration 140, Loss: 0.8524437427520752\n",
      "Epoch 17, Iteration 150, Loss: 0.8543089628219604\n",
      "Epoch 17, Iteration 160, Loss: 0.8567006587982178\n",
      "Epoch 17, Iteration 170, Loss: 0.8583637833595276\n",
      "Epoch 17, Iteration 180, Loss: 0.8628345966339112\n",
      "Epoch 17, Iteration 190, Loss: 0.8658555686473847\n",
      "Epoch 18, Iteration 0, Loss: 0.08744252920150757\n",
      "Epoch 18, Iteration 10, Loss: 0.8774138808250427\n",
      "Epoch 18, Iteration 20, Loss: 0.8885352134704589\n",
      "Epoch 18, Iteration 30, Loss: 0.8953684568405151\n",
      "Epoch 18, Iteration 40, Loss: 0.8903833270072937\n",
      "Epoch 18, Iteration 50, Loss: 0.8887067675590515\n",
      "Epoch 18, Iteration 60, Loss: 0.8865024864673614\n",
      "Epoch 18, Iteration 70, Loss: 0.8813338041305542\n",
      "Epoch 18, Iteration 80, Loss: 0.8730891942977905\n",
      "Epoch 18, Iteration 90, Loss: 0.8707453906536102\n",
      "Epoch 18, Iteration 100, Loss: 0.8678127348423004\n",
      "Epoch 18, Iteration 110, Loss: 0.8612654805183411\n",
      "Epoch 18, Iteration 120, Loss: 0.8650484204292297\n",
      "Epoch 18, Iteration 130, Loss: 0.8656400322914124\n",
      "Epoch 18, Iteration 140, Loss: 0.8621522545814514\n",
      "Epoch 18, Iteration 150, Loss: 0.8642717123031616\n",
      "Epoch 18, Iteration 160, Loss: 0.8586312055587768\n",
      "Epoch 18, Iteration 170, Loss: 0.8669467628002167\n",
      "Epoch 18, Iteration 180, Loss: 0.8624346435070038\n",
      "Epoch 18, Iteration 190, Loss: 0.866556566953659\n",
      "Epoch 19, Iteration 0, Loss: 0.08769450187683106\n",
      "Epoch 19, Iteration 10, Loss: 0.8760890781879425\n",
      "Epoch 19, Iteration 20, Loss: 0.8874005615711212\n",
      "Epoch 19, Iteration 30, Loss: 0.8918551921844482\n",
      "Epoch 19, Iteration 40, Loss: 0.8877407371997833\n",
      "Epoch 19, Iteration 50, Loss: 0.885313218832016\n",
      "Epoch 19, Iteration 60, Loss: 0.8818680286407471\n",
      "Epoch 19, Iteration 70, Loss: 0.8771701455116272\n",
      "Epoch 19, Iteration 80, Loss: 0.8691954851150513\n",
      "Epoch 19, Iteration 90, Loss: 0.8664959609508515\n",
      "Epoch 19, Iteration 100, Loss: 0.8598541498184205\n",
      "Epoch 19, Iteration 110, Loss: 0.8596310913562775\n",
      "Epoch 19, Iteration 120, Loss: 0.858073377609253\n",
      "Epoch 19, Iteration 130, Loss: 0.8553130388259887\n",
      "Epoch 19, Iteration 140, Loss: 0.8557948112487793\n",
      "Epoch 19, Iteration 150, Loss: 0.8564269483089447\n",
      "Epoch 19, Iteration 160, Loss: 0.8592914819717408\n",
      "Epoch 19, Iteration 170, Loss: 0.8616325795650482\n",
      "Epoch 19, Iteration 180, Loss: 0.8660743057727813\n",
      "Epoch 19, Iteration 190, Loss: 0.8670335412025452\n",
      "Epoch 20, Iteration 0, Loss: 0.0865734875202179\n",
      "Epoch 20, Iteration 10, Loss: 0.8751796662807465\n",
      "Epoch 20, Iteration 20, Loss: 0.8900504767894745\n",
      "Epoch 20, Iteration 30, Loss: 0.8902156591415405\n",
      "Epoch 20, Iteration 40, Loss: 0.8876436948776245\n",
      "Epoch 20, Iteration 50, Loss: 0.8820437371730805\n",
      "Epoch 20, Iteration 60, Loss: 0.8740874409675599\n",
      "Epoch 20, Iteration 70, Loss: 0.8744891464710236\n",
      "Epoch 20, Iteration 80, Loss: 0.8642670035362243\n",
      "Epoch 20, Iteration 90, Loss: 0.8648290872573853\n",
      "Epoch 20, Iteration 100, Loss: 0.8585883855819703\n",
      "Epoch 20, Iteration 110, Loss: 0.8602962732315064\n",
      "Epoch 20, Iteration 120, Loss: 0.8590239107608795\n",
      "Epoch 20, Iteration 130, Loss: 0.8583263397216797\n",
      "Epoch 20, Iteration 140, Loss: 0.859651792049408\n",
      "Epoch 20, Iteration 150, Loss: 0.861527556180954\n",
      "Epoch 20, Iteration 160, Loss: 0.8639784991741181\n",
      "Epoch 20, Iteration 170, Loss: 0.8657364547252655\n",
      "Epoch 20, Iteration 180, Loss: 0.8703152894973755\n",
      "Epoch 20, Iteration 190, Loss: 0.8719408094882966\n",
      "Epoch 21, Iteration 0, Loss: 0.087124764919281\n",
      "Epoch 21, Iteration 10, Loss: 0.8845164895057678\n",
      "Epoch 21, Iteration 20, Loss: 0.8954930245876312\n",
      "Epoch 21, Iteration 30, Loss: 0.8986021280288696\n",
      "Epoch 21, Iteration 40, Loss: 0.8951882541179657\n",
      "Epoch 21, Iteration 50, Loss: 0.8878133893013\n",
      "Epoch 21, Iteration 60, Loss: 0.8851770102977753\n",
      "Epoch 21, Iteration 70, Loss: 0.8797824740409851\n",
      "Epoch 21, Iteration 80, Loss: 0.8750180780887604\n",
      "Epoch 21, Iteration 90, Loss: 0.8687789261341095\n",
      "Epoch 21, Iteration 100, Loss: 0.8631559789180756\n",
      "Epoch 21, Iteration 110, Loss: 0.8625253081321717\n",
      "Epoch 21, Iteration 120, Loss: 0.8632970035076142\n",
      "Epoch 21, Iteration 130, Loss: 0.8592487871646881\n",
      "Epoch 21, Iteration 140, Loss: 0.862139630317688\n",
      "Epoch 21, Iteration 150, Loss: 0.8635570168495178\n",
      "Epoch 21, Iteration 160, Loss: 0.864559018611908\n",
      "Epoch 21, Iteration 170, Loss: 0.8661619842052459\n",
      "Epoch 21, Iteration 180, Loss: 0.8705772817134857\n",
      "Epoch 21, Iteration 190, Loss: 0.869159746170044\n",
      "Epoch 22, Iteration 0, Loss: 0.08665412068367004\n",
      "Epoch 22, Iteration 10, Loss: 0.8833120942115784\n",
      "Epoch 22, Iteration 20, Loss: 0.9020931541919708\n",
      "Epoch 22, Iteration 30, Loss: 0.9058974325656891\n",
      "Epoch 22, Iteration 40, Loss: 0.8986970603466033\n",
      "Epoch 22, Iteration 50, Loss: 0.8973418414592743\n",
      "Epoch 22, Iteration 60, Loss: 0.8918167471885681\n",
      "Epoch 22, Iteration 70, Loss: 0.8888866007328033\n",
      "Epoch 22, Iteration 80, Loss: 0.8793548047542572\n",
      "Epoch 22, Iteration 90, Loss: 0.8760273158550262\n",
      "Epoch 22, Iteration 100, Loss: 0.8716867148876191\n",
      "Epoch 22, Iteration 110, Loss: 0.8677031397819519\n",
      "Epoch 22, Iteration 120, Loss: 0.8697661519050598\n",
      "Epoch 22, Iteration 130, Loss: 0.864338219165802\n",
      "Epoch 22, Iteration 140, Loss: 0.864331066608429\n",
      "Epoch 22, Iteration 150, Loss: 0.8639932990074157\n",
      "Epoch 22, Iteration 160, Loss: 0.8647555530071258\n",
      "Epoch 22, Iteration 170, Loss: 0.8679696798324585\n",
      "Epoch 22, Iteration 180, Loss: 0.8724973559379577\n",
      "Epoch 22, Iteration 190, Loss: 0.8710372567176818\n",
      "Epoch 23, Iteration 0, Loss: 0.08644416332244872\n",
      "Epoch 23, Iteration 10, Loss: 0.8821660161018372\n",
      "Epoch 23, Iteration 20, Loss: 0.8880554258823394\n",
      "Epoch 23, Iteration 30, Loss: 0.8914684236049653\n",
      "Epoch 23, Iteration 40, Loss: 0.8915647506713867\n",
      "Epoch 23, Iteration 50, Loss: 0.8850395441055298\n",
      "Epoch 23, Iteration 60, Loss: 0.8795501053333282\n",
      "Epoch 23, Iteration 70, Loss: 0.8758843421936036\n",
      "Epoch 23, Iteration 80, Loss: 0.8693178474903107\n",
      "Epoch 23, Iteration 90, Loss: 0.867402994632721\n",
      "Epoch 23, Iteration 100, Loss: 0.8625297665596008\n",
      "Epoch 23, Iteration 110, Loss: 0.8594434857368469\n",
      "Epoch 23, Iteration 120, Loss: 0.8604570746421814\n",
      "Epoch 23, Iteration 130, Loss: 0.8617708206176757\n",
      "Epoch 23, Iteration 140, Loss: 0.8572877407073974\n",
      "Epoch 23, Iteration 150, Loss: 0.8599679112434387\n",
      "Epoch 23, Iteration 160, Loss: 0.8596304059028625\n",
      "Epoch 23, Iteration 170, Loss: 0.8681092262268066\n",
      "Epoch 23, Iteration 180, Loss: 0.8657913327217102\n",
      "Epoch 23, Iteration 190, Loss: 0.8687067091464996\n",
      "Epoch 24, Iteration 0, Loss: 0.08637044429779053\n",
      "Epoch 24, Iteration 10, Loss: 0.8786267757415771\n",
      "Epoch 24, Iteration 20, Loss: 0.8950150310993195\n",
      "Epoch 24, Iteration 30, Loss: 0.8938148081302643\n",
      "Epoch 24, Iteration 40, Loss: 0.8964983999729157\n",
      "Epoch 24, Iteration 50, Loss: 0.885470175743103\n",
      "Epoch 24, Iteration 60, Loss: 0.881663179397583\n",
      "Epoch 24, Iteration 70, Loss: 0.8757683157920837\n",
      "Epoch 24, Iteration 80, Loss: 0.8669657707214355\n",
      "Epoch 24, Iteration 90, Loss: 0.86565300822258\n",
      "Epoch 24, Iteration 100, Loss: 0.8638767659664154\n",
      "Epoch 24, Iteration 110, Loss: 0.8621617913246155\n",
      "Epoch 24, Iteration 120, Loss: 0.8626124262809753\n",
      "Epoch 24, Iteration 130, Loss: 0.8623650312423706\n",
      "Epoch 24, Iteration 140, Loss: 0.8616796195507049\n",
      "Epoch 24, Iteration 150, Loss: 0.8653373301029206\n",
      "Epoch 24, Iteration 160, Loss: 0.8694325685501099\n",
      "Epoch 24, Iteration 170, Loss: 0.8705073773860932\n",
      "Epoch 24, Iteration 180, Loss: 0.8718620240688324\n",
      "Epoch 24, Iteration 190, Loss: 0.8790422320365906\n",
      "Epoch 25, Iteration 0, Loss: 0.08732409477233886\n",
      "Epoch 25, Iteration 10, Loss: 0.8922050416469574\n",
      "Epoch 25, Iteration 20, Loss: 0.906284648180008\n",
      "Epoch 25, Iteration 30, Loss: 0.9116122424602509\n",
      "Epoch 25, Iteration 40, Loss: 0.9097530722618103\n",
      "Epoch 25, Iteration 50, Loss: 0.8999711632728576\n",
      "Epoch 25, Iteration 60, Loss: 0.9001969397068024\n",
      "Epoch 25, Iteration 70, Loss: 0.8907114148139954\n",
      "Epoch 25, Iteration 80, Loss: 0.887688958644867\n",
      "Epoch 25, Iteration 90, Loss: 0.8824699997901917\n",
      "Epoch 25, Iteration 100, Loss: 0.8730078160762786\n",
      "Epoch 25, Iteration 110, Loss: 0.8740022718906403\n",
      "Epoch 25, Iteration 120, Loss: 0.8707529067993164\n",
      "Epoch 25, Iteration 130, Loss: 0.869253146648407\n",
      "Epoch 25, Iteration 140, Loss: 0.8694729387760163\n",
      "Epoch 25, Iteration 150, Loss: 0.8677562177181244\n",
      "Epoch 25, Iteration 160, Loss: 0.8654205560684204\n",
      "Epoch 25, Iteration 170, Loss: 0.8700126945972443\n",
      "Epoch 25, Iteration 180, Loss: 0.871540766954422\n",
      "Epoch 25, Iteration 190, Loss: 0.8720353543758392\n",
      "Epoch 26, Iteration 0, Loss: 0.08825146555900573\n",
      "Epoch 26, Iteration 10, Loss: 0.8841930329799652\n",
      "Epoch 26, Iteration 20, Loss: 0.898223751783371\n",
      "Epoch 26, Iteration 30, Loss: 0.9001144886016845\n",
      "Epoch 26, Iteration 40, Loss: 0.8975281953811646\n",
      "Epoch 26, Iteration 50, Loss: 0.8917669653892517\n",
      "Epoch 26, Iteration 60, Loss: 0.8887916564941406\n",
      "Epoch 26, Iteration 70, Loss: 0.8833473920822144\n",
      "Epoch 26, Iteration 80, Loss: 0.8776709973812103\n",
      "Epoch 26, Iteration 90, Loss: 0.8722188353538514\n",
      "Epoch 26, Iteration 100, Loss: 0.8705069899559021\n",
      "Epoch 26, Iteration 110, Loss: 0.867768156528473\n",
      "Epoch 26, Iteration 120, Loss: 0.8641806840896606\n",
      "Epoch 26, Iteration 130, Loss: 0.8658832669258117\n",
      "Epoch 26, Iteration 140, Loss: 0.8639483153820038\n",
      "Epoch 26, Iteration 150, Loss: 0.8685316622257233\n",
      "Epoch 26, Iteration 160, Loss: 0.8696268141269684\n",
      "Epoch 26, Iteration 170, Loss: 0.8695009350776672\n",
      "Epoch 26, Iteration 180, Loss: 0.8729911327362061\n",
      "Epoch 26, Iteration 190, Loss: 0.8760931491851807\n",
      "Epoch 27, Iteration 0, Loss: 0.08758128881454467\n",
      "Epoch 27, Iteration 10, Loss: 0.8826781928539276\n",
      "Epoch 27, Iteration 20, Loss: 0.894803500175476\n",
      "Epoch 27, Iteration 30, Loss: 0.9015009939670563\n",
      "Epoch 27, Iteration 40, Loss: 0.9013773381710053\n",
      "Epoch 27, Iteration 50, Loss: 0.8925190567970276\n",
      "Epoch 27, Iteration 60, Loss: 0.8853504419326782\n",
      "Epoch 27, Iteration 70, Loss: 0.8834557294845581\n",
      "Epoch 27, Iteration 80, Loss: 0.8755703628063202\n",
      "Epoch 27, Iteration 90, Loss: 0.867311030626297\n",
      "Epoch 27, Iteration 100, Loss: 0.8700609564781189\n",
      "Epoch 27, Iteration 110, Loss: 0.8654843986034393\n",
      "Epoch 27, Iteration 120, Loss: 0.8649738967418671\n",
      "Epoch 27, Iteration 130, Loss: 0.8653932631015777\n",
      "Epoch 27, Iteration 140, Loss: 0.8654736399650573\n",
      "Epoch 27, Iteration 150, Loss: 0.860962426662445\n",
      "Epoch 27, Iteration 160, Loss: 0.8678942561149597\n",
      "Epoch 27, Iteration 170, Loss: 0.8680949449539185\n",
      "Epoch 27, Iteration 180, Loss: 0.8743605434894561\n",
      "Epoch 27, Iteration 190, Loss: 0.8759169816970825\n",
      "Epoch 28, Iteration 0, Loss: 0.08760274052619935\n",
      "Epoch 28, Iteration 10, Loss: 0.8881046295166015\n",
      "Epoch 28, Iteration 20, Loss: 0.8976979851722717\n",
      "Epoch 28, Iteration 30, Loss: 0.9006267964839936\n",
      "Epoch 28, Iteration 40, Loss: 0.897655576467514\n",
      "Epoch 28, Iteration 50, Loss: 0.8929852962493896\n",
      "Epoch 28, Iteration 60, Loss: 0.8860265195369721\n",
      "Epoch 28, Iteration 70, Loss: 0.8798597574234008\n",
      "Epoch 28, Iteration 80, Loss: 0.8730107426643372\n",
      "Epoch 28, Iteration 90, Loss: 0.87059166431427\n",
      "Epoch 28, Iteration 100, Loss: 0.8674925744533539\n",
      "Epoch 28, Iteration 110, Loss: 0.866374796628952\n",
      "Epoch 28, Iteration 120, Loss: 0.8618191719055176\n",
      "Epoch 28, Iteration 130, Loss: 0.8582812905311584\n",
      "Epoch 28, Iteration 140, Loss: 0.8623979389667511\n",
      "Epoch 28, Iteration 150, Loss: 0.8608850955963134\n",
      "Epoch 28, Iteration 160, Loss: 0.8608011126518249\n",
      "Epoch 28, Iteration 170, Loss: 0.8624906241893768\n",
      "Epoch 28, Iteration 180, Loss: 0.8629394710063935\n",
      "Epoch 28, Iteration 190, Loss: 0.8680425465106965\n",
      "Epoch 29, Iteration 0, Loss: 0.08655564188957214\n",
      "Epoch 29, Iteration 10, Loss: 0.874385929107666\n",
      "Epoch 29, Iteration 20, Loss: 0.889468914270401\n",
      "Epoch 29, Iteration 30, Loss: 0.8909783124923706\n",
      "Epoch 29, Iteration 40, Loss: 0.8915455877780915\n",
      "Epoch 29, Iteration 50, Loss: 0.8919678866863251\n",
      "Epoch 29, Iteration 60, Loss: 0.8842114448547364\n",
      "Epoch 29, Iteration 70, Loss: 0.8786263346672059\n",
      "Epoch 29, Iteration 80, Loss: 0.8730699121952057\n",
      "Epoch 29, Iteration 90, Loss: 0.8683631122112274\n",
      "Epoch 29, Iteration 100, Loss: 0.8634555280208588\n",
      "Epoch 29, Iteration 110, Loss: 0.8632416069507599\n",
      "Epoch 29, Iteration 120, Loss: 0.855469411611557\n",
      "Epoch 29, Iteration 130, Loss: 0.8570559859275818\n",
      "Epoch 29, Iteration 140, Loss: 0.8567691028118134\n",
      "Epoch 29, Iteration 150, Loss: 0.8578214704990387\n",
      "Epoch 29, Iteration 160, Loss: 0.8610435009002686\n",
      "Epoch 29, Iteration 170, Loss: 0.8637079775333405\n",
      "Epoch 29, Iteration 180, Loss: 0.8662674307823182\n",
      "Epoch 29, Iteration 190, Loss: 0.8677215933799743\n",
      "Epoch 30, Iteration 0, Loss: 0.08686391711235046\n",
      "Epoch 30, Iteration 10, Loss: 0.8790508091449738\n",
      "Epoch 30, Iteration 20, Loss: 0.8920310795307159\n",
      "Epoch 30, Iteration 30, Loss: 0.8949248671531678\n",
      "Epoch 30, Iteration 40, Loss: 0.8915786743164062\n",
      "Epoch 30, Iteration 50, Loss: 0.8878515064716339\n",
      "Epoch 30, Iteration 60, Loss: 0.8825256049633026\n",
      "Epoch 30, Iteration 70, Loss: 0.8726766884326935\n",
      "Epoch 30, Iteration 80, Loss: 0.8677560389041901\n",
      "Epoch 30, Iteration 90, Loss: 0.866771113872528\n",
      "Epoch 30, Iteration 100, Loss: 0.859854918718338\n",
      "Epoch 30, Iteration 110, Loss: 0.8579903244972229\n",
      "Epoch 30, Iteration 120, Loss: 0.8620045959949494\n",
      "Epoch 30, Iteration 130, Loss: 0.8579533517360687\n",
      "Epoch 30, Iteration 140, Loss: 0.8596284508705139\n",
      "Epoch 30, Iteration 150, Loss: 0.8596338510513306\n",
      "Epoch 30, Iteration 160, Loss: 0.864144480228424\n",
      "Epoch 30, Iteration 170, Loss: 0.8674409031867981\n",
      "Epoch 30, Iteration 180, Loss: 0.8753432512283326\n",
      "Epoch 30, Iteration 190, Loss: 0.8755226552486419\n",
      "Epoch 31, Iteration 0, Loss: 0.08697989583015442\n",
      "Epoch 31, Iteration 10, Loss: 0.8861910939216614\n",
      "Epoch 31, Iteration 20, Loss: 0.8980628669261932\n",
      "Epoch 31, Iteration 30, Loss: 0.8984556317329406\n",
      "Epoch 31, Iteration 40, Loss: 0.8950760364532471\n",
      "Epoch 31, Iteration 50, Loss: 0.8888761401176453\n",
      "Epoch 31, Iteration 60, Loss: 0.8835271418094635\n",
      "Epoch 31, Iteration 70, Loss: 0.8774898409843445\n",
      "Epoch 31, Iteration 80, Loss: 0.872606384754181\n",
      "Epoch 31, Iteration 90, Loss: 0.8717608153820038\n",
      "Epoch 31, Iteration 100, Loss: 0.8663228332996369\n",
      "Epoch 31, Iteration 110, Loss: 0.8591426312923431\n",
      "Epoch 31, Iteration 120, Loss: 0.8580979764461517\n",
      "Epoch 31, Iteration 130, Loss: 0.8604864597320556\n",
      "Epoch 31, Iteration 140, Loss: 0.8564070463180542\n",
      "Epoch 31, Iteration 150, Loss: 0.8608028650283813\n",
      "Epoch 31, Iteration 160, Loss: 0.8627733886241913\n",
      "Epoch 31, Iteration 170, Loss: 0.866141939163208\n",
      "Epoch 31, Iteration 180, Loss: 0.8674737930297851\n",
      "Epoch 31, Iteration 190, Loss: 0.8718342423439026\n",
      "Epoch 32, Iteration 0, Loss: 0.08864317536354065\n",
      "Epoch 32, Iteration 10, Loss: 0.8791323304176331\n",
      "Epoch 32, Iteration 20, Loss: 0.8885119259357452\n",
      "Epoch 32, Iteration 30, Loss: 0.8975993871688843\n",
      "Epoch 32, Iteration 40, Loss: 0.894572240114212\n",
      "Epoch 32, Iteration 50, Loss: 0.8870321750640869\n",
      "Epoch 32, Iteration 60, Loss: 0.8806809186935425\n",
      "Epoch 32, Iteration 70, Loss: 0.8763774573802948\n",
      "Epoch 32, Iteration 80, Loss: 0.8708492994308472\n",
      "Epoch 32, Iteration 90, Loss: 0.8640760362148285\n",
      "Epoch 32, Iteration 100, Loss: 0.8578308820724487\n",
      "Epoch 32, Iteration 110, Loss: 0.860890656709671\n",
      "Epoch 32, Iteration 120, Loss: 0.8573112726211548\n",
      "Epoch 32, Iteration 130, Loss: 0.8542185246944427\n",
      "Epoch 32, Iteration 140, Loss: 0.8575039446353913\n",
      "Epoch 32, Iteration 150, Loss: 0.8541870176792145\n",
      "Epoch 32, Iteration 160, Loss: 0.8599911808967591\n",
      "Epoch 32, Iteration 170, Loss: 0.8630577623844147\n",
      "Epoch 32, Iteration 180, Loss: 0.8636925518512726\n",
      "Epoch 32, Iteration 190, Loss: 0.8678131401538849\n",
      "Epoch 33, Iteration 0, Loss: 0.08751508593559265\n",
      "Epoch 33, Iteration 10, Loss: 0.8819444715976715\n",
      "Epoch 33, Iteration 20, Loss: 0.8930817723274231\n",
      "Epoch 33, Iteration 30, Loss: 0.8944069445133209\n",
      "Epoch 33, Iteration 40, Loss: 0.8927075266838074\n",
      "Epoch 33, Iteration 50, Loss: 0.8859667479991913\n",
      "Epoch 33, Iteration 60, Loss: 0.8828545093536377\n",
      "Epoch 33, Iteration 70, Loss: 0.8799903988838196\n",
      "Epoch 33, Iteration 80, Loss: 0.869702261686325\n",
      "Epoch 33, Iteration 90, Loss: 0.862172418832779\n",
      "Epoch 33, Iteration 100, Loss: 0.8589194893836976\n",
      "Epoch 33, Iteration 110, Loss: 0.8607154726982117\n",
      "Epoch 33, Iteration 120, Loss: 0.8584905624389648\n",
      "Epoch 33, Iteration 130, Loss: 0.8600091695785522\n",
      "Epoch 33, Iteration 140, Loss: 0.8597535908222198\n",
      "Epoch 33, Iteration 150, Loss: 0.8637852013111115\n",
      "Epoch 33, Iteration 160, Loss: 0.8679016053676605\n",
      "Epoch 33, Iteration 170, Loss: 0.8699065148830414\n",
      "Epoch 33, Iteration 180, Loss: 0.8745046973228454\n",
      "Epoch 33, Iteration 190, Loss: 0.877410763502121\n",
      "Epoch 34, Iteration 0, Loss: 0.08783184289932251\n",
      "Epoch 34, Iteration 10, Loss: 0.8848363339900971\n",
      "Epoch 34, Iteration 20, Loss: 0.901365327835083\n",
      "Epoch 34, Iteration 30, Loss: 0.9032299160957337\n",
      "Epoch 34, Iteration 40, Loss: 0.8970263004302979\n",
      "Epoch 34, Iteration 50, Loss: 0.8908330023288726\n",
      "Epoch 34, Iteration 60, Loss: 0.8855230689048768\n",
      "Epoch 34, Iteration 70, Loss: 0.8789499402046204\n",
      "Epoch 34, Iteration 80, Loss: 0.8724490225315094\n",
      "Epoch 34, Iteration 90, Loss: 0.8681288599967957\n",
      "Epoch 34, Iteration 100, Loss: 0.8627823472023011\n",
      "Epoch 34, Iteration 110, Loss: 0.8609925389289856\n",
      "Epoch 34, Iteration 120, Loss: 0.8598859190940857\n",
      "Epoch 34, Iteration 130, Loss: 0.8584340214729309\n",
      "Epoch 34, Iteration 140, Loss: 0.8600075125694275\n",
      "Epoch 34, Iteration 150, Loss: 0.861833918094635\n",
      "Epoch 34, Iteration 160, Loss: 0.8632055819034576\n",
      "Epoch 34, Iteration 170, Loss: 0.8664822459220887\n",
      "Epoch 34, Iteration 180, Loss: 0.8705926418304444\n",
      "Epoch 34, Iteration 190, Loss: 0.8745982587337494\n",
      "Epoch 35, Iteration 0, Loss: 0.08740132451057434\n",
      "Epoch 35, Iteration 10, Loss: 0.8814388811588287\n",
      "Epoch 35, Iteration 20, Loss: 0.8978069007396698\n",
      "Epoch 35, Iteration 30, Loss: 0.9001724004745484\n",
      "Epoch 35, Iteration 40, Loss: 0.9004919469356537\n",
      "Epoch 35, Iteration 50, Loss: 0.8911116540431976\n",
      "Epoch 35, Iteration 60, Loss: 0.8869791865348816\n",
      "Epoch 35, Iteration 70, Loss: 0.8835031628608704\n",
      "Epoch 35, Iteration 80, Loss: 0.8700094044208526\n",
      "Epoch 35, Iteration 90, Loss: 0.8696864545345306\n",
      "Epoch 35, Iteration 100, Loss: 0.8650105118751525\n",
      "Epoch 35, Iteration 110, Loss: 0.8607314586639404\n",
      "Epoch 35, Iteration 120, Loss: 0.864033579826355\n",
      "Epoch 35, Iteration 130, Loss: 0.8632905781269073\n",
      "Epoch 35, Iteration 140, Loss: 0.8615181684494019\n",
      "Epoch 35, Iteration 150, Loss: 0.8631404757499694\n",
      "Epoch 35, Iteration 160, Loss: 0.8643890380859375\n",
      "Epoch 35, Iteration 170, Loss: 0.8704768240451812\n",
      "Epoch 35, Iteration 180, Loss: 0.8717488765716552\n",
      "Epoch 35, Iteration 190, Loss: 0.8775897204875946\n",
      "Epoch 36, Iteration 0, Loss: 0.08703427910804748\n",
      "Epoch 36, Iteration 10, Loss: 0.8879275679588318\n",
      "Epoch 36, Iteration 20, Loss: 0.9025787532329559\n",
      "Epoch 36, Iteration 30, Loss: 0.9046728670597076\n",
      "Epoch 36, Iteration 40, Loss: 0.9025228500366211\n",
      "Epoch 36, Iteration 50, Loss: 0.8925703167915344\n",
      "Epoch 36, Iteration 60, Loss: 0.8883973956108093\n",
      "Epoch 36, Iteration 70, Loss: 0.88103346824646\n",
      "Epoch 36, Iteration 80, Loss: 0.8745258927345276\n",
      "Epoch 36, Iteration 90, Loss: 0.866639393568039\n",
      "Epoch 36, Iteration 100, Loss: 0.8634929835796357\n",
      "Epoch 36, Iteration 110, Loss: 0.8588612735271454\n",
      "Epoch 36, Iteration 120, Loss: 0.8564798355102539\n",
      "Epoch 36, Iteration 130, Loss: 0.8582331597805023\n",
      "Epoch 36, Iteration 140, Loss: 0.8569219529628753\n",
      "Epoch 36, Iteration 150, Loss: 0.8603642642498016\n",
      "Epoch 36, Iteration 160, Loss: 0.8626543879508972\n",
      "Epoch 36, Iteration 170, Loss: 0.8665076196193695\n",
      "Epoch 36, Iteration 180, Loss: 0.8690272688865661\n",
      "Epoch 36, Iteration 190, Loss: 0.8734268307685852\n",
      "Epoch 37, Iteration 0, Loss: 0.08767508268356324\n",
      "Epoch 37, Iteration 10, Loss: 0.8802812099456787\n",
      "Epoch 37, Iteration 20, Loss: 0.8942475378513336\n",
      "Epoch 37, Iteration 30, Loss: 0.8954012036323548\n",
      "Epoch 37, Iteration 40, Loss: 0.8966161251068115\n",
      "Epoch 37, Iteration 50, Loss: 0.896088308095932\n",
      "Epoch 37, Iteration 60, Loss: 0.8855611979961395\n",
      "Epoch 37, Iteration 70, Loss: 0.8816966354846955\n",
      "Epoch 37, Iteration 80, Loss: 0.8735740482807159\n",
      "Epoch 37, Iteration 90, Loss: 0.8694704830646515\n",
      "Epoch 37, Iteration 100, Loss: 0.8663523137569428\n",
      "Epoch 37, Iteration 110, Loss: 0.8646356582641601\n",
      "Epoch 37, Iteration 120, Loss: 0.8659651517868042\n",
      "Epoch 37, Iteration 130, Loss: 0.8622710466384887\n",
      "Epoch 37, Iteration 140, Loss: 0.8616176903247833\n",
      "Epoch 37, Iteration 150, Loss: 0.8659804463386536\n",
      "Epoch 37, Iteration 160, Loss: 0.8674734234809875\n",
      "Epoch 37, Iteration 170, Loss: 0.8714181542396545\n",
      "Epoch 37, Iteration 180, Loss: 0.8729966342449188\n",
      "Epoch 37, Iteration 190, Loss: 0.8767971634864807\n",
      "Epoch 38, Iteration 0, Loss: 0.08791427612304688\n",
      "Epoch 38, Iteration 10, Loss: 0.8869095623493195\n",
      "Epoch 38, Iteration 20, Loss: 0.901147586107254\n",
      "Epoch 38, Iteration 30, Loss: 0.9062516689300537\n",
      "Epoch 38, Iteration 40, Loss: 0.9023806869983673\n",
      "Epoch 38, Iteration 50, Loss: 0.90003302693367\n",
      "Epoch 38, Iteration 60, Loss: 0.8881357073783874\n",
      "Epoch 38, Iteration 70, Loss: 0.8856648147106171\n",
      "Epoch 38, Iteration 80, Loss: 0.881206876039505\n",
      "Epoch 38, Iteration 90, Loss: 0.8783441722393036\n",
      "Epoch 38, Iteration 100, Loss: 0.8724831402301788\n",
      "Epoch 38, Iteration 110, Loss: 0.8627552330493927\n",
      "Epoch 38, Iteration 120, Loss: 0.865934681892395\n",
      "Epoch 38, Iteration 130, Loss: 0.8642147421836853\n",
      "Epoch 38, Iteration 140, Loss: 0.8613583505153656\n",
      "Epoch 38, Iteration 150, Loss: 0.8686072289943695\n",
      "Epoch 38, Iteration 160, Loss: 0.8696058630943299\n",
      "Epoch 38, Iteration 170, Loss: 0.8688741624355316\n",
      "Epoch 38, Iteration 180, Loss: 0.8733326077461243\n",
      "Epoch 38, Iteration 190, Loss: 0.8780816316604614\n",
      "Epoch 39, Iteration 0, Loss: 0.08761911988258361\n",
      "Epoch 39, Iteration 10, Loss: 0.8908013463020324\n",
      "Epoch 39, Iteration 20, Loss: 0.9025238394737244\n",
      "Epoch 39, Iteration 30, Loss: 0.9039847254753113\n",
      "Epoch 39, Iteration 40, Loss: 0.8995438635349273\n",
      "Epoch 39, Iteration 50, Loss: 0.8975823163986206\n",
      "Epoch 39, Iteration 60, Loss: 0.8859777927398682\n",
      "Epoch 39, Iteration 70, Loss: 0.8787828683853149\n",
      "Epoch 39, Iteration 80, Loss: 0.8745471715927124\n",
      "Epoch 39, Iteration 90, Loss: 0.8688641011714935\n",
      "Epoch 39, Iteration 100, Loss: 0.8640925705432891\n",
      "Epoch 39, Iteration 110, Loss: 0.859697163105011\n",
      "Epoch 39, Iteration 120, Loss: 0.8570186018943786\n",
      "Epoch 39, Iteration 130, Loss: 0.8547113180160523\n",
      "Epoch 39, Iteration 140, Loss: 0.8564375638961792\n",
      "Epoch 39, Iteration 150, Loss: 0.8561199963092804\n",
      "Epoch 39, Iteration 160, Loss: 0.8584779262542724\n",
      "Epoch 39, Iteration 170, Loss: 0.8616916596889496\n",
      "Epoch 39, Iteration 180, Loss: 0.8643754422664642\n",
      "Epoch 39, Iteration 190, Loss: 0.8721877694129944\n",
      "Epoch 40, Iteration 0, Loss: 0.0869905948638916\n",
      "Epoch 40, Iteration 10, Loss: 0.8867208182811737\n",
      "Epoch 40, Iteration 20, Loss: 0.8985838472843171\n",
      "Epoch 40, Iteration 30, Loss: 0.9061120569705963\n",
      "Epoch 40, Iteration 40, Loss: 0.8943028509616852\n",
      "Epoch 40, Iteration 50, Loss: 0.8884062111377716\n",
      "Epoch 40, Iteration 60, Loss: 0.8918604195117951\n",
      "Epoch 40, Iteration 70, Loss: 0.8826767385005951\n",
      "Epoch 40, Iteration 80, Loss: 0.877906721830368\n",
      "Epoch 40, Iteration 90, Loss: 0.8697835981845856\n",
      "Epoch 40, Iteration 100, Loss: 0.8687148571014405\n",
      "Epoch 40, Iteration 110, Loss: 0.8658804953098297\n",
      "Epoch 40, Iteration 120, Loss: 0.8658649682998657\n",
      "Epoch 40, Iteration 130, Loss: 0.865828561782837\n",
      "Epoch 40, Iteration 140, Loss: 0.8678109467029571\n",
      "Epoch 40, Iteration 150, Loss: 0.8715272784233093\n",
      "Epoch 40, Iteration 160, Loss: 0.8686396598815918\n",
      "Epoch 40, Iteration 170, Loss: 0.8711452484130859\n",
      "Epoch 40, Iteration 180, Loss: 0.873866856098175\n",
      "Epoch 40, Iteration 190, Loss: 0.8807238340377808\n",
      "Epoch 41, Iteration 0, Loss: 0.08878202438354492\n",
      "Epoch 41, Iteration 10, Loss: 0.8904294788837432\n",
      "Epoch 41, Iteration 20, Loss: 0.9058412790298462\n",
      "Epoch 41, Iteration 30, Loss: 0.9055770635604858\n",
      "Epoch 41, Iteration 40, Loss: 0.9040297746658326\n",
      "Epoch 41, Iteration 50, Loss: 0.8994298279285431\n",
      "Epoch 41, Iteration 60, Loss: 0.8917428374290466\n",
      "Epoch 41, Iteration 70, Loss: 0.8892455101013184\n",
      "Epoch 41, Iteration 80, Loss: 0.8806597948074341\n",
      "Epoch 41, Iteration 90, Loss: 0.8794201850891114\n",
      "Epoch 41, Iteration 100, Loss: 0.871024352312088\n",
      "Epoch 41, Iteration 110, Loss: 0.8682367622852325\n",
      "Epoch 41, Iteration 120, Loss: 0.8689180374145508\n",
      "Epoch 41, Iteration 130, Loss: 0.8666823387145997\n",
      "Epoch 41, Iteration 140, Loss: 0.868576055765152\n",
      "Epoch 41, Iteration 150, Loss: 0.8697714328765869\n",
      "Epoch 41, Iteration 160, Loss: 0.8691794693470001\n",
      "Epoch 41, Iteration 170, Loss: 0.8748981833457947\n",
      "Epoch 41, Iteration 180, Loss: 0.8779474377632142\n",
      "Epoch 41, Iteration 190, Loss: 0.8797080338001251\n",
      "Epoch 42, Iteration 0, Loss: 0.08836517333984376\n",
      "Epoch 42, Iteration 10, Loss: 0.8870844066143035\n",
      "Epoch 42, Iteration 20, Loss: 0.9036251962184906\n",
      "Epoch 42, Iteration 30, Loss: 0.9049943804740905\n",
      "Epoch 42, Iteration 40, Loss: 0.9001247823238373\n",
      "Epoch 42, Iteration 50, Loss: 0.890947163105011\n",
      "Epoch 42, Iteration 60, Loss: 0.8852910935878754\n",
      "Epoch 42, Iteration 70, Loss: 0.8780710577964783\n",
      "Epoch 42, Iteration 80, Loss: 0.8753908514976502\n",
      "Epoch 42, Iteration 90, Loss: 0.8662896394729614\n",
      "Epoch 42, Iteration 100, Loss: 0.8611981928348541\n",
      "Epoch 42, Iteration 110, Loss: 0.8574737489223481\n",
      "Epoch 42, Iteration 120, Loss: 0.8599489808082581\n",
      "Epoch 42, Iteration 130, Loss: 0.8585415363311768\n",
      "Epoch 42, Iteration 140, Loss: 0.8564400553703309\n",
      "Epoch 42, Iteration 150, Loss: 0.8625588774681091\n",
      "Epoch 42, Iteration 160, Loss: 0.8611100912094116\n",
      "Epoch 42, Iteration 170, Loss: 0.8637225449085235\n",
      "Epoch 42, Iteration 180, Loss: 0.872703742980957\n",
      "Epoch 42, Iteration 190, Loss: 0.872891753911972\n",
      "Epoch 43, Iteration 0, Loss: 0.08761628270149231\n",
      "Epoch 43, Iteration 10, Loss: 0.8834802448749542\n",
      "Epoch 43, Iteration 20, Loss: 0.8981584072113037\n",
      "Epoch 43, Iteration 30, Loss: 0.9028922975063324\n",
      "Epoch 43, Iteration 40, Loss: 0.89963698387146\n",
      "Epoch 43, Iteration 50, Loss: 0.8943069398403167\n",
      "Epoch 43, Iteration 60, Loss: 0.8861097753047943\n",
      "Epoch 43, Iteration 70, Loss: 0.8827990651130676\n",
      "Epoch 43, Iteration 80, Loss: 0.8754066586494446\n",
      "Epoch 43, Iteration 90, Loss: 0.8716077685356141\n",
      "Epoch 43, Iteration 100, Loss: 0.8664826273918151\n",
      "Epoch 43, Iteration 110, Loss: 0.8679376006126404\n",
      "Epoch 43, Iteration 120, Loss: 0.8609924197196961\n",
      "Epoch 43, Iteration 130, Loss: 0.8592230439186096\n",
      "Epoch 43, Iteration 140, Loss: 0.8595102429389954\n",
      "Epoch 43, Iteration 150, Loss: 0.8612598419189453\n",
      "Epoch 43, Iteration 160, Loss: 0.8680835723876953\n",
      "Epoch 43, Iteration 170, Loss: 0.8712266504764556\n",
      "Epoch 43, Iteration 180, Loss: 0.8716064453125\n",
      "Epoch 43, Iteration 190, Loss: 0.879741495847702\n",
      "Epoch 44, Iteration 0, Loss: 0.08733128905296325\n",
      "Epoch 44, Iteration 10, Loss: 0.8889330267906189\n",
      "Epoch 44, Iteration 20, Loss: 0.9043371558189393\n",
      "Epoch 44, Iteration 30, Loss: 0.9063733220100403\n",
      "Epoch 44, Iteration 40, Loss: 0.9011170983314514\n",
      "Epoch 44, Iteration 50, Loss: 0.8948104202747345\n",
      "Epoch 44, Iteration 60, Loss: 0.8919335186481476\n",
      "Epoch 44, Iteration 70, Loss: 0.886286610364914\n",
      "Epoch 44, Iteration 80, Loss: 0.8793009757995606\n",
      "Epoch 44, Iteration 90, Loss: 0.8757628738880158\n",
      "Epoch 44, Iteration 100, Loss: 0.8691092789173126\n",
      "Epoch 44, Iteration 110, Loss: 0.8671562850475312\n",
      "Epoch 44, Iteration 120, Loss: 0.8697685241699219\n",
      "Epoch 44, Iteration 130, Loss: 0.8703451454639435\n",
      "Epoch 44, Iteration 140, Loss: 0.8713692009449006\n",
      "Epoch 44, Iteration 150, Loss: 0.8752866506576538\n",
      "Epoch 44, Iteration 160, Loss: 0.8788077294826507\n",
      "Epoch 44, Iteration 170, Loss: 0.8785113513469696\n",
      "Epoch 44, Iteration 180, Loss: 0.8841201007366181\n",
      "Epoch 44, Iteration 190, Loss: 0.892103910446167\n",
      "Epoch 45, Iteration 0, Loss: 0.0893411636352539\n",
      "Epoch 45, Iteration 10, Loss: 0.904384869337082\n",
      "Epoch 45, Iteration 20, Loss: 0.9100203156471253\n",
      "Epoch 45, Iteration 30, Loss: 0.9183954060077667\n",
      "Epoch 45, Iteration 40, Loss: 0.9126069247722626\n",
      "Epoch 45, Iteration 50, Loss: 0.9045375406742096\n",
      "Epoch 45, Iteration 60, Loss: 0.9030045211315155\n",
      "Epoch 45, Iteration 70, Loss: 0.8976053535938263\n",
      "Epoch 45, Iteration 80, Loss: 0.8865895390510559\n",
      "Epoch 45, Iteration 90, Loss: 0.8814637243747712\n",
      "Epoch 45, Iteration 100, Loss: 0.8791944563388825\n",
      "Epoch 45, Iteration 110, Loss: 0.8773328721523285\n",
      "Epoch 45, Iteration 120, Loss: 0.869448471069336\n",
      "Epoch 45, Iteration 130, Loss: 0.8705103158950805\n",
      "Epoch 45, Iteration 140, Loss: 0.8719939827919007\n",
      "Epoch 45, Iteration 150, Loss: 0.8730712831020355\n",
      "Epoch 45, Iteration 160, Loss: 0.8741808712482453\n",
      "Epoch 45, Iteration 170, Loss: 0.8734297275543212\n",
      "Epoch 45, Iteration 180, Loss: 0.8754869878292084\n",
      "Epoch 45, Iteration 190, Loss: 0.8792790651321412\n",
      "Epoch 46, Iteration 0, Loss: 0.08771196603775025\n",
      "Epoch 46, Iteration 10, Loss: 0.8935546040534973\n",
      "Epoch 46, Iteration 20, Loss: 0.9030244529247284\n",
      "Epoch 46, Iteration 30, Loss: 0.90563063621521\n",
      "Epoch 46, Iteration 40, Loss: 0.903871214389801\n",
      "Epoch 46, Iteration 50, Loss: 0.8917540073394775\n",
      "Epoch 46, Iteration 60, Loss: 0.8894733607769012\n",
      "Epoch 46, Iteration 70, Loss: 0.8829229831695556\n",
      "Epoch 46, Iteration 80, Loss: 0.8799031436443329\n",
      "Epoch 46, Iteration 90, Loss: 0.8752457857131958\n",
      "Epoch 46, Iteration 100, Loss: 0.8717778205871582\n",
      "Epoch 46, Iteration 110, Loss: 0.8673212349414825\n",
      "Epoch 46, Iteration 120, Loss: 0.8672832608222961\n",
      "Epoch 46, Iteration 130, Loss: 0.8648024141788483\n",
      "Epoch 46, Iteration 140, Loss: 0.8693752944469452\n",
      "Epoch 46, Iteration 150, Loss: 0.8687337636947632\n",
      "Epoch 46, Iteration 160, Loss: 0.8689116179943085\n",
      "Epoch 46, Iteration 170, Loss: 0.8717439353466034\n",
      "Epoch 46, Iteration 180, Loss: 0.8724937796592712\n",
      "Epoch 46, Iteration 190, Loss: 0.8792307853698731\n",
      "Epoch 47, Iteration 0, Loss: 0.08745841979980469\n",
      "Epoch 47, Iteration 10, Loss: 0.8879275262355805\n",
      "Epoch 47, Iteration 20, Loss: 0.9019937455654145\n",
      "Epoch 47, Iteration 30, Loss: 0.9072722733020783\n",
      "Epoch 47, Iteration 40, Loss: 0.8971028327941895\n",
      "Epoch 47, Iteration 50, Loss: 0.8950510680675506\n",
      "Epoch 47, Iteration 60, Loss: 0.8888482034206391\n",
      "Epoch 47, Iteration 70, Loss: 0.8839085042476654\n",
      "Epoch 47, Iteration 80, Loss: 0.8764475643634796\n",
      "Epoch 47, Iteration 90, Loss: 0.8710666716098785\n",
      "Epoch 47, Iteration 100, Loss: 0.8697364509105683\n",
      "Epoch 47, Iteration 110, Loss: 0.8713980317115784\n",
      "Epoch 47, Iteration 120, Loss: 0.863988173007965\n",
      "Epoch 47, Iteration 130, Loss: 0.86538947224617\n",
      "Epoch 47, Iteration 140, Loss: 0.8683197736740113\n",
      "Epoch 47, Iteration 150, Loss: 0.86798597574234\n",
      "Epoch 47, Iteration 160, Loss: 0.8728223145008087\n",
      "Epoch 47, Iteration 170, Loss: 0.8774784743785858\n",
      "Epoch 47, Iteration 180, Loss: 0.8843150556087493\n",
      "Epoch 47, Iteration 190, Loss: 0.8842207670211792\n",
      "Epoch 48, Iteration 0, Loss: 0.0903356909751892\n",
      "Epoch 48, Iteration 10, Loss: 0.9020313382148742\n",
      "Epoch 48, Iteration 20, Loss: 0.9181913256645202\n",
      "Epoch 48, Iteration 30, Loss: 0.9226131737232208\n",
      "Epoch 48, Iteration 40, Loss: 0.9182449102401733\n",
      "Epoch 48, Iteration 50, Loss: 0.9180661797523498\n",
      "Epoch 48, Iteration 60, Loss: 0.9069988489151001\n",
      "Epoch 48, Iteration 70, Loss: 0.8983450829982758\n",
      "Epoch 48, Iteration 80, Loss: 0.8905131876468658\n",
      "Epoch 48, Iteration 90, Loss: 0.8826979517936706\n",
      "Epoch 48, Iteration 100, Loss: 0.8779644429683685\n",
      "Epoch 48, Iteration 110, Loss: 0.8783998847007751\n",
      "Epoch 48, Iteration 120, Loss: 0.8733565211296082\n",
      "Epoch 48, Iteration 130, Loss: 0.8715249717235565\n",
      "Epoch 48, Iteration 140, Loss: 0.8694559037685394\n",
      "Epoch 48, Iteration 150, Loss: 0.8712930560112\n",
      "Epoch 48, Iteration 160, Loss: 0.8734904766082764\n",
      "Epoch 48, Iteration 170, Loss: 0.875559949874878\n",
      "Epoch 48, Iteration 180, Loss: 0.8772659003734589\n",
      "Epoch 48, Iteration 190, Loss: 0.8832209527492523\n",
      "Epoch 49, Iteration 0, Loss: 0.08921396136283874\n",
      "Epoch 49, Iteration 10, Loss: 0.8978139579296112\n",
      "Epoch 49, Iteration 20, Loss: 0.9055632412433624\n",
      "Epoch 49, Iteration 30, Loss: 0.9075529158115387\n",
      "Epoch 49, Iteration 40, Loss: 0.902532309293747\n",
      "Epoch 49, Iteration 50, Loss: 0.9011888682842255\n",
      "Epoch 49, Iteration 60, Loss: 0.8992592871189118\n",
      "Epoch 49, Iteration 70, Loss: 0.8904214382171631\n",
      "Epoch 49, Iteration 80, Loss: 0.8852768123149872\n",
      "Epoch 49, Iteration 90, Loss: 0.8781783044338226\n",
      "Epoch 49, Iteration 100, Loss: 0.872033542394638\n",
      "Epoch 49, Iteration 110, Loss: 0.8687395274639129\n",
      "Epoch 49, Iteration 120, Loss: 0.8679902613162994\n",
      "Epoch 49, Iteration 130, Loss: 0.8650932788848877\n",
      "Epoch 49, Iteration 140, Loss: 0.8644162476062774\n",
      "Epoch 49, Iteration 150, Loss: 0.8669328033924103\n",
      "Epoch 49, Iteration 160, Loss: 0.8653896391391754\n",
      "Epoch 49, Iteration 170, Loss: 0.8722240269184113\n",
      "Epoch 49, Iteration 180, Loss: 0.8737702667713165\n",
      "Epoch 49, Iteration 190, Loss: 0.8757268011569976\n",
      "Epoch 50, Iteration 0, Loss: 0.0876248836517334\n",
      "Epoch 50, Iteration 10, Loss: 0.8906800925731659\n",
      "Epoch 50, Iteration 20, Loss: 0.9012952387332916\n",
      "Epoch 50, Iteration 30, Loss: 0.9061472952365875\n",
      "Epoch 50, Iteration 40, Loss: 0.9067225337028504\n",
      "Epoch 50, Iteration 50, Loss: 0.9009385287761689\n",
      "Epoch 50, Iteration 60, Loss: 0.8954545021057129\n",
      "Epoch 50, Iteration 70, Loss: 0.8936623394489288\n",
      "Epoch 50, Iteration 80, Loss: 0.8887609124183655\n",
      "Epoch 50, Iteration 90, Loss: 0.8817103803157806\n",
      "Epoch 50, Iteration 100, Loss: 0.8754320800304413\n",
      "Epoch 50, Iteration 110, Loss: 0.8771653294563293\n",
      "Epoch 50, Iteration 120, Loss: 0.8751652181148529\n",
      "Epoch 50, Iteration 130, Loss: 0.8766521394252778\n",
      "Epoch 50, Iteration 140, Loss: 0.87541965842247\n",
      "Epoch 50, Iteration 150, Loss: 0.8735088229179382\n",
      "Epoch 50, Iteration 160, Loss: 0.874823659658432\n",
      "Epoch 50, Iteration 170, Loss: 0.8810255467891693\n",
      "Epoch 50, Iteration 180, Loss: 0.886251586675644\n",
      "Epoch 50, Iteration 190, Loss: 0.8885480701923371\n",
      "Epoch 51, Iteration 0, Loss: 0.0904579758644104\n",
      "Epoch 51, Iteration 10, Loss: 0.9003412663936615\n",
      "Epoch 51, Iteration 20, Loss: 0.9157001912593842\n",
      "Epoch 51, Iteration 30, Loss: 0.9101013541221619\n",
      "Epoch 51, Iteration 40, Loss: 0.9135674953460693\n",
      "Epoch 51, Iteration 50, Loss: 0.9048318862915039\n",
      "Epoch 51, Iteration 60, Loss: 0.8959044873714447\n",
      "Epoch 51, Iteration 70, Loss: 0.8913404107093811\n",
      "Epoch 51, Iteration 80, Loss: 0.8890698969364166\n",
      "Epoch 51, Iteration 90, Loss: 0.8755698084831238\n",
      "Epoch 51, Iteration 100, Loss: 0.875994873046875\n",
      "Epoch 51, Iteration 110, Loss: 0.8718916654586792\n",
      "Epoch 51, Iteration 120, Loss: 0.8705704212188721\n",
      "Epoch 51, Iteration 130, Loss: 0.8685995697975158\n",
      "Epoch 51, Iteration 140, Loss: 0.8725223541259766\n",
      "Epoch 51, Iteration 150, Loss: 0.8727697551250457\n",
      "Epoch 51, Iteration 160, Loss: 0.8729906022548676\n",
      "Epoch 51, Iteration 170, Loss: 0.8747929334640503\n",
      "Epoch 51, Iteration 180, Loss: 0.8807140111923217\n",
      "Epoch 51, Iteration 190, Loss: 0.8839707791805267\n",
      "Epoch 52, Iteration 0, Loss: 0.08772757053375244\n",
      "Epoch 52, Iteration 10, Loss: 0.8931304156780243\n",
      "Epoch 52, Iteration 20, Loss: 0.9079281270503998\n",
      "Epoch 52, Iteration 30, Loss: 0.9117245018482208\n",
      "Epoch 52, Iteration 40, Loss: 0.9120864570140839\n",
      "Epoch 52, Iteration 50, Loss: 0.9039421141147613\n",
      "Epoch 52, Iteration 60, Loss: 0.9009957611560822\n",
      "Epoch 52, Iteration 70, Loss: 0.8922210931777954\n",
      "Epoch 52, Iteration 80, Loss: 0.8886097550392151\n",
      "Epoch 52, Iteration 90, Loss: 0.8819452106952668\n",
      "Epoch 52, Iteration 100, Loss: 0.8769264280796051\n",
      "Epoch 52, Iteration 110, Loss: 0.8734632134437561\n",
      "Epoch 52, Iteration 120, Loss: 0.872868001461029\n",
      "Epoch 52, Iteration 130, Loss: 0.8727680921554566\n",
      "Epoch 52, Iteration 140, Loss: 0.8712245285511017\n",
      "Epoch 52, Iteration 150, Loss: 0.8689812541007995\n",
      "Epoch 52, Iteration 160, Loss: 0.8682576775550842\n",
      "Epoch 52, Iteration 170, Loss: 0.8739100515842437\n",
      "Epoch 52, Iteration 180, Loss: 0.87498340010643\n",
      "Epoch 52, Iteration 190, Loss: 0.8722915768623352\n",
      "Epoch 53, Iteration 0, Loss: 0.08807294964790344\n",
      "Epoch 53, Iteration 10, Loss: 0.8861894130706787\n",
      "Epoch 53, Iteration 20, Loss: 0.900687038898468\n",
      "Epoch 53, Iteration 30, Loss: 0.9023126602172852\n",
      "Epoch 53, Iteration 40, Loss: 0.898388934135437\n",
      "Epoch 53, Iteration 50, Loss: 0.8968835771083832\n",
      "Epoch 53, Iteration 60, Loss: 0.8924326181411744\n",
      "Epoch 53, Iteration 70, Loss: 0.8848630309104919\n",
      "Epoch 53, Iteration 80, Loss: 0.8796617448329925\n",
      "Epoch 53, Iteration 90, Loss: 0.8797272622585297\n",
      "Epoch 53, Iteration 100, Loss: 0.8722926497459411\n",
      "Epoch 53, Iteration 110, Loss: 0.8678670465946198\n",
      "Epoch 53, Iteration 120, Loss: 0.8705582916736603\n",
      "Epoch 53, Iteration 130, Loss: 0.8724277377128601\n",
      "Epoch 53, Iteration 140, Loss: 0.8702313959598541\n",
      "Epoch 53, Iteration 150, Loss: 0.8754082679748535\n",
      "Epoch 53, Iteration 160, Loss: 0.8752966046333313\n",
      "Epoch 53, Iteration 170, Loss: 0.8769999563694\n",
      "Epoch 53, Iteration 180, Loss: 0.8750748455524444\n",
      "Epoch 53, Iteration 190, Loss: 0.8856675267219544\n",
      "Epoch 54, Iteration 0, Loss: 0.08835780024528503\n",
      "Epoch 54, Iteration 10, Loss: 0.8909158408641815\n",
      "Epoch 54, Iteration 20, Loss: 0.9035363316535949\n",
      "Epoch 54, Iteration 30, Loss: 0.912013828754425\n",
      "Epoch 54, Iteration 40, Loss: 0.89977987408638\n",
      "Epoch 54, Iteration 50, Loss: 0.8965270817279816\n",
      "Epoch 54, Iteration 60, Loss: 0.8940079748630524\n",
      "Epoch 54, Iteration 70, Loss: 0.8877241373062134\n",
      "Epoch 54, Iteration 80, Loss: 0.8847932457923889\n",
      "Epoch 54, Iteration 90, Loss: 0.8770985305309296\n",
      "Epoch 54, Iteration 100, Loss: 0.8728505432605743\n",
      "Epoch 54, Iteration 110, Loss: 0.8699900865554809\n",
      "Epoch 54, Iteration 120, Loss: 0.8699386417865753\n",
      "Epoch 54, Iteration 130, Loss: 0.8689723908901215\n",
      "Epoch 54, Iteration 140, Loss: 0.8675743818283081\n",
      "Epoch 54, Iteration 150, Loss: 0.866966700553894\n",
      "Epoch 54, Iteration 160, Loss: 0.8697453796863556\n",
      "Epoch 54, Iteration 170, Loss: 0.8711568593978882\n",
      "Epoch 54, Iteration 180, Loss: 0.8722804188728333\n",
      "Epoch 54, Iteration 190, Loss: 0.875468498468399\n",
      "Epoch 55, Iteration 0, Loss: 0.08834373354911804\n",
      "Epoch 55, Iteration 10, Loss: 0.8815785467624664\n",
      "Epoch 55, Iteration 20, Loss: 0.8904032349586487\n",
      "Epoch 55, Iteration 30, Loss: 0.8945929288864136\n",
      "Epoch 55, Iteration 40, Loss: 0.8940042078495025\n",
      "Epoch 55, Iteration 50, Loss: 0.88790442943573\n",
      "Epoch 55, Iteration 60, Loss: 0.8811798512935638\n",
      "Epoch 55, Iteration 70, Loss: 0.8748795628547669\n",
      "Epoch 55, Iteration 80, Loss: 0.8729011952877045\n",
      "Epoch 55, Iteration 90, Loss: 0.8642307698726654\n",
      "Epoch 55, Iteration 100, Loss: 0.864504611492157\n",
      "Epoch 55, Iteration 110, Loss: 0.8641823410987854\n",
      "Epoch 55, Iteration 120, Loss: 0.8610712230205536\n",
      "Epoch 55, Iteration 130, Loss: 0.8648843109607697\n",
      "Epoch 55, Iteration 140, Loss: 0.8689628839492798\n",
      "Epoch 55, Iteration 150, Loss: 0.8661213696002961\n",
      "Epoch 55, Iteration 160, Loss: 0.8669424951076508\n",
      "Epoch 55, Iteration 170, Loss: 0.873018103837967\n",
      "Epoch 55, Iteration 180, Loss: 0.8747478902339936\n",
      "Epoch 55, Iteration 190, Loss: 0.8784929513931274\n",
      "Epoch 56, Iteration 0, Loss: 0.08842723369598389\n",
      "Epoch 56, Iteration 10, Loss: 0.8889760673046112\n",
      "Epoch 56, Iteration 20, Loss: 0.896856027841568\n",
      "Epoch 56, Iteration 30, Loss: 0.9036506235599517\n",
      "Epoch 56, Iteration 40, Loss: 0.898012226819992\n",
      "Epoch 56, Iteration 50, Loss: 0.8915296971797944\n",
      "Epoch 56, Iteration 60, Loss: 0.8818172097206116\n",
      "Epoch 56, Iteration 70, Loss: 0.8726356089115143\n",
      "Epoch 56, Iteration 80, Loss: 0.8705922365188599\n",
      "Epoch 56, Iteration 90, Loss: 0.8645052254199982\n",
      "Epoch 56, Iteration 100, Loss: 0.8585097849369049\n",
      "Epoch 56, Iteration 110, Loss: 0.8587291002273559\n",
      "Epoch 56, Iteration 120, Loss: 0.857311737537384\n",
      "Epoch 56, Iteration 130, Loss: 0.8588546812534332\n",
      "Epoch 56, Iteration 140, Loss: 0.8607828378677368\n",
      "Epoch 56, Iteration 150, Loss: 0.8584123015403747\n",
      "Epoch 56, Iteration 160, Loss: 0.8622975468635559\n",
      "Epoch 56, Iteration 170, Loss: 0.8667216002941132\n",
      "Epoch 56, Iteration 180, Loss: 0.870730710029602\n",
      "Epoch 56, Iteration 190, Loss: 0.873852264881134\n",
      "Epoch 57, Iteration 0, Loss: 0.08662972450256348\n",
      "Epoch 57, Iteration 10, Loss: 0.8868335247039795\n",
      "Epoch 57, Iteration 20, Loss: 0.9010194838047028\n",
      "Epoch 57, Iteration 30, Loss: 0.89994598031044\n",
      "Epoch 57, Iteration 40, Loss: 0.8956926584243774\n",
      "Epoch 57, Iteration 50, Loss: 0.8930581092834473\n",
      "Epoch 57, Iteration 60, Loss: 0.8895957708358765\n",
      "Epoch 57, Iteration 70, Loss: 0.8798996150493622\n",
      "Epoch 57, Iteration 80, Loss: 0.8771468281745911\n",
      "Epoch 57, Iteration 90, Loss: 0.8753411889076232\n",
      "Epoch 57, Iteration 100, Loss: 0.868852162361145\n",
      "Epoch 57, Iteration 110, Loss: 0.8638343691825867\n",
      "Epoch 57, Iteration 120, Loss: 0.8637500464916229\n",
      "Epoch 57, Iteration 130, Loss: 0.8622620701789856\n",
      "Epoch 57, Iteration 140, Loss: 0.8595466613769531\n",
      "Epoch 57, Iteration 150, Loss: 0.8661404192447663\n",
      "Epoch 57, Iteration 160, Loss: 0.8690602242946625\n",
      "Epoch 57, Iteration 170, Loss: 0.8698752701282502\n",
      "Epoch 57, Iteration 180, Loss: 0.8731582999229431\n",
      "Epoch 57, Iteration 190, Loss: 0.87380810379982\n",
      "Epoch 58, Iteration 0, Loss: 0.08829318284988404\n",
      "Epoch 58, Iteration 10, Loss: 0.8869842529296875\n",
      "Epoch 58, Iteration 20, Loss: 0.9010609686374664\n",
      "Epoch 58, Iteration 30, Loss: 0.8983654379844666\n",
      "Epoch 58, Iteration 40, Loss: 0.897619777917862\n",
      "Epoch 58, Iteration 50, Loss: 0.8890352547168732\n",
      "Epoch 58, Iteration 60, Loss: 0.8836357533931732\n",
      "Epoch 58, Iteration 70, Loss: 0.877251124382019\n",
      "Epoch 58, Iteration 80, Loss: 0.8751959860324859\n",
      "Epoch 58, Iteration 90, Loss: 0.8657286763191223\n",
      "Epoch 58, Iteration 100, Loss: 0.8633558511734009\n",
      "Epoch 58, Iteration 110, Loss: 0.8592269718647003\n",
      "Epoch 58, Iteration 120, Loss: 0.863056743144989\n",
      "Epoch 58, Iteration 130, Loss: 0.8629064559936523\n",
      "Epoch 58, Iteration 140, Loss: 0.8641673564910889\n",
      "Epoch 58, Iteration 150, Loss: 0.8630117177963257\n",
      "Epoch 58, Iteration 160, Loss: 0.8621797859668732\n",
      "Epoch 58, Iteration 170, Loss: 0.8644138753414154\n",
      "Epoch 58, Iteration 180, Loss: 0.8706745386123658\n",
      "Epoch 58, Iteration 190, Loss: 0.8746012210845947\n",
      "Epoch 59, Iteration 0, Loss: 0.08678454160690308\n",
      "Epoch 59, Iteration 10, Loss: 0.8845322132110596\n",
      "Epoch 59, Iteration 20, Loss: 0.8935341835021973\n",
      "Epoch 59, Iteration 30, Loss: 0.8967940032482147\n",
      "Epoch 59, Iteration 40, Loss: 0.8969213008880615\n",
      "Epoch 59, Iteration 50, Loss: 0.8919957995414733\n",
      "Epoch 59, Iteration 60, Loss: 0.8812632501125336\n",
      "Epoch 59, Iteration 70, Loss: 0.8771984457969666\n",
      "Epoch 59, Iteration 80, Loss: 0.8665231883525848\n",
      "Epoch 59, Iteration 90, Loss: 0.8673186838626862\n",
      "Epoch 59, Iteration 100, Loss: 0.8632995843887329\n",
      "Epoch 59, Iteration 110, Loss: 0.8606857001781464\n",
      "Epoch 59, Iteration 120, Loss: 0.8579470396041871\n",
      "Epoch 59, Iteration 130, Loss: 0.855923718214035\n",
      "Epoch 59, Iteration 140, Loss: 0.8582429349422455\n",
      "Epoch 59, Iteration 150, Loss: 0.8586214482784271\n",
      "Epoch 59, Iteration 160, Loss: 0.861690080165863\n",
      "Epoch 59, Iteration 170, Loss: 0.866266256570816\n",
      "Epoch 59, Iteration 180, Loss: 0.8705294132232666\n",
      "Epoch 59, Iteration 190, Loss: 0.8754306375980377\n",
      "Epoch 60, Iteration 0, Loss: 0.08766908049583436\n",
      "Epoch 60, Iteration 10, Loss: 0.8864274322986603\n",
      "Epoch 60, Iteration 20, Loss: 0.9012161791324615\n",
      "Epoch 60, Iteration 30, Loss: 0.9040552496910095\n",
      "Epoch 60, Iteration 40, Loss: 0.898995327949524\n",
      "Epoch 60, Iteration 50, Loss: 0.8948764324188232\n",
      "Epoch 60, Iteration 60, Loss: 0.889746081829071\n",
      "Epoch 60, Iteration 70, Loss: 0.8830990850925445\n",
      "Epoch 60, Iteration 80, Loss: 0.8768080532550812\n",
      "Epoch 60, Iteration 90, Loss: 0.8723637342453003\n",
      "Epoch 60, Iteration 100, Loss: 0.8660686850547791\n",
      "Epoch 60, Iteration 110, Loss: 0.8669463872909546\n",
      "Epoch 60, Iteration 120, Loss: 0.8597543597221374\n",
      "Epoch 60, Iteration 130, Loss: 0.8635734736919403\n",
      "Epoch 60, Iteration 140, Loss: 0.8626657009124756\n",
      "Epoch 60, Iteration 150, Loss: 0.8626522898674012\n",
      "Epoch 60, Iteration 160, Loss: 0.8692418456077575\n",
      "Epoch 60, Iteration 170, Loss: 0.8691033840179443\n",
      "Epoch 60, Iteration 180, Loss: 0.8732209980487824\n",
      "Epoch 60, Iteration 190, Loss: 0.8820753335952759\n",
      "Epoch 61, Iteration 0, Loss: 0.08748079538345337\n",
      "Epoch 61, Iteration 10, Loss: 0.8928952932357788\n",
      "Epoch 61, Iteration 20, Loss: 0.9053077936172486\n",
      "Epoch 61, Iteration 30, Loss: 0.9080702304840088\n",
      "Epoch 61, Iteration 40, Loss: 0.9029790699481964\n",
      "Epoch 61, Iteration 50, Loss: 0.8964082479476929\n",
      "Epoch 61, Iteration 60, Loss: 0.89381844997406\n",
      "Epoch 61, Iteration 70, Loss: 0.8868003010749816\n",
      "Epoch 61, Iteration 80, Loss: 0.8831675350666046\n",
      "Epoch 61, Iteration 90, Loss: 0.8749545276165008\n",
      "Epoch 61, Iteration 100, Loss: 0.8766364455223083\n",
      "Epoch 61, Iteration 110, Loss: 0.8681452870368958\n",
      "Epoch 61, Iteration 120, Loss: 0.8709970712661743\n",
      "Epoch 61, Iteration 130, Loss: 0.8710926592350006\n",
      "Epoch 61, Iteration 140, Loss: 0.8722848355770111\n",
      "Epoch 61, Iteration 150, Loss: 0.8731791973114014\n",
      "Epoch 61, Iteration 160, Loss: 0.8751781702041626\n",
      "Epoch 61, Iteration 170, Loss: 0.8782222747802735\n",
      "Epoch 61, Iteration 180, Loss: 0.8816298604011535\n",
      "Epoch 61, Iteration 190, Loss: 0.8884006381034851\n",
      "Epoch 62, Iteration 0, Loss: 0.08979498744010925\n",
      "Epoch 62, Iteration 10, Loss: 0.9048034846782684\n",
      "Epoch 62, Iteration 20, Loss: 0.9142823994159699\n",
      "Epoch 62, Iteration 30, Loss: 0.9179737508296967\n",
      "Epoch 62, Iteration 40, Loss: 0.9160879969596862\n",
      "Epoch 62, Iteration 50, Loss: 0.9124184131622315\n",
      "Epoch 62, Iteration 60, Loss: 0.905976402759552\n",
      "Epoch 62, Iteration 70, Loss: 0.9018316924571991\n",
      "Epoch 62, Iteration 80, Loss: 0.8939690053462982\n",
      "Epoch 62, Iteration 90, Loss: 0.8917362689971924\n",
      "Epoch 62, Iteration 100, Loss: 0.8829800486564636\n",
      "Epoch 62, Iteration 110, Loss: 0.8868711650371551\n",
      "Epoch 62, Iteration 120, Loss: 0.883396852016449\n",
      "Epoch 62, Iteration 130, Loss: 0.876663213968277\n",
      "Epoch 62, Iteration 140, Loss: 0.8834833562374115\n",
      "Epoch 62, Iteration 150, Loss: 0.8832184910774231\n",
      "Epoch 62, Iteration 160, Loss: 0.8879387438297272\n",
      "Epoch 62, Iteration 170, Loss: 0.8892978549003601\n",
      "Epoch 62, Iteration 180, Loss: 0.8885734856128693\n",
      "Epoch 62, Iteration 190, Loss: 0.8930796205997467\n",
      "Epoch 63, Iteration 0, Loss: 0.08940338492393493\n",
      "Epoch 63, Iteration 10, Loss: 0.904387378692627\n",
      "Epoch 63, Iteration 20, Loss: 0.9206831216812134\n",
      "Epoch 63, Iteration 30, Loss: 0.9204971551895141\n",
      "Epoch 63, Iteration 40, Loss: 0.9149078905582428\n",
      "Epoch 63, Iteration 50, Loss: 0.9070764899253845\n",
      "Epoch 63, Iteration 60, Loss: 0.9068883836269379\n",
      "Epoch 63, Iteration 70, Loss: 0.8948034703731537\n",
      "Epoch 63, Iteration 80, Loss: 0.8880698204040527\n",
      "Epoch 63, Iteration 90, Loss: 0.8840520560741425\n",
      "Epoch 63, Iteration 100, Loss: 0.8822808027267456\n",
      "Epoch 63, Iteration 110, Loss: 0.8783550083637237\n",
      "Epoch 63, Iteration 120, Loss: 0.8770353972911835\n",
      "Epoch 63, Iteration 130, Loss: 0.8742529153823853\n",
      "Epoch 63, Iteration 140, Loss: 0.8741541802883148\n",
      "Epoch 63, Iteration 150, Loss: 0.8726097881793976\n",
      "Epoch 63, Iteration 160, Loss: 0.8786345958709717\n",
      "Epoch 63, Iteration 170, Loss: 0.8810388028621674\n",
      "Epoch 63, Iteration 180, Loss: 0.8853915989398956\n",
      "Epoch 63, Iteration 190, Loss: 0.8866794884204865\n",
      "Epoch 64, Iteration 0, Loss: 0.08768920302391052\n",
      "Epoch 64, Iteration 10, Loss: 0.8983675360679626\n",
      "Epoch 64, Iteration 20, Loss: 0.9158277213573456\n",
      "Epoch 64, Iteration 30, Loss: 0.9178483247756958\n",
      "Epoch 64, Iteration 40, Loss: 0.91232670545578\n",
      "Epoch 64, Iteration 50, Loss: 0.9032094776630402\n",
      "Epoch 64, Iteration 60, Loss: 0.9018999338150024\n",
      "Epoch 64, Iteration 70, Loss: 0.8954663634300232\n",
      "Epoch 64, Iteration 80, Loss: 0.8873332798480987\n",
      "Epoch 64, Iteration 90, Loss: 0.8849934875965119\n",
      "Epoch 64, Iteration 100, Loss: 0.878896278142929\n",
      "Epoch 64, Iteration 110, Loss: 0.8763995170593262\n",
      "Epoch 64, Iteration 120, Loss: 0.8768532872200012\n",
      "Epoch 64, Iteration 130, Loss: 0.8807147324085236\n",
      "Epoch 64, Iteration 140, Loss: 0.8794634878635407\n",
      "Epoch 64, Iteration 150, Loss: 0.8784456193447113\n",
      "Epoch 64, Iteration 160, Loss: 0.8763072490692139\n",
      "Epoch 64, Iteration 170, Loss: 0.8870364964008332\n",
      "Epoch 64, Iteration 180, Loss: 0.8885757446289062\n",
      "Epoch 64, Iteration 190, Loss: 0.8934023678302765\n",
      "Epoch 65, Iteration 0, Loss: 0.08995241522789002\n",
      "Epoch 65, Iteration 10, Loss: 0.902761846780777\n",
      "Epoch 65, Iteration 20, Loss: 0.9174965798854828\n",
      "Epoch 65, Iteration 30, Loss: 0.9213129639625549\n",
      "Epoch 65, Iteration 40, Loss: 0.9148203790187835\n",
      "Epoch 65, Iteration 50, Loss: 0.9113703548908234\n",
      "Epoch 65, Iteration 60, Loss: 0.9027899920940399\n",
      "Epoch 65, Iteration 70, Loss: 0.8973773121833801\n",
      "Epoch 65, Iteration 80, Loss: 0.8922981739044189\n",
      "Epoch 65, Iteration 90, Loss: 0.8819452345371246\n",
      "Epoch 65, Iteration 100, Loss: 0.8843783497810364\n",
      "Epoch 65, Iteration 110, Loss: 0.8778260529041291\n",
      "Epoch 65, Iteration 120, Loss: 0.8765695273876191\n",
      "Epoch 65, Iteration 130, Loss: 0.8764330148696899\n",
      "Epoch 65, Iteration 140, Loss: 0.8715229034423828\n",
      "Epoch 65, Iteration 150, Loss: 0.8742475569248199\n",
      "Epoch 65, Iteration 160, Loss: 0.878910344839096\n",
      "Epoch 65, Iteration 170, Loss: 0.8780251502990722\n",
      "Epoch 65, Iteration 180, Loss: 0.8830787837505341\n",
      "Epoch 65, Iteration 190, Loss: 0.8835424959659577\n",
      "Epoch 66, Iteration 0, Loss: 0.08909955620765686\n",
      "Epoch 66, Iteration 10, Loss: 0.8972494423389434\n",
      "Epoch 66, Iteration 20, Loss: 0.9090634882450104\n",
      "Epoch 66, Iteration 30, Loss: 0.9140200972557068\n",
      "Epoch 66, Iteration 40, Loss: 0.9049459993839264\n",
      "Epoch 66, Iteration 50, Loss: 0.8984148740768433\n",
      "Epoch 66, Iteration 60, Loss: 0.8932532787322998\n",
      "Epoch 66, Iteration 70, Loss: 0.8824545085430145\n",
      "Epoch 66, Iteration 80, Loss: 0.8793096125125885\n",
      "Epoch 66, Iteration 90, Loss: 0.8731752276420593\n",
      "Epoch 66, Iteration 100, Loss: 0.8670865058898926\n",
      "Epoch 66, Iteration 110, Loss: 0.8676187634468079\n",
      "Epoch 66, Iteration 120, Loss: 0.8634257018566132\n",
      "Epoch 66, Iteration 130, Loss: 0.8616350710391998\n",
      "Epoch 66, Iteration 140, Loss: 0.8649102807044983\n",
      "Epoch 66, Iteration 150, Loss: 0.8661017715930939\n",
      "Epoch 66, Iteration 160, Loss: 0.8675775527954102\n",
      "Epoch 66, Iteration 170, Loss: 0.8760693848133088\n",
      "Epoch 66, Iteration 180, Loss: 0.8786341667175293\n",
      "Epoch 66, Iteration 190, Loss: 0.8845792412757874\n",
      "Epoch 67, Iteration 0, Loss: 0.0885631799697876\n",
      "Epoch 67, Iteration 10, Loss: 0.8944938480854034\n",
      "Epoch 67, Iteration 20, Loss: 0.9129461884498596\n",
      "Epoch 67, Iteration 30, Loss: 0.910229229927063\n",
      "Epoch 67, Iteration 40, Loss: 0.9075301826000214\n",
      "Epoch 67, Iteration 50, Loss: 0.8965235650539398\n",
      "Epoch 67, Iteration 60, Loss: 0.8930999636650085\n",
      "Epoch 67, Iteration 70, Loss: 0.8854598701000214\n",
      "Epoch 67, Iteration 80, Loss: 0.8773812115192413\n",
      "Epoch 67, Iteration 90, Loss: 0.8743224799633026\n",
      "Epoch 67, Iteration 100, Loss: 0.8689038634300232\n",
      "Epoch 67, Iteration 110, Loss: 0.8637706100940704\n",
      "Epoch 67, Iteration 120, Loss: 0.860599035024643\n",
      "Epoch 67, Iteration 130, Loss: 0.8617804229259491\n",
      "Epoch 67, Iteration 140, Loss: 0.8587801516056061\n",
      "Epoch 67, Iteration 150, Loss: 0.8616016924381256\n",
      "Epoch 67, Iteration 160, Loss: 0.8646361351013183\n",
      "Epoch 67, Iteration 170, Loss: 0.8672049939632416\n",
      "Epoch 67, Iteration 180, Loss: 0.87473424077034\n",
      "Epoch 67, Iteration 190, Loss: 0.8773559033870697\n",
      "Epoch 68, Iteration 0, Loss: 0.08871867656707763\n",
      "Epoch 68, Iteration 10, Loss: 0.8927730202674866\n",
      "Epoch 68, Iteration 20, Loss: 0.9096895694732666\n",
      "Epoch 68, Iteration 30, Loss: 0.9098026156425476\n",
      "Epoch 68, Iteration 40, Loss: 0.9083575129508972\n",
      "Epoch 68, Iteration 50, Loss: 0.9060319185256958\n",
      "Epoch 68, Iteration 60, Loss: 0.8985369324684143\n",
      "Epoch 68, Iteration 70, Loss: 0.8872382640838623\n",
      "Epoch 68, Iteration 80, Loss: 0.8831264436244964\n",
      "Epoch 68, Iteration 90, Loss: 0.8741049766540527\n",
      "Epoch 68, Iteration 100, Loss: 0.868734461069107\n",
      "Epoch 68, Iteration 110, Loss: 0.8678832352161407\n",
      "Epoch 68, Iteration 120, Loss: 0.8611927211284638\n",
      "Epoch 68, Iteration 130, Loss: 0.8619732916355133\n",
      "Epoch 68, Iteration 140, Loss: 0.8673071384429931\n",
      "Epoch 68, Iteration 150, Loss: 0.8686868786811829\n",
      "Epoch 68, Iteration 160, Loss: 0.8676575422286987\n",
      "Epoch 68, Iteration 170, Loss: 0.8744703710079194\n",
      "Epoch 68, Iteration 180, Loss: 0.875867509841919\n",
      "Epoch 68, Iteration 190, Loss: 0.8799250841140747\n",
      "Epoch 69, Iteration 0, Loss: 0.0879373550415039\n",
      "Epoch 69, Iteration 10, Loss: 0.8983590424060821\n",
      "Epoch 69, Iteration 20, Loss: 0.8984362006187439\n",
      "Epoch 69, Iteration 30, Loss: 0.9055253803730011\n",
      "Epoch 69, Iteration 40, Loss: 0.899936193227768\n",
      "Epoch 69, Iteration 50, Loss: 0.8962500929832459\n",
      "Epoch 69, Iteration 60, Loss: 0.8898120105266571\n",
      "Epoch 69, Iteration 70, Loss: 0.8792891561985016\n",
      "Epoch 69, Iteration 80, Loss: 0.8804989993572235\n",
      "Epoch 69, Iteration 90, Loss: 0.8723659515380859\n",
      "Epoch 69, Iteration 100, Loss: 0.8674929082393646\n",
      "Epoch 69, Iteration 110, Loss: 0.8639094591140747\n",
      "Epoch 69, Iteration 120, Loss: 0.8638997197151184\n",
      "Epoch 69, Iteration 130, Loss: 0.8642142415046692\n",
      "Epoch 69, Iteration 140, Loss: 0.8643503844738006\n",
      "Epoch 69, Iteration 150, Loss: 0.8679576098918915\n",
      "Epoch 69, Iteration 160, Loss: 0.8724794685840607\n",
      "Epoch 69, Iteration 170, Loss: 0.8788150787353516\n",
      "Epoch 69, Iteration 180, Loss: 0.8795985281467438\n",
      "Epoch 69, Iteration 190, Loss: 0.8890487074851989\n",
      "Epoch 70, Iteration 0, Loss: 0.08880134224891663\n",
      "Epoch 70, Iteration 10, Loss: 0.893167394399643\n",
      "Epoch 70, Iteration 20, Loss: 0.9136994421482086\n",
      "Epoch 70, Iteration 30, Loss: 0.9120842814445496\n",
      "Epoch 70, Iteration 40, Loss: 0.9114343523979187\n",
      "Epoch 70, Iteration 50, Loss: 0.9013573825359344\n",
      "Epoch 70, Iteration 60, Loss: 0.8944281995296478\n",
      "Epoch 70, Iteration 70, Loss: 0.8888317823410035\n",
      "Epoch 70, Iteration 80, Loss: 0.8775343418121337\n",
      "Epoch 70, Iteration 90, Loss: 0.8774910211563111\n",
      "Epoch 70, Iteration 100, Loss: 0.871204000711441\n",
      "Epoch 70, Iteration 110, Loss: 0.8687380433082581\n",
      "Epoch 70, Iteration 120, Loss: 0.870224940776825\n",
      "Epoch 70, Iteration 130, Loss: 0.8717388153076172\n",
      "Epoch 70, Iteration 140, Loss: 0.8717675507068634\n",
      "Epoch 70, Iteration 150, Loss: 0.8783122479915619\n",
      "Epoch 70, Iteration 160, Loss: 0.8766935169696808\n",
      "Epoch 70, Iteration 170, Loss: 0.8799788415431976\n",
      "Epoch 70, Iteration 180, Loss: 0.8851754069328308\n",
      "Epoch 70, Iteration 190, Loss: 0.889686667919159\n",
      "Epoch 71, Iteration 0, Loss: 0.08909432291984558\n",
      "Epoch 71, Iteration 10, Loss: 0.9027141690254211\n",
      "Epoch 71, Iteration 20, Loss: 0.916511058807373\n",
      "Epoch 71, Iteration 30, Loss: 0.9190151989459991\n",
      "Epoch 71, Iteration 40, Loss: 0.9158636510372162\n",
      "Epoch 71, Iteration 50, Loss: 0.908960497379303\n",
      "Epoch 71, Iteration 60, Loss: 0.8974412620067597\n",
      "Epoch 71, Iteration 70, Loss: 0.895540177822113\n",
      "Epoch 71, Iteration 80, Loss: 0.8858353078365326\n",
      "Epoch 71, Iteration 90, Loss: 0.8813069820404053\n",
      "Epoch 71, Iteration 100, Loss: 0.8743977665901184\n",
      "Epoch 71, Iteration 110, Loss: 0.872946435213089\n",
      "Epoch 71, Iteration 120, Loss: 0.8723356902599335\n",
      "Epoch 71, Iteration 130, Loss: 0.8692280948162079\n",
      "Epoch 71, Iteration 140, Loss: 0.8710650742053986\n",
      "Epoch 71, Iteration 150, Loss: 0.8721745073795318\n",
      "Epoch 71, Iteration 160, Loss: 0.8764089941978455\n",
      "Epoch 71, Iteration 170, Loss: 0.8803888201713562\n",
      "Epoch 71, Iteration 180, Loss: 0.8800333380699158\n",
      "Epoch 71, Iteration 190, Loss: 0.8859131395816803\n",
      "Epoch 72, Iteration 0, Loss: 0.08834508061408997\n",
      "Epoch 72, Iteration 10, Loss: 0.8967962563037872\n",
      "Epoch 72, Iteration 20, Loss: 0.9062533378601074\n",
      "Epoch 72, Iteration 30, Loss: 0.9153366029262543\n",
      "Epoch 72, Iteration 40, Loss: 0.9110189914703369\n",
      "Epoch 72, Iteration 50, Loss: 0.905293321609497\n",
      "Epoch 72, Iteration 60, Loss: 0.8963838398456574\n",
      "Epoch 72, Iteration 70, Loss: 0.8897962391376495\n",
      "Epoch 72, Iteration 80, Loss: 0.8860355854034424\n",
      "Epoch 72, Iteration 90, Loss: 0.8823810756206513\n",
      "Epoch 72, Iteration 100, Loss: 0.8772550225257874\n",
      "Epoch 72, Iteration 110, Loss: 0.877229756116867\n",
      "Epoch 72, Iteration 120, Loss: 0.8703962981700897\n",
      "Epoch 72, Iteration 130, Loss: 0.8721296787261963\n",
      "Epoch 72, Iteration 140, Loss: 0.8748558044433594\n",
      "Epoch 72, Iteration 150, Loss: 0.8765919148921967\n",
      "Epoch 72, Iteration 160, Loss: 0.8791587710380554\n",
      "Epoch 72, Iteration 170, Loss: 0.884484738111496\n",
      "Epoch 72, Iteration 180, Loss: 0.8871030390262604\n",
      "Epoch 72, Iteration 190, Loss: 0.8897380471229553\n",
      "Epoch 73, Iteration 0, Loss: 0.0888539731502533\n",
      "Epoch 73, Iteration 10, Loss: 0.9097714960575104\n",
      "Epoch 73, Iteration 20, Loss: 0.9181213915348053\n",
      "Epoch 73, Iteration 30, Loss: 0.9233031511306763\n",
      "Epoch 73, Iteration 40, Loss: 0.9206359386444092\n",
      "Epoch 73, Iteration 50, Loss: 0.9140242397785187\n",
      "Epoch 73, Iteration 60, Loss: 0.9070737659931183\n",
      "Epoch 73, Iteration 70, Loss: 0.8993322193622589\n",
      "Epoch 73, Iteration 80, Loss: 0.8915147542953491\n",
      "Epoch 73, Iteration 90, Loss: 0.8860526144504547\n",
      "Epoch 73, Iteration 100, Loss: 0.8814993798732758\n",
      "Epoch 73, Iteration 110, Loss: 0.8791811347007752\n",
      "Epoch 73, Iteration 120, Loss: 0.8753057181835174\n",
      "Epoch 73, Iteration 130, Loss: 0.8770482182502747\n",
      "Epoch 73, Iteration 140, Loss: 0.8705685675144196\n",
      "Epoch 73, Iteration 150, Loss: 0.8745542705059052\n",
      "Epoch 73, Iteration 160, Loss: 0.8758723914623261\n",
      "Epoch 73, Iteration 170, Loss: 0.8808908879756927\n",
      "Epoch 73, Iteration 180, Loss: 0.8837380409240723\n",
      "Epoch 73, Iteration 190, Loss: 0.887138170003891\n",
      "Epoch 74, Iteration 0, Loss: 0.08797848224639893\n",
      "Epoch 74, Iteration 10, Loss: 0.9006902813911438\n",
      "Epoch 74, Iteration 20, Loss: 0.912159389257431\n",
      "Epoch 74, Iteration 30, Loss: 0.917854231595993\n",
      "Epoch 74, Iteration 40, Loss: 0.9141093730926514\n",
      "Epoch 74, Iteration 50, Loss: 0.9075243532657623\n",
      "Epoch 74, Iteration 60, Loss: 0.9008658528327942\n",
      "Epoch 74, Iteration 70, Loss: 0.8912569224834442\n",
      "Epoch 74, Iteration 80, Loss: 0.8849983811378479\n",
      "Epoch 74, Iteration 90, Loss: 0.8834344685077667\n",
      "Epoch 74, Iteration 100, Loss: 0.8794254124164581\n",
      "Epoch 74, Iteration 110, Loss: 0.8758202373981476\n",
      "Epoch 74, Iteration 120, Loss: 0.8722415626049042\n",
      "Epoch 74, Iteration 130, Loss: 0.8756630718708038\n",
      "Epoch 74, Iteration 140, Loss: 0.8792160868644714\n",
      "Epoch 74, Iteration 150, Loss: 0.8782024264335633\n",
      "Epoch 74, Iteration 160, Loss: 0.8769048452377319\n",
      "Epoch 74, Iteration 170, Loss: 0.8862513244152069\n",
      "Epoch 74, Iteration 180, Loss: 0.8884372711181641\n",
      "Epoch 74, Iteration 190, Loss: 0.89543417096138\n",
      "Epoch 75, Iteration 0, Loss: 0.08915380835533142\n",
      "Epoch 75, Iteration 10, Loss: 0.9075869977474212\n",
      "Epoch 75, Iteration 20, Loss: 0.9257496535778046\n",
      "Epoch 75, Iteration 30, Loss: 0.9251829087734222\n",
      "Epoch 75, Iteration 40, Loss: 0.9216243922710419\n",
      "Epoch 75, Iteration 50, Loss: 0.9185168862342834\n",
      "Epoch 75, Iteration 60, Loss: 0.9068713843822479\n",
      "Epoch 75, Iteration 70, Loss: 0.9015247523784637\n",
      "Epoch 75, Iteration 80, Loss: 0.8945183277130127\n",
      "Epoch 75, Iteration 90, Loss: 0.8873957395553589\n",
      "Epoch 75, Iteration 100, Loss: 0.8822861850261688\n",
      "Epoch 75, Iteration 110, Loss: 0.8800508975982666\n",
      "Epoch 75, Iteration 120, Loss: 0.8756902694702149\n",
      "Epoch 75, Iteration 130, Loss: 0.8761711239814758\n",
      "Epoch 75, Iteration 140, Loss: 0.8760790348052978\n",
      "Epoch 75, Iteration 150, Loss: 0.8778711378574371\n",
      "Epoch 75, Iteration 160, Loss: 0.8748764574527741\n",
      "Epoch 75, Iteration 170, Loss: 0.8777397334575653\n",
      "Epoch 75, Iteration 180, Loss: 0.8823527753353119\n",
      "Epoch 75, Iteration 190, Loss: 0.8857212901115418\n",
      "Epoch 76, Iteration 0, Loss: 0.08920741081237793\n",
      "Epoch 76, Iteration 10, Loss: 0.8954499006271363\n",
      "Epoch 76, Iteration 20, Loss: 0.9070983231067657\n",
      "Epoch 76, Iteration 30, Loss: 0.9106240034103393\n",
      "Epoch 76, Iteration 40, Loss: 0.9054237902164459\n",
      "Epoch 76, Iteration 50, Loss: 0.9039286255836487\n",
      "Epoch 76, Iteration 60, Loss: 0.8942574441432953\n",
      "Epoch 76, Iteration 70, Loss: 0.8874300956726074\n",
      "Epoch 76, Iteration 80, Loss: 0.8830359578132629\n",
      "Epoch 76, Iteration 90, Loss: 0.8775222659111023\n",
      "Epoch 76, Iteration 100, Loss: 0.8733963310718537\n",
      "Epoch 76, Iteration 110, Loss: 0.8700599789619445\n",
      "Epoch 76, Iteration 120, Loss: 0.8692574083805085\n",
      "Epoch 76, Iteration 130, Loss: 0.868902200460434\n",
      "Epoch 76, Iteration 140, Loss: 0.8697028994560242\n",
      "Epoch 76, Iteration 150, Loss: 0.8694419085979461\n",
      "Epoch 76, Iteration 160, Loss: 0.8712885320186615\n",
      "Epoch 76, Iteration 170, Loss: 0.8732805550098419\n",
      "Epoch 76, Iteration 180, Loss: 0.8794068038463593\n",
      "Epoch 76, Iteration 190, Loss: 0.8834578514099121\n",
      "Epoch 77, Iteration 0, Loss: 0.08744242191314697\n",
      "Epoch 77, Iteration 10, Loss: 0.8916715383529663\n",
      "Epoch 77, Iteration 20, Loss: 0.9074469685554505\n",
      "Epoch 77, Iteration 30, Loss: 0.9096372127532959\n",
      "Epoch 77, Iteration 40, Loss: 0.9071672141551972\n",
      "Epoch 77, Iteration 50, Loss: 0.9027465105056762\n",
      "Epoch 77, Iteration 60, Loss: 0.8932748556137085\n",
      "Epoch 77, Iteration 70, Loss: 0.8875979363918305\n",
      "Epoch 77, Iteration 80, Loss: 0.8859081566333771\n",
      "Epoch 77, Iteration 90, Loss: 0.877668035030365\n",
      "Epoch 77, Iteration 100, Loss: 0.8769254744052887\n",
      "Epoch 77, Iteration 110, Loss: 0.8752430438995361\n",
      "Epoch 77, Iteration 120, Loss: 0.8690713226795197\n",
      "Epoch 77, Iteration 130, Loss: 0.8696230709552765\n",
      "Epoch 77, Iteration 140, Loss: 0.8689028739929199\n",
      "Epoch 77, Iteration 150, Loss: 0.8752886056900024\n",
      "Epoch 77, Iteration 160, Loss: 0.8751141726970673\n",
      "Epoch 77, Iteration 170, Loss: 0.8765920221805572\n",
      "Epoch 77, Iteration 180, Loss: 0.8788257002830505\n",
      "Epoch 77, Iteration 190, Loss: 0.889436000585556\n",
      "Epoch 78, Iteration 0, Loss: 0.08812172412872314\n",
      "Epoch 78, Iteration 10, Loss: 0.8980777084827423\n",
      "Epoch 78, Iteration 20, Loss: 0.9040555715560913\n",
      "Epoch 78, Iteration 30, Loss: 0.9112042844295501\n",
      "Epoch 78, Iteration 40, Loss: 0.9045901894569397\n",
      "Epoch 78, Iteration 50, Loss: 0.9014724552631378\n",
      "Epoch 78, Iteration 60, Loss: 0.8965292274951935\n",
      "Epoch 78, Iteration 70, Loss: 0.8880394339561463\n",
      "Epoch 78, Iteration 80, Loss: 0.8860725402832031\n",
      "Epoch 78, Iteration 90, Loss: 0.8777040600776672\n",
      "Epoch 78, Iteration 100, Loss: 0.8753115653991699\n",
      "Epoch 78, Iteration 110, Loss: 0.8775039672851562\n",
      "Epoch 78, Iteration 120, Loss: 0.8737751960754394\n",
      "Epoch 78, Iteration 130, Loss: 0.8746782958507537\n",
      "Epoch 78, Iteration 140, Loss: 0.8763600766658783\n",
      "Epoch 78, Iteration 150, Loss: 0.8805820941925049\n",
      "Epoch 78, Iteration 160, Loss: 0.8809028744697571\n",
      "Epoch 78, Iteration 170, Loss: 0.8820804417133331\n",
      "Epoch 78, Iteration 180, Loss: 0.887338250875473\n",
      "Epoch 78, Iteration 190, Loss: 0.8934512495994568\n",
      "Epoch 79, Iteration 0, Loss: 0.09034839868545533\n",
      "Epoch 79, Iteration 10, Loss: 0.905187463760376\n",
      "Epoch 79, Iteration 20, Loss: 0.917722636461258\n",
      "Epoch 79, Iteration 30, Loss: 0.9204996705055237\n",
      "Epoch 79, Iteration 40, Loss: 0.9163048744201661\n",
      "Epoch 79, Iteration 50, Loss: 0.9129855275154114\n",
      "Epoch 79, Iteration 60, Loss: 0.9055136620998383\n",
      "Epoch 79, Iteration 70, Loss: 0.8971475720405578\n",
      "Epoch 79, Iteration 80, Loss: 0.8915477931499481\n",
      "Epoch 79, Iteration 90, Loss: 0.8855875432491302\n",
      "Epoch 79, Iteration 100, Loss: 0.8772116065025329\n",
      "Epoch 79, Iteration 110, Loss: 0.8756574094295502\n",
      "Epoch 79, Iteration 120, Loss: 0.8724153876304627\n",
      "Epoch 79, Iteration 130, Loss: 0.8749601304531097\n",
      "Epoch 79, Iteration 140, Loss: 0.8760107338428498\n",
      "Epoch 79, Iteration 150, Loss: 0.8745711445808411\n",
      "Epoch 79, Iteration 160, Loss: 0.8754279315471649\n",
      "Epoch 79, Iteration 170, Loss: 0.8769293010234833\n",
      "Epoch 79, Iteration 180, Loss: 0.8830270171165466\n",
      "Epoch 79, Iteration 190, Loss: 0.8827379703521728\n",
      "Epoch 80, Iteration 0, Loss: 0.08911784887313842\n",
      "Epoch 80, Iteration 10, Loss: 0.8981659471988678\n",
      "Epoch 80, Iteration 20, Loss: 0.9077821612358093\n",
      "Epoch 80, Iteration 30, Loss: 0.9076625287532807\n",
      "Epoch 80, Iteration 40, Loss: 0.8999807834625244\n",
      "Epoch 80, Iteration 50, Loss: 0.896757173538208\n",
      "Epoch 80, Iteration 60, Loss: 0.8928688764572144\n",
      "Epoch 80, Iteration 70, Loss: 0.8839719116687774\n",
      "Epoch 80, Iteration 80, Loss: 0.8732317626476288\n",
      "Epoch 80, Iteration 90, Loss: 0.8708583056926728\n",
      "Epoch 80, Iteration 100, Loss: 0.8694125533103942\n",
      "Epoch 80, Iteration 110, Loss: 0.8674268305301667\n",
      "Epoch 80, Iteration 120, Loss: 0.8677362561225891\n",
      "Epoch 80, Iteration 130, Loss: 0.8617477655410767\n",
      "Epoch 80, Iteration 140, Loss: 0.8657580077648163\n",
      "Epoch 80, Iteration 150, Loss: 0.8692197024822235\n",
      "Epoch 80, Iteration 160, Loss: 0.8690956234931946\n",
      "Epoch 80, Iteration 170, Loss: 0.8736380100250244\n",
      "Epoch 80, Iteration 180, Loss: 0.8802394330501556\n",
      "Epoch 80, Iteration 190, Loss: 0.8840277671813965\n",
      "Epoch 81, Iteration 0, Loss: 0.08879997730255126\n",
      "Epoch 81, Iteration 10, Loss: 0.8943161129951477\n",
      "Epoch 81, Iteration 20, Loss: 0.9058325231075287\n",
      "Epoch 81, Iteration 30, Loss: 0.906769335269928\n",
      "Epoch 81, Iteration 40, Loss: 0.904875373840332\n",
      "Epoch 81, Iteration 50, Loss: 0.8982720613479614\n",
      "Epoch 81, Iteration 60, Loss: 0.8920371294021606\n",
      "Epoch 81, Iteration 70, Loss: 0.8865647435188293\n",
      "Epoch 81, Iteration 80, Loss: 0.8796886563301086\n",
      "Epoch 81, Iteration 90, Loss: 0.8756718635559082\n",
      "Epoch 81, Iteration 100, Loss: 0.8637287557125092\n",
      "Epoch 81, Iteration 110, Loss: 0.8685162305831909\n",
      "Epoch 81, Iteration 120, Loss: 0.8641846954822541\n",
      "Epoch 81, Iteration 130, Loss: 0.8620560586452484\n",
      "Epoch 81, Iteration 140, Loss: 0.8653039693832397\n",
      "Epoch 81, Iteration 150, Loss: 0.8668240666389465\n",
      "Epoch 81, Iteration 160, Loss: 0.8680252015590668\n",
      "Epoch 81, Iteration 170, Loss: 0.875506067276001\n",
      "Epoch 81, Iteration 180, Loss: 0.8775348484516143\n",
      "Epoch 81, Iteration 190, Loss: 0.8833354413509369\n",
      "Epoch 82, Iteration 0, Loss: 0.08778726458549499\n",
      "Epoch 82, Iteration 10, Loss: 0.8973856329917907\n",
      "Epoch 82, Iteration 20, Loss: 0.9101704359054565\n",
      "Epoch 82, Iteration 30, Loss: 0.9080704033374787\n",
      "Epoch 82, Iteration 40, Loss: 0.9019936859607697\n",
      "Epoch 82, Iteration 50, Loss: 0.8997409760951995\n",
      "Epoch 82, Iteration 60, Loss: 0.8919398784637451\n",
      "Epoch 82, Iteration 70, Loss: 0.8885672509670257\n",
      "Epoch 82, Iteration 80, Loss: 0.8804756760597229\n",
      "Epoch 82, Iteration 90, Loss: 0.8731498301029206\n",
      "Epoch 82, Iteration 100, Loss: 0.8733738243579865\n",
      "Epoch 82, Iteration 110, Loss: 0.8724372506141662\n",
      "Epoch 82, Iteration 120, Loss: 0.8654921412467956\n",
      "Epoch 82, Iteration 130, Loss: 0.8677075386047364\n",
      "Epoch 82, Iteration 140, Loss: 0.8710278153419495\n",
      "Epoch 82, Iteration 150, Loss: 0.8741503179073333\n",
      "Epoch 82, Iteration 160, Loss: 0.8726104497909546\n",
      "Epoch 82, Iteration 170, Loss: 0.8816729664802552\n",
      "Epoch 82, Iteration 180, Loss: 0.8845285832881927\n",
      "Epoch 82, Iteration 190, Loss: 0.892740535736084\n",
      "Epoch 83, Iteration 0, Loss: 0.08964365124702453\n",
      "Epoch 83, Iteration 10, Loss: 0.8984279096126556\n",
      "Epoch 83, Iteration 20, Loss: 0.913829642534256\n",
      "Epoch 83, Iteration 30, Loss: 0.9162043929100037\n",
      "Epoch 83, Iteration 40, Loss: 0.920187920331955\n",
      "Epoch 83, Iteration 50, Loss: 0.9057493567466736\n",
      "Epoch 83, Iteration 60, Loss: 0.9043804764747619\n",
      "Epoch 83, Iteration 70, Loss: 0.8944864749908448\n",
      "Epoch 83, Iteration 80, Loss: 0.8898658335208893\n",
      "Epoch 83, Iteration 90, Loss: 0.8852980256080627\n",
      "Epoch 83, Iteration 100, Loss: 0.8816474437713623\n",
      "Epoch 83, Iteration 110, Loss: 0.876689612865448\n",
      "Epoch 83, Iteration 120, Loss: 0.876004022359848\n",
      "Epoch 83, Iteration 130, Loss: 0.8706156253814697\n",
      "Epoch 83, Iteration 140, Loss: 0.8704657435417176\n",
      "Epoch 83, Iteration 150, Loss: 0.8748320162296295\n",
      "Epoch 83, Iteration 160, Loss: 0.8807000637054443\n",
      "Epoch 83, Iteration 170, Loss: 0.880042952299118\n",
      "Epoch 83, Iteration 180, Loss: 0.8867424726486206\n",
      "Epoch 83, Iteration 190, Loss: 0.8891053795814514\n",
      "Epoch 84, Iteration 0, Loss: 0.08961285948753357\n",
      "Epoch 84, Iteration 10, Loss: 0.9034023940563202\n",
      "Epoch 84, Iteration 20, Loss: 0.9154047131538391\n",
      "Epoch 84, Iteration 30, Loss: 0.9188564658164978\n",
      "Epoch 84, Iteration 40, Loss: 0.9114095389842987\n",
      "Epoch 84, Iteration 50, Loss: 0.9013201296329498\n",
      "Epoch 84, Iteration 60, Loss: 0.8992029368877411\n",
      "Epoch 84, Iteration 70, Loss: 0.8913923799991608\n",
      "Epoch 84, Iteration 80, Loss: 0.8857368886470794\n",
      "Epoch 84, Iteration 90, Loss: 0.8793046593666076\n",
      "Epoch 84, Iteration 100, Loss: 0.8739229261875152\n",
      "Epoch 84, Iteration 110, Loss: 0.8780500292778015\n",
      "Epoch 84, Iteration 120, Loss: 0.8729881525039673\n",
      "Epoch 84, Iteration 130, Loss: 0.8740906774997711\n",
      "Epoch 84, Iteration 140, Loss: 0.8706178784370422\n",
      "Epoch 84, Iteration 150, Loss: 0.8742660343647003\n",
      "Epoch 84, Iteration 160, Loss: 0.8761370956897736\n",
      "Epoch 84, Iteration 170, Loss: 0.8770522117614746\n",
      "Epoch 84, Iteration 180, Loss: 0.8840254247188568\n",
      "Epoch 84, Iteration 190, Loss: 0.8906914830207825\n",
      "Epoch 85, Iteration 0, Loss: 0.08853744864463806\n",
      "Epoch 85, Iteration 10, Loss: 0.8982222259044648\n",
      "Epoch 85, Iteration 20, Loss: 0.9091964840888977\n",
      "Epoch 85, Iteration 30, Loss: 0.9097672700881958\n",
      "Epoch 85, Iteration 40, Loss: 0.9062219858169556\n",
      "Epoch 85, Iteration 50, Loss: 0.8993098437786102\n",
      "Epoch 85, Iteration 60, Loss: 0.8978941142559052\n",
      "Epoch 85, Iteration 70, Loss: 0.8854063928127289\n",
      "Epoch 85, Iteration 80, Loss: 0.8787808418273926\n",
      "Epoch 85, Iteration 90, Loss: 0.8754568219184875\n",
      "Epoch 85, Iteration 100, Loss: 0.8701615512371064\n",
      "Epoch 85, Iteration 110, Loss: 0.8690495252609253\n",
      "Epoch 85, Iteration 120, Loss: 0.8671776831150055\n",
      "Epoch 85, Iteration 130, Loss: 0.8682200968265533\n",
      "Epoch 85, Iteration 140, Loss: 0.8692292451858521\n",
      "Epoch 85, Iteration 150, Loss: 0.8711162269115448\n",
      "Epoch 85, Iteration 160, Loss: 0.8760381698608398\n",
      "Epoch 85, Iteration 170, Loss: 0.8853934586048127\n",
      "Epoch 85, Iteration 180, Loss: 0.8843814790248871\n",
      "Epoch 85, Iteration 190, Loss: 0.8901999533176422\n",
      "Epoch 86, Iteration 0, Loss: 0.09163304567337036\n",
      "Epoch 86, Iteration 10, Loss: 0.904296338558197\n",
      "Epoch 86, Iteration 20, Loss: 0.9210053324699402\n",
      "Epoch 86, Iteration 30, Loss: 0.9221055388450623\n",
      "Epoch 86, Iteration 40, Loss: 0.9218482971191406\n",
      "Epoch 86, Iteration 50, Loss: 0.9117237269878388\n",
      "Epoch 86, Iteration 60, Loss: 0.9116709470748902\n",
      "Epoch 86, Iteration 70, Loss: 0.9006252825260163\n",
      "Epoch 86, Iteration 80, Loss: 0.8939791679382324\n",
      "Epoch 86, Iteration 90, Loss: 0.8913051128387451\n",
      "Epoch 86, Iteration 100, Loss: 0.8860490262508393\n",
      "Epoch 86, Iteration 110, Loss: 0.8825778126716614\n",
      "Epoch 86, Iteration 120, Loss: 0.8812356233596802\n",
      "Epoch 86, Iteration 130, Loss: 0.8839682459831237\n",
      "Epoch 86, Iteration 140, Loss: 0.8816519260406495\n",
      "Epoch 86, Iteration 150, Loss: 0.8850455164909363\n",
      "Epoch 86, Iteration 160, Loss: 0.8858276009559631\n",
      "Epoch 86, Iteration 170, Loss: 0.8915067732334137\n",
      "Epoch 86, Iteration 180, Loss: 0.8956588208675385\n",
      "Epoch 86, Iteration 190, Loss: 0.9029104769229889\n",
      "Epoch 87, Iteration 0, Loss: 0.09108656644821167\n",
      "Epoch 87, Iteration 10, Loss: 0.91473867893219\n",
      "Epoch 87, Iteration 20, Loss: 0.9302437722682952\n",
      "Epoch 87, Iteration 30, Loss: 0.9309648036956787\n",
      "Epoch 87, Iteration 40, Loss: 0.9284413874149322\n",
      "Epoch 87, Iteration 50, Loss: 0.919636332988739\n",
      "Epoch 87, Iteration 60, Loss: 0.9171734929084778\n",
      "Epoch 87, Iteration 70, Loss: 0.9080613851547241\n",
      "Epoch 87, Iteration 80, Loss: 0.9037708163261413\n",
      "Epoch 87, Iteration 90, Loss: 0.903429263830185\n",
      "Epoch 87, Iteration 100, Loss: 0.894694322347641\n",
      "Epoch 87, Iteration 110, Loss: 0.8922346949577331\n",
      "Epoch 87, Iteration 120, Loss: 0.8892721354961395\n",
      "Epoch 87, Iteration 130, Loss: 0.888739961385727\n",
      "Epoch 87, Iteration 140, Loss: 0.8925004065036773\n",
      "Epoch 87, Iteration 150, Loss: 0.8898931920528412\n",
      "Epoch 87, Iteration 160, Loss: 0.8912419438362121\n",
      "Epoch 87, Iteration 170, Loss: 0.8946222364902496\n",
      "Epoch 87, Iteration 180, Loss: 0.895755285024643\n",
      "Epoch 87, Iteration 190, Loss: 0.8974623680114746\n",
      "Epoch 88, Iteration 0, Loss: 0.09076559543609619\n",
      "Epoch 88, Iteration 10, Loss: 0.9103298664093018\n",
      "Epoch 88, Iteration 20, Loss: 0.9216030418872834\n",
      "Epoch 88, Iteration 30, Loss: 0.9311354756355286\n",
      "Epoch 88, Iteration 40, Loss: 0.9230448365211487\n",
      "Epoch 88, Iteration 50, Loss: 0.9200718879699707\n",
      "Epoch 88, Iteration 60, Loss: 0.9112352848052978\n",
      "Epoch 88, Iteration 70, Loss: 0.9039145469665527\n",
      "Epoch 88, Iteration 80, Loss: 0.8986388146877289\n",
      "Epoch 88, Iteration 90, Loss: 0.892797976732254\n",
      "Epoch 88, Iteration 100, Loss: 0.8895099520683288\n",
      "Epoch 88, Iteration 110, Loss: 0.8817627549171447\n",
      "Epoch 88, Iteration 120, Loss: 0.881751412153244\n",
      "Epoch 88, Iteration 130, Loss: 0.8819213211536407\n",
      "Epoch 88, Iteration 140, Loss: 0.8803523123264313\n",
      "Epoch 88, Iteration 150, Loss: 0.8854669392108917\n",
      "Epoch 88, Iteration 160, Loss: 0.8816657602787018\n",
      "Epoch 88, Iteration 170, Loss: 0.8857562780380249\n",
      "Epoch 88, Iteration 180, Loss: 0.8934047996997834\n",
      "Epoch 88, Iteration 190, Loss: 0.8984909236431122\n",
      "Epoch 89, Iteration 0, Loss: 0.08996883630752564\n",
      "Epoch 89, Iteration 10, Loss: 0.9066664278507233\n",
      "Epoch 89, Iteration 20, Loss: 0.9242158353328704\n",
      "Epoch 89, Iteration 30, Loss: 0.9279698193073272\n",
      "Epoch 89, Iteration 40, Loss: 0.9202101349830627\n",
      "Epoch 89, Iteration 50, Loss: 0.9127002894878388\n",
      "Epoch 89, Iteration 60, Loss: 0.9089140295982361\n",
      "Epoch 89, Iteration 70, Loss: 0.8987029790878296\n",
      "Epoch 89, Iteration 80, Loss: 0.8947131156921386\n",
      "Epoch 89, Iteration 90, Loss: 0.893325811624527\n",
      "Epoch 89, Iteration 100, Loss: 0.8858508408069611\n",
      "Epoch 89, Iteration 110, Loss: 0.8822564482688904\n",
      "Epoch 89, Iteration 120, Loss: 0.8772037565708161\n",
      "Epoch 89, Iteration 130, Loss: 0.8800063848495483\n",
      "Epoch 89, Iteration 140, Loss: 0.8735520124435425\n",
      "Epoch 89, Iteration 150, Loss: 0.8793502390384674\n",
      "Epoch 89, Iteration 160, Loss: 0.8800800979137421\n",
      "Epoch 89, Iteration 170, Loss: 0.8871984660625458\n",
      "Epoch 89, Iteration 180, Loss: 0.8844163954257965\n",
      "Epoch 89, Iteration 190, Loss: 0.8891774654388428\n",
      "Epoch 90, Iteration 0, Loss: 0.08898652791976928\n",
      "Epoch 90, Iteration 10, Loss: 0.8976813614368438\n",
      "Epoch 90, Iteration 20, Loss: 0.909598833322525\n",
      "Epoch 90, Iteration 30, Loss: 0.9125129461288453\n",
      "Epoch 90, Iteration 40, Loss: 0.9091857969760895\n",
      "Epoch 90, Iteration 50, Loss: 0.8986148595809936\n",
      "Epoch 90, Iteration 60, Loss: 0.8961611270904541\n",
      "Epoch 90, Iteration 70, Loss: 0.8876067340373993\n",
      "Epoch 90, Iteration 80, Loss: 0.8872995853424073\n",
      "Epoch 90, Iteration 90, Loss: 0.8808985352516174\n",
      "Epoch 90, Iteration 100, Loss: 0.8752394378185272\n",
      "Epoch 90, Iteration 110, Loss: 0.8709189832210541\n",
      "Epoch 90, Iteration 120, Loss: 0.8699195086956024\n",
      "Epoch 90, Iteration 130, Loss: 0.8688347935676575\n",
      "Epoch 90, Iteration 140, Loss: 0.8701168596744537\n",
      "Epoch 90, Iteration 150, Loss: 0.874147915840149\n",
      "Epoch 90, Iteration 160, Loss: 0.8776919126510621\n",
      "Epoch 90, Iteration 170, Loss: 0.882352215051651\n",
      "Epoch 90, Iteration 180, Loss: 0.8826244175434113\n",
      "Epoch 90, Iteration 190, Loss: 0.8898820161819458\n",
      "Epoch 91, Iteration 0, Loss: 0.08975666761398315\n",
      "Epoch 91, Iteration 10, Loss: 0.8994159042835236\n",
      "Epoch 91, Iteration 20, Loss: 0.9092546045780182\n",
      "Epoch 91, Iteration 30, Loss: 0.9107516407966614\n",
      "Epoch 91, Iteration 40, Loss: 0.907613068819046\n",
      "Epoch 91, Iteration 50, Loss: 0.8994705080986023\n",
      "Epoch 91, Iteration 60, Loss: 0.8906748950481415\n",
      "Epoch 91, Iteration 70, Loss: 0.8886546730995178\n",
      "Epoch 91, Iteration 80, Loss: 0.878792816400528\n",
      "Epoch 91, Iteration 90, Loss: 0.8741460621356965\n",
      "Epoch 91, Iteration 100, Loss: 0.8699854373931885\n",
      "Epoch 91, Iteration 110, Loss: 0.8697104692459107\n",
      "Epoch 91, Iteration 120, Loss: 0.8718369543552399\n",
      "Epoch 91, Iteration 130, Loss: 0.871814352273941\n",
      "Epoch 91, Iteration 140, Loss: 0.8665142476558685\n",
      "Epoch 91, Iteration 150, Loss: 0.8715928375720978\n",
      "Epoch 91, Iteration 160, Loss: 0.8769158959388733\n",
      "Epoch 91, Iteration 170, Loss: 0.8765327274799347\n",
      "Epoch 91, Iteration 180, Loss: 0.8825048089027405\n",
      "Epoch 91, Iteration 190, Loss: 0.8921936094760895\n",
      "Epoch 92, Iteration 0, Loss: 0.08963319063186645\n",
      "Epoch 92, Iteration 10, Loss: 0.8971814215183258\n",
      "Epoch 92, Iteration 20, Loss: 0.9118766069412232\n",
      "Epoch 92, Iteration 30, Loss: 0.915648776292801\n",
      "Epoch 92, Iteration 40, Loss: 0.9142707109451294\n",
      "Epoch 92, Iteration 50, Loss: 0.9056259155273437\n",
      "Epoch 92, Iteration 60, Loss: 0.9006084203720093\n",
      "Epoch 92, Iteration 70, Loss: 0.8939791977405548\n",
      "Epoch 92, Iteration 80, Loss: 0.8881659746170044\n",
      "Epoch 92, Iteration 90, Loss: 0.8835129022598267\n",
      "Epoch 92, Iteration 100, Loss: 0.8820888996124268\n",
      "Epoch 92, Iteration 110, Loss: 0.8776780545711518\n",
      "Epoch 92, Iteration 120, Loss: 0.8765179991722107\n",
      "Epoch 92, Iteration 130, Loss: 0.8753565311431885\n",
      "Epoch 92, Iteration 140, Loss: 0.8770138800144196\n",
      "Epoch 92, Iteration 150, Loss: 0.8756270587444306\n",
      "Epoch 92, Iteration 160, Loss: 0.8785897433757782\n",
      "Epoch 92, Iteration 170, Loss: 0.8814761579036713\n",
      "Epoch 92, Iteration 180, Loss: 0.8860599339008332\n",
      "Epoch 92, Iteration 190, Loss: 0.8930651843547821\n",
      "Epoch 93, Iteration 0, Loss: 0.08968591690063477\n",
      "Epoch 93, Iteration 10, Loss: 0.9056889295578003\n",
      "Epoch 93, Iteration 20, Loss: 0.9154566347599029\n",
      "Epoch 93, Iteration 30, Loss: 0.9181513905525207\n",
      "Epoch 93, Iteration 40, Loss: 0.9128111600875854\n",
      "Epoch 93, Iteration 50, Loss: 0.9059797048568725\n",
      "Epoch 93, Iteration 60, Loss: 0.9003531515598298\n",
      "Epoch 93, Iteration 70, Loss: 0.8909480929374695\n",
      "Epoch 93, Iteration 80, Loss: 0.883442485332489\n",
      "Epoch 93, Iteration 90, Loss: 0.8777796149253845\n",
      "Epoch 93, Iteration 100, Loss: 0.8692907929420471\n",
      "Epoch 93, Iteration 110, Loss: 0.8675504803657532\n",
      "Epoch 93, Iteration 120, Loss: 0.8692724525928497\n",
      "Epoch 93, Iteration 130, Loss: 0.8721118927001953\n",
      "Epoch 93, Iteration 140, Loss: 0.8717393398284912\n",
      "Epoch 93, Iteration 150, Loss: 0.873747706413269\n",
      "Epoch 93, Iteration 160, Loss: 0.8740251123905182\n",
      "Epoch 93, Iteration 170, Loss: 0.8793792068958283\n",
      "Epoch 93, Iteration 180, Loss: 0.8868263542652131\n",
      "Epoch 93, Iteration 190, Loss: 0.8911123752593995\n",
      "Epoch 94, Iteration 0, Loss: 0.09043811559677124\n",
      "Epoch 94, Iteration 10, Loss: 0.9027443647384643\n",
      "Epoch 94, Iteration 20, Loss: 0.9141407251358032\n",
      "Epoch 94, Iteration 30, Loss: 0.9220843195915223\n",
      "Epoch 94, Iteration 40, Loss: 0.9167556405067444\n",
      "Epoch 94, Iteration 50, Loss: 0.9099967777729034\n",
      "Epoch 94, Iteration 60, Loss: 0.9026840806007386\n",
      "Epoch 94, Iteration 70, Loss: 0.8979491412639617\n",
      "Epoch 94, Iteration 80, Loss: 0.8892569005489349\n",
      "Epoch 94, Iteration 90, Loss: 0.8794468522071839\n",
      "Epoch 94, Iteration 100, Loss: 0.8773744404315948\n",
      "Epoch 94, Iteration 110, Loss: 0.8734308779239655\n",
      "Epoch 94, Iteration 120, Loss: 0.8729582369327545\n",
      "Epoch 94, Iteration 130, Loss: 0.8720615148544312\n",
      "Epoch 94, Iteration 140, Loss: 0.8753050982952117\n",
      "Epoch 94, Iteration 150, Loss: 0.8777333319187164\n",
      "Epoch 94, Iteration 160, Loss: 0.8793371737003326\n",
      "Epoch 94, Iteration 170, Loss: 0.8842169046401978\n",
      "Epoch 94, Iteration 180, Loss: 0.8861777722835541\n",
      "Epoch 94, Iteration 190, Loss: 0.8964385449886322\n",
      "Epoch 95, Iteration 0, Loss: 0.08905596733093261\n",
      "Epoch 95, Iteration 10, Loss: 0.9067019641399383\n",
      "Epoch 95, Iteration 20, Loss: 0.9244256377220154\n",
      "Epoch 95, Iteration 30, Loss: 0.9301973640918731\n",
      "Epoch 95, Iteration 40, Loss: 0.9279743015766144\n",
      "Epoch 95, Iteration 50, Loss: 0.918541693687439\n",
      "Epoch 95, Iteration 60, Loss: 0.9132292628288269\n",
      "Epoch 95, Iteration 70, Loss: 0.9086620807647705\n",
      "Epoch 95, Iteration 80, Loss: 0.8981682538986206\n",
      "Epoch 95, Iteration 90, Loss: 0.8986085593700409\n",
      "Epoch 95, Iteration 100, Loss: 0.8919233739376068\n",
      "Epoch 95, Iteration 110, Loss: 0.8860427916049958\n",
      "Epoch 95, Iteration 120, Loss: 0.8864013493061066\n",
      "Epoch 95, Iteration 130, Loss: 0.8871673285961151\n",
      "Epoch 95, Iteration 140, Loss: 0.8825343608856201\n",
      "Epoch 95, Iteration 150, Loss: 0.8892978489398956\n",
      "Epoch 95, Iteration 160, Loss: 0.8908721327781677\n",
      "Epoch 95, Iteration 170, Loss: 0.8948375880718231\n",
      "Epoch 95, Iteration 180, Loss: 0.897696602344513\n",
      "Epoch 95, Iteration 190, Loss: 0.9027211427688598\n",
      "Epoch 96, Iteration 0, Loss: 0.08931573033332825\n",
      "Epoch 96, Iteration 10, Loss: 0.9161483705043793\n",
      "Epoch 96, Iteration 20, Loss: 0.9234271049499512\n",
      "Epoch 96, Iteration 30, Loss: 0.9299864411354065\n",
      "Epoch 96, Iteration 40, Loss: 0.9249577462673187\n",
      "Epoch 96, Iteration 50, Loss: 0.9217415869235992\n",
      "Epoch 96, Iteration 60, Loss: 0.9113718748092652\n",
      "Epoch 96, Iteration 70, Loss: 0.9123328149318695\n",
      "Epoch 96, Iteration 80, Loss: 0.8996622562408447\n",
      "Epoch 96, Iteration 90, Loss: 0.8984897315502167\n",
      "Epoch 96, Iteration 100, Loss: 0.8870077252388\n",
      "Epoch 96, Iteration 110, Loss: 0.8893726527690887\n",
      "Epoch 96, Iteration 120, Loss: 0.8866352379322052\n",
      "Epoch 96, Iteration 130, Loss: 0.8921918869018555\n",
      "Epoch 96, Iteration 140, Loss: 0.8936939358711242\n",
      "Epoch 96, Iteration 150, Loss: 0.8948994278907776\n",
      "Epoch 96, Iteration 160, Loss: 0.8963132202625275\n",
      "Epoch 96, Iteration 170, Loss: 0.9018012106418609\n",
      "Epoch 96, Iteration 180, Loss: 0.9018926203250885\n",
      "Epoch 96, Iteration 190, Loss: 0.9095564842224121\n",
      "Epoch 97, Iteration 0, Loss: 0.09040674567222595\n",
      "Epoch 97, Iteration 10, Loss: 0.9245469093322753\n",
      "Epoch 97, Iteration 20, Loss: 0.9355336010456086\n",
      "Epoch 97, Iteration 30, Loss: 0.9385799825191498\n",
      "Epoch 97, Iteration 40, Loss: 0.9332118630409241\n",
      "Epoch 97, Iteration 50, Loss: 0.9298158705234527\n",
      "Epoch 97, Iteration 60, Loss: 0.9204849600791931\n",
      "Epoch 97, Iteration 70, Loss: 0.9169149518013\n",
      "Epoch 97, Iteration 80, Loss: 0.9075850427150727\n",
      "Epoch 97, Iteration 90, Loss: 0.901435112953186\n",
      "Epoch 97, Iteration 100, Loss: 0.8988857567310333\n",
      "Epoch 97, Iteration 110, Loss: 0.8942244946956635\n",
      "Epoch 97, Iteration 120, Loss: 0.8960056006908417\n",
      "Epoch 97, Iteration 130, Loss: 0.8914319038391113\n",
      "Epoch 97, Iteration 140, Loss: 0.8907099545001984\n",
      "Epoch 97, Iteration 150, Loss: 0.8927778780460358\n",
      "Epoch 97, Iteration 160, Loss: 0.8903362095355988\n",
      "Epoch 97, Iteration 170, Loss: 0.8977687120437622\n",
      "Epoch 97, Iteration 180, Loss: 0.8995978713035584\n",
      "Epoch 97, Iteration 190, Loss: 0.8990919709205627\n",
      "Epoch 98, Iteration 0, Loss: 0.0911688506603241\n",
      "Epoch 98, Iteration 10, Loss: 0.9077594101428985\n",
      "Epoch 98, Iteration 20, Loss: 0.9279128968715668\n",
      "Epoch 98, Iteration 30, Loss: 0.9258344173431396\n",
      "Epoch 98, Iteration 40, Loss: 0.9191071391105652\n",
      "Epoch 98, Iteration 50, Loss: 0.9153391897678376\n",
      "Epoch 98, Iteration 60, Loss: 0.9070627987384796\n",
      "Epoch 98, Iteration 70, Loss: 0.9012513279914856\n",
      "Epoch 98, Iteration 80, Loss: 0.8927327632904053\n",
      "Epoch 98, Iteration 90, Loss: 0.8872856855392456\n",
      "Epoch 98, Iteration 100, Loss: 0.8796360492706299\n",
      "Epoch 98, Iteration 110, Loss: 0.8806840300559997\n",
      "Epoch 98, Iteration 120, Loss: 0.879420030117035\n",
      "Epoch 98, Iteration 130, Loss: 0.8795288741588593\n",
      "Epoch 98, Iteration 140, Loss: 0.8792486369609833\n",
      "Epoch 98, Iteration 150, Loss: 0.879021269083023\n",
      "Epoch 98, Iteration 160, Loss: 0.88214191198349\n",
      "Epoch 98, Iteration 170, Loss: 0.8860435128211975\n",
      "Epoch 98, Iteration 180, Loss: 0.8880050539970398\n",
      "Epoch 98, Iteration 190, Loss: 0.8984111726284028\n",
      "Epoch 99, Iteration 0, Loss: 0.08936641812324524\n",
      "Epoch 99, Iteration 10, Loss: 0.9059235394001007\n",
      "Epoch 99, Iteration 20, Loss: 0.9208154201507568\n",
      "Epoch 99, Iteration 30, Loss: 0.9227183043956757\n",
      "Epoch 99, Iteration 40, Loss: 0.9183596789836883\n",
      "Epoch 99, Iteration 50, Loss: 0.9180842995643616\n",
      "Epoch 99, Iteration 60, Loss: 0.9050689816474915\n",
      "Epoch 99, Iteration 70, Loss: 0.9024624347686767\n",
      "Epoch 99, Iteration 80, Loss: 0.8954524397850037\n",
      "Epoch 99, Iteration 90, Loss: 0.8877209663391114\n",
      "Epoch 99, Iteration 100, Loss: 0.8850237607955933\n",
      "Epoch 99, Iteration 110, Loss: 0.8794360041618348\n",
      "Epoch 99, Iteration 120, Loss: 0.8749191105365753\n",
      "Epoch 99, Iteration 130, Loss: 0.878224915266037\n",
      "Epoch 99, Iteration 140, Loss: 0.8805758237838746\n",
      "Epoch 99, Iteration 150, Loss: 0.8789160907268524\n",
      "Epoch 99, Iteration 160, Loss: 0.8826289117336273\n",
      "Epoch 99, Iteration 170, Loss: 0.8877926528453827\n",
      "Epoch 99, Iteration 180, Loss: 0.8915779829025269\n",
      "Epoch 99, Iteration 190, Loss: 0.8940395951271057\n",
      "Epoch 100, Iteration 0, Loss: 0.09005631804466248\n",
      "Epoch 100, Iteration 10, Loss: 0.9117641687393189\n",
      "Epoch 100, Iteration 20, Loss: 0.9243307650089264\n",
      "Epoch 100, Iteration 30, Loss: 0.925585001707077\n",
      "Epoch 100, Iteration 40, Loss: 0.9221467137336731\n",
      "Epoch 100, Iteration 50, Loss: 0.9187486171722412\n",
      "Epoch 100, Iteration 60, Loss: 0.9078251361846924\n",
      "Epoch 100, Iteration 70, Loss: 0.9055729389190674\n",
      "Epoch 100, Iteration 80, Loss: 0.9017517983913421\n",
      "Epoch 100, Iteration 90, Loss: 0.8871700227260589\n",
      "Epoch 100, Iteration 100, Loss: 0.8839816212654114\n",
      "Epoch 100, Iteration 110, Loss: 0.8802559316158295\n",
      "Epoch 100, Iteration 120, Loss: 0.881408566236496\n",
      "Epoch 100, Iteration 130, Loss: 0.8791121780872345\n",
      "Epoch 100, Iteration 140, Loss: 0.8776766955852509\n",
      "Epoch 100, Iteration 150, Loss: 0.8759454131126404\n",
      "Epoch 100, Iteration 160, Loss: 0.881745707988739\n",
      "Epoch 100, Iteration 170, Loss: 0.8847232282161712\n",
      "Epoch 100, Iteration 180, Loss: 0.8867358028888702\n",
      "Epoch 100, Iteration 190, Loss: 0.8933991074562073\n"
     ]
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T23:41:35.076453Z",
     "start_time": "2024-05-25T23:41:35.063077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract embeddings\n",
    "node_embeddings = node2vec.embedding.weight.data.cpu().numpy()\n",
    "\n",
    "# Update node features with embeddings\n",
    "data.x = torch.tensor(node_embeddings, dtype=torch.float)"
   ],
   "id": "4f2994a9c90aef5c",
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T23:41:36.804909Z",
     "start_time": "2024-05-25T23:41:36.792345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GAE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GAE, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, pos_edge_index, neg_edge_index):\n",
    "        pos_pred = (z[pos_edge_index[0].long()] * z[pos_edge_index[1].long()]).sum(dim=1)\n",
    "        neg_pred = (z[neg_edge_index[0].long()] * z[neg_edge_index[1].long()]).sum(dim=1)\n",
    "        return pos_pred, neg_pred\n",
    "\n",
    "    def forward(self, data):\n",
    "        z = self.encode(data.x, data.train_pos_edge_index)\n",
    "        return z"
   ],
   "id": "280a1a320e603e0a",
   "outputs": [],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T23:41:37.451712Z",
     "start_time": "2024-05-25T23:41:37.439264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize and train GAE model as before\n",
    "model = GAE(data.num_node_features, 32)  # Adjust dimensions as needed\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ],
   "id": "d9923f5f9b0fdb86",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T23:41:38.245619Z",
     "start_time": "2024-05-25T23:41:38.237587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.train_pos_edge_index)\n",
    "    pos_pred, neg_pred = model.decode(z, data.train_pos_edge_index, data.train_neg_edge_index)\n",
    "    pos_loss = loss_fn(pos_pred, torch.ones_like(pos_pred))\n",
    "    neg_loss = loss_fn(neg_pred, torch.zeros_like(neg_pred))\n",
    "    loss = pos_loss + neg_loss\n",
    "    if torch.isnan(loss) or torch.isinf(loss):\n",
    "        print(\"Warning: NaN or Inf loss detected\")\n",
    "        return float('inf')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ],
   "id": "d59e18cf369aff0b",
   "outputs": [],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T23:47:12.298538Z",
     "start_time": "2024-05-25T23:41:39.769122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(1000):\n",
    "    loss = train(data)\n",
    "    if loss == float('inf'):\n",
    "        break\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss}')"
   ],
   "id": "819793948be2b1e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.5716328620910645\n",
      "Epoch 100, Loss: 0.9737919569015503\n",
      "Epoch 200, Loss: 0.934123158454895\n",
      "Epoch 300, Loss: 0.9196598529815674\n",
      "Epoch 400, Loss: 0.9115588665008545\n",
      "Epoch 500, Loss: 0.9057427644729614\n",
      "Epoch 600, Loss: 0.901170015335083\n",
      "Epoch 700, Loss: 0.8973367810249329\n",
      "Epoch 800, Loss: 0.8938947319984436\n",
      "Epoch 900, Loss: 0.8904709219932556\n"
     ]
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T23:47:12.304523Z",
     "start_time": "2024-05-25T23:47:12.298538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(data, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(data.x, data.train_pos_edge_index)\n",
    "        pos_pred = torch.sigmoid((z[data.test_pos_edge_index[0].long()] * z[data.test_pos_edge_index[1].long()]).sum(dim=1)).cpu().numpy()\n",
    "        neg_pred = torch.sigmoid((z[data.test_neg_edge_index[0].long()] * z[data.test_neg_edge_index[1].long()]).sum(dim=1)).cpu().numpy()\n",
    "\n",
    "    y_true = np.concatenate([np.ones(pos_pred.shape[0]), np.zeros(neg_pred.shape[0])])\n",
    "    y_pred = np.concatenate([pos_pred, neg_pred])\n",
    "\n",
    "    auc_roc = roc_auc_score(y_true, y_pred)\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "\n",
    "    return auc_roc, ap"
   ],
   "id": "dd65d2d7892ba243",
   "outputs": [],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T23:47:12.472990Z",
     "start_time": "2024-05-25T23:47:12.304523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "auc_roc, ap = evaluate_model(data, model)\n",
    "print(f\"AUC-ROC: {auc_roc:.4f}, AP: {ap:.4f}\")"
   ],
   "id": "37b2a03df1f5ce83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.9703, AP: 0.9558\n"
     ]
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T23:47:12.479629Z",
     "start_time": "2024-05-25T23:47:12.472990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_best_candidates(job_descriptions, resumes, z):\n",
    "    job_ids = job_descriptions['job_id'].values\n",
    "    candidate_ids = resumes['candidate_id'].values + len(job_descriptions)\n",
    "\n",
    "    predictions = []\n",
    "    for job_id, job_title, job_skills in zip(job_ids, job_descriptions['job_title'], job_descriptions['skills']):\n",
    "        best_match = None\n",
    "        best_score = float('-inf')\n",
    "        for candidate_id, category, candidate_job_title, skills in zip(\n",
    "                resumes['candidate_id'], resumes['category'], resumes['job_title'], resumes['skills']):\n",
    "            candidate_index = candidate_id + len(job_descriptions) - 1\n",
    "            job_index = job_id - 1\n",
    "\n",
    "            # Ensure indices are within range\n",
    "            if candidate_index >= z.size(0) or job_index >= z.size(0):\n",
    "                continue\n",
    "\n",
    "            score = torch.sigmoid(torch.dot(z[job_index], z[candidate_index])).item()\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = (job_id, job_title, candidate_id, candidate_job_title, category, skills, score)\n",
    "\n",
    "        if best_match:\n",
    "            job_id, job_title, candidate_id, candidate_job_title, category, skills, score = best_match\n",
    "            match_percentage = score * 100  # Assuming the score is between 0 and 1\n",
    "            predictions.append({\n",
    "                \"Job ID\": job_id,\n",
    "                \"Job Title\": le_job_title.inverse_transform([job_title])[0],\n",
    "                \"Candidate ID\": candidate_id,\n",
    "                \"Candidate Job Title\": le_job_title.inverse_transform([candidate_job_title])[0],\n",
    "                \"Candidate Category\": le_category.inverse_transform([category])[0],\n",
    "                \"Match Percentage\": match_percentage,\n",
    "                \"Mutual Skills\": set(job_skills).intersection(set(skills)),\n",
    "                \"Job Skills\": job_skills,\n",
    "                \"Candidate Skills\": skills\n",
    "            })\n",
    "\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "    return predictions_df"
   ],
   "id": "d9b4e3dd15402801",
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T23:47:12.582631Z",
     "start_time": "2024-05-25T23:47:12.479629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "with torch.no_grad():\n",
    "    z = model.encode(data.x, data.train_pos_edge_index)"
   ],
   "id": "455e4c57053c84e",
   "outputs": [],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T23:47:14.270751Z",
     "start_time": "2024-05-25T23:47:12.582631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions_df = predict_best_candidates(job_descriptions.sample(frac=1, random_state=random_seed)[:100], resumes, z)\n",
    "\n",
    "torch.save(model.state_dict(), f\"./models/gcn-recommendation-system-{auc_roc:.2f}-acc-{uuid.uuid4()}-{time.strftime('%Y%m%d-%H%M%S')}-v1.pth\")"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T23:47:14.281396Z",
     "start_time": "2024-05-25T23:47:14.270751Z"
    }
   },
   "cell_type": "code",
   "source": "predictions_df.head(1000)",
   "id": "3d6f035b4107326f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Job ID                        Job Title  Candidate ID  \\\n",
       "0     6253            network administrator          1646   \n",
       "1     4685  customer service representative          1022   \n",
       "2     1732              procurement manager          1632   \n",
       "3     4743                account executive          1022   \n",
       "4     4522                    legal counsel          2236   \n",
       "..     ...                              ...           ...   \n",
       "95    3788             supply chain manager          1968   \n",
       "96    9190                   ux/ui designer           800   \n",
       "97    7826                 graphic designer          1646   \n",
       "98    7540           procurement specialist          1604   \n",
       "99    7232                 technical writer          1022   \n",
       "\n",
       "            Candidate Job Title Candidate Category  Match Percentage  \\\n",
       "0           product specialists            apparel         93.553579   \n",
       "1                         sales              sales         93.024325   \n",
       "2              jobs coordinator            apparel         99.999988   \n",
       "3                         sales              sales         86.895841   \n",
       "4          principal consultant            banking         98.519576   \n",
       "..                          ...                ...               ...   \n",
       "95  construction safety officer       construction         99.876010   \n",
       "96     group fitness instructor            fitness         82.718599   \n",
       "97          product specialists            apparel         90.890688   \n",
       "98                      stylist            apparel         64.016950   \n",
       "99                        sales              sales         94.238794   \n",
       "\n",
       "   Mutual Skills                                         Job Skills  \\\n",
       "0             {}  [system administration, server maintenance, ac...   \n",
       "1             {}  [live chat support, online customer communicat...   \n",
       "2             {}  [procurement processes, vendor assessment, con...   \n",
       "3             {}  [key account management, sales strategy develo...   \n",
       "4             {}  [intellectual property law, trademark and pate...   \n",
       "..           ...                                                ...   \n",
       "95            {}  [demand forecasting, inventory management, dat...   \n",
       "96            {}  [u, i design principles and best practices, gr...   \n",
       "97            {}  [user interface, u, i, user experience, u, x, ...   \n",
       "98            {}  [procurement strategies, supplier management, ...   \n",
       "99            {}  [writing skills, content creation, s, e, o kno...   \n",
       "\n",
       "                                     Candidate Skills  \n",
       "0   [business, support, front end, documentation, ...  \n",
       "1   [business, support, medium, commerce, bash, ma...  \n",
       "2   [business, release, business administration, s...  \n",
       "3   [business, support, medium, commerce, bash, ma...  \n",
       "4   [interaction, business, project management, wo...  \n",
       "..                                                ...  \n",
       "95                                       [monitoring]  \n",
       "96                                                 []  \n",
       "97  [business, support, front end, documentation, ...  \n",
       "98         [support, business, accounting, marketing]  \n",
       "99  [business, support, medium, commerce, bash, ma...  \n",
       "\n",
       "[100 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job ID</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Candidate ID</th>\n",
       "      <th>Candidate Job Title</th>\n",
       "      <th>Candidate Category</th>\n",
       "      <th>Match Percentage</th>\n",
       "      <th>Mutual Skills</th>\n",
       "      <th>Job Skills</th>\n",
       "      <th>Candidate Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6253</td>\n",
       "      <td>network administrator</td>\n",
       "      <td>1646</td>\n",
       "      <td>product specialists</td>\n",
       "      <td>apparel</td>\n",
       "      <td>93.553579</td>\n",
       "      <td>{}</td>\n",
       "      <td>[system administration, server maintenance, ac...</td>\n",
       "      <td>[business, support, front end, documentation, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4685</td>\n",
       "      <td>customer service representative</td>\n",
       "      <td>1022</td>\n",
       "      <td>sales</td>\n",
       "      <td>sales</td>\n",
       "      <td>93.024325</td>\n",
       "      <td>{}</td>\n",
       "      <td>[live chat support, online customer communicat...</td>\n",
       "      <td>[business, support, medium, commerce, bash, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1732</td>\n",
       "      <td>procurement manager</td>\n",
       "      <td>1632</td>\n",
       "      <td>jobs coordinator</td>\n",
       "      <td>apparel</td>\n",
       "      <td>99.999988</td>\n",
       "      <td>{}</td>\n",
       "      <td>[procurement processes, vendor assessment, con...</td>\n",
       "      <td>[business, release, business administration, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4743</td>\n",
       "      <td>account executive</td>\n",
       "      <td>1022</td>\n",
       "      <td>sales</td>\n",
       "      <td>sales</td>\n",
       "      <td>86.895841</td>\n",
       "      <td>{}</td>\n",
       "      <td>[key account management, sales strategy develo...</td>\n",
       "      <td>[business, support, medium, commerce, bash, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4522</td>\n",
       "      <td>legal counsel</td>\n",
       "      <td>2236</td>\n",
       "      <td>principal consultant</td>\n",
       "      <td>banking</td>\n",
       "      <td>98.519576</td>\n",
       "      <td>{}</td>\n",
       "      <td>[intellectual property law, trademark and pate...</td>\n",
       "      <td>[interaction, business, project management, wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3788</td>\n",
       "      <td>supply chain manager</td>\n",
       "      <td>1968</td>\n",
       "      <td>construction safety officer</td>\n",
       "      <td>construction</td>\n",
       "      <td>99.876010</td>\n",
       "      <td>{}</td>\n",
       "      <td>[demand forecasting, inventory management, dat...</td>\n",
       "      <td>[monitoring]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>9190</td>\n",
       "      <td>ux/ui designer</td>\n",
       "      <td>800</td>\n",
       "      <td>group fitness instructor</td>\n",
       "      <td>fitness</td>\n",
       "      <td>82.718599</td>\n",
       "      <td>{}</td>\n",
       "      <td>[u, i design principles and best practices, gr...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7826</td>\n",
       "      <td>graphic designer</td>\n",
       "      <td>1646</td>\n",
       "      <td>product specialists</td>\n",
       "      <td>apparel</td>\n",
       "      <td>90.890688</td>\n",
       "      <td>{}</td>\n",
       "      <td>[user interface, u, i, user experience, u, x, ...</td>\n",
       "      <td>[business, support, front end, documentation, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7540</td>\n",
       "      <td>procurement specialist</td>\n",
       "      <td>1604</td>\n",
       "      <td>stylist</td>\n",
       "      <td>apparel</td>\n",
       "      <td>64.016950</td>\n",
       "      <td>{}</td>\n",
       "      <td>[procurement strategies, supplier management, ...</td>\n",
       "      <td>[support, business, accounting, marketing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>7232</td>\n",
       "      <td>technical writer</td>\n",
       "      <td>1022</td>\n",
       "      <td>sales</td>\n",
       "      <td>sales</td>\n",
       "      <td>94.238794</td>\n",
       "      <td>{}</td>\n",
       "      <td>[writing skills, content creation, s, e, o kno...</td>\n",
       "      <td>[business, support, medium, commerce, bash, ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 152
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "21942676a9d862da",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
