{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# GAE",
   "id": "74f7ed965b90fc08",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Set random seed for reproducibility\n",
    "# random_seed = 42\n",
    "# np.random.seed(random_seed)\n",
    "# \n",
    "# # Load datasets\n",
    "# job_descriptions = pd.read_csv('./data/processed/job_descriptions_processed.csv')\n",
    "# resumes = pd.read_csv('./data/processed/resume-dataset-processed.csv', converters={'skills': literal_eval})\n",
    "# \n",
    "# # Shuffle job_descriptions and select the first 100 rows\n",
    "# job_descriptions = job_descriptions.sample(frac=1, random_state=random_seed).head(100)\n",
    "# \n",
    "# # Convert 'skills' column to list\n",
    "# job_descriptions['skills'] = job_descriptions['skills'].apply(literal_eval)"
   ],
   "id": "4991f8d84ef5ee92",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, VGAE\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import train_test_split_edges, negative_sampling\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from ast import literal_eval\n",
    "import numpy as np"
   ],
   "id": "a511aa2d122e9de1",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Load datasets\n",
    "job_descriptions = pd.read_csv('./data/processed/job_descriptions_processed.csv')\n",
    "resumes = pd.read_csv('./data/processed/general-resume-dataset-processed-v1.csv', converters={'skills': literal_eval})\n",
    "\n",
    "# Shuffle job_descriptions and select the first N rows\n",
    "job_descriptions = job_descriptions.sample(frac=1, random_state=random_seed).head(10000)\n",
    "\n",
    "# Convert 'skills' column to list\n",
    "job_descriptions['skills'] = job_descriptions['skills'].apply(literal_eval)"
   ],
   "id": "fa9cfddac8b5ada2",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Replace None values in job_title and category with a default value before encoding\n",
    "job_descriptions['job_title'].fillna('unknown', inplace=True)\n",
    "resumes['job_title'].fillna('unknown', inplace=True)\n",
    "resumes['category'].fillna('unknown', inplace=True)\n",
    "\n",
    "# Ensure job_ids and candidate_ids are correctly assigned\n",
    "job_descriptions['job_id'] = range(1, len(job_descriptions) + 1)\n",
    "resumes['candidate_id'] = range(1, len(resumes) + 1)\n",
    "\n",
    "# Add 'unknown' to the list of all titles and categories to handle unseen labels\n",
    "all_titles = job_descriptions['job_title'].tolist() + resumes['job_title'].tolist()\n",
    "all_titles.append('unknown')\n",
    "all_categories = resumes['category'].tolist()\n",
    "all_categories.append('unknown')"
   ],
   "id": "b70a742ea5564a74",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fit the label encoders\n",
    "le_job_title = LabelEncoder()\n",
    "le_category = LabelEncoder()\n",
    "le_job_title.fit(all_titles)\n",
    "le_category.fit(all_categories)\n",
    "\n",
    "# Transform the columns\n",
    "job_descriptions['job_title'] = le_job_title.transform(job_descriptions['job_title'])\n",
    "resumes['job_title'] = le_job_title.transform(resumes['job_title'])\n",
    "resumes['category'] = le_category.transform(resumes['category'])\n",
    "\n",
    "# Encode skills\n",
    "all_skills = set(skill for skills in job_descriptions['skills'].tolist() + resumes['skills'].tolist() for skill in skills)\n",
    "le_skills = {skill: i for i, skill in enumerate(all_skills)}"
   ],
   "id": "c49775725ec99b91",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create nodes and edges for the graph\n",
    "nodes = []\n",
    "edges = []\n",
    "node_features = []\n",
    "\n",
    "jobs_from_edges = []\n",
    "candidates_from_edges = []\n",
    "jobs_and_candidates_from_edges = []\n",
    "\n",
    "# Add job nodes\n",
    "for i, row in job_descriptions.iterrows():\n",
    "    nodes.append(row['job_id'])\n",
    "    skills_vector = [0] * len(le_skills)\n",
    "    if row['skills']:  # Check if skills are not empty\n",
    "        for skill in row['skills']:\n",
    "            skills_vector[le_skills[skill]] = 1\n",
    "    node_features.append([row['job_title'], row['min_experience']] + skills_vector)\n",
    "\n",
    "# Add resume nodes, using 'category' instead of 'job_title'\n",
    "for i, row in resumes.iterrows():\n",
    "    nodes.append(row['candidate_id'] + len(job_descriptions))\n",
    "    skills_vector = [0] * len(le_skills)\n",
    "    if row['skills']:  # Check if skills are not empty\n",
    "        for skill in row['skills']:\n",
    "            skills_vector[le_skills[skill]] = 1\n",
    "    node_features.append([row['job_title'], row['experience']] + skills_vector)\n",
    "\n",
    "# Add edges based on job_title overlap\n",
    "# for i, job in job_descriptions.iterrows():\n",
    "#     for j, resume in resumes.iterrows():\n",
    "#         if job['job_title'] == resume['job_title']:  # Changed from resume['job_title'] to resume['category']\n",
    "#             edges.append((job['job_id'], resume['candidate_id'] + len(job_descriptions)))\n",
    "\n",
    "def skills_overlap(job_skills, resume_skills):\n",
    "    return len(set(job_skills).intersection(set(resume_skills)))\n",
    "\n",
    "threshold = 1  # Set a threshold for the minimum number of overlapping skills\n",
    "\n",
    "# for i, job in job_descriptions.iterrows():\n",
    "#     for j, resume in resumes.iterrows():\n",
    "#         overlap = skills_overlap(job['skills'], resume['skills'])\n",
    "#         if overlap >= threshold:\n",
    "#             edges.append((job['job_id'], resume['candidate_id'] + len(job_descriptions)))\n",
    "\n",
    "for i, job in job_descriptions.iterrows():\n",
    "    for j, resume in resumes.iterrows():\n",
    "        if job['job_title'] == resume['job_title'] or skills_overlap(job['skills'], resume['skills']) >= threshold:\n",
    "            edges.append((job['job_id'], resume['candidate_id'] + len(job_descriptions)))\n",
    "            jobs_and_candidates_from_edges.append((job['job_id'], resume['candidate_id']))\n",
    "            jobs_from_edges.append(job['job_id'])\n",
    "            candidates_from_edges.append(resume['candidate_id'])"
   ],
   "id": "f4b872c380c1063b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "jobs_from_edges = set(jobs_from_edges)\n",
    "candidates_from_edges = set(candidates_from_edges)\n",
    "jobs_and_candidates_from_edges = set(jobs_and_candidates_from_edges)"
   ],
   "id": "bbd8424f8cbbe445",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Correct node indices\n",
    "num_job_nodes = len(job_descriptions)\n",
    "num_resume_nodes = len(resumes)\n",
    "total_nodes = num_job_nodes + num_resume_nodes\n",
    "\n",
    "# Reindex edges to ensure correct range\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "edge_index[0] = edge_index[0].clamp(0, total_nodes - 1)\n",
    "edge_index[1] = edge_index[1].clamp(0, total_nodes - 1)\n",
    "\n",
    "# Convert to torch tensors\n",
    "x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "# Create PyTorch Geometric data object\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# Ensure edge indices are within range\n",
    "data.edge_index = edge_index\n",
    "data.num_nodes = total_nodes\n",
    "\n",
    "# Splitting edges for training/validation\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "# Manually create negative edges for training\n",
    "neg_edge_index_train = negative_sampling(\n",
    "    edge_index=data.train_pos_edge_index,\n",
    "    num_nodes=data.num_nodes,\n",
    "    num_neg_samples=data.train_pos_edge_index.size(1)\n",
    ")\n",
    "data.train_neg_edge_index = neg_edge_index_train\n",
    "\n",
    "# Manually create negative edges for testing\n",
    "neg_edge_index_test = negative_sampling(\n",
    "    edge_index=data.test_pos_edge_index,\n",
    "    num_nodes=data.num_nodes,\n",
    "    num_neg_samples=data.test_pos_edge_index.size(1)\n",
    ")\n",
    "data.test_neg_edge_index = neg_edge_index_test"
   ],
   "id": "91f230b61ba4cc8a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class GAE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GAE, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, pos_edge_index, neg_edge_index):\n",
    "        pos_pred = (z[pos_edge_index[0].long()] * z[pos_edge_index[1].long()]).sum(dim=1)\n",
    "        neg_pred = (z[neg_edge_index[0].long()] * z[neg_edge_index[1].long()]).sum(dim=1)\n",
    "        return pos_pred, neg_pred\n",
    "\n",
    "    def forward(self, data):\n",
    "        z = self.encode(data.x, data.train_pos_edge_index)\n",
    "        return z"
   ],
   "id": "280a1a320e603e0a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize model, optimizer, and loss function\n",
    "model = GAE(data.num_node_features, 32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ],
   "id": "d9923f5f9b0fdb86",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training loop with better numerical stability checks\n",
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.train_pos_edge_index)\n",
    "    pos_pred, neg_pred = model.decode(z, data.train_pos_edge_index, data.train_neg_edge_index)\n",
    "    pos_loss = loss_fn(pos_pred, torch.ones_like(pos_pred))\n",
    "    neg_loss = loss_fn(neg_pred, torch.zeros_like(neg_pred))\n",
    "    loss = pos_loss + neg_loss\n",
    "    if torch.isnan(loss) or torch.isinf(loss):\n",
    "        print(\"Warning: NaN or Inf loss detected\")\n",
    "        return float('inf')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # scheduler.step()\n",
    "    return loss.item()"
   ],
   "id": "d59e18cf369aff0b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for epoch in range(1000):\n",
    "    loss = train(data)\n",
    "    if loss == float('inf'):\n",
    "        break\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss}')"
   ],
   "id": "819793948be2b1e8",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_model(data, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(data.x, data.train_pos_edge_index)\n",
    "        pos_pred = torch.sigmoid((z[data.test_pos_edge_index[0].long()] * z[data.test_pos_edge_index[1].long()]).sum(dim=1)).cpu().numpy()\n",
    "        neg_pred = torch.sigmoid((z[data.test_neg_edge_index[0].long()] * z[data.test_neg_edge_index[1].long()]).sum(dim=1)).cpu().numpy()\n",
    "\n",
    "    y_true = np.concatenate([np.ones(pos_pred.shape[0]), np.zeros(neg_pred.shape[0])])\n",
    "    y_pred = np.concatenate([pos_pred, neg_pred])\n",
    "\n",
    "    auc_roc = roc_auc_score(y_true, y_pred)\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "\n",
    "    return auc_roc, ap"
   ],
   "id": "dd65d2d7892ba243",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "auc_roc, ap = evaluate_model(data, model)\n",
    "print(f\"AUC-ROC: {auc_roc:.4f}, AP: {ap:.4f}\")"
   ],
   "id": "37b2a03df1f5ce83",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_best_candidates(job_descriptions, resumes, z):\n",
    "    job_ids = job_descriptions['job_id'].values\n",
    "    candidate_ids = resumes['candidate_id'].values + len(job_descriptions)\n",
    "\n",
    "    predictions = []\n",
    "    for job_id, job_title, job_skills in zip(job_ids, job_descriptions['job_title'], job_descriptions['skills']):\n",
    "        best_match = None\n",
    "        best_score = float('-inf')\n",
    "        for candidate_id, category, candidate_job_title, skills in zip(\n",
    "                resumes['candidate_id'], resumes['category'], resumes['job_title'], resumes['skills']):\n",
    "            candidate_index = candidate_id + len(job_descriptions) - 1\n",
    "            job_index = job_id - 1\n",
    "\n",
    "            # Ensure indices are within range\n",
    "            if candidate_index >= z.size(0) or job_index >= z.size(0):\n",
    "                continue\n",
    "\n",
    "            score = torch.sigmoid(torch.dot(z[job_index], z[candidate_index])).item()\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = (job_id, job_title, candidate_id, candidate_job_title, category, skills, score)\n",
    "\n",
    "        if best_match:\n",
    "            job_id, job_title, candidate_id, candidate_job_title, category, skills, score = best_match\n",
    "            match_percentage = score * 100  # Assuming the score is between 0 and 1\n",
    "            predictions.append({\n",
    "                \"Job ID\": job_id,\n",
    "                \"Job Title\": le_job_title.inverse_transform([job_title])[0],\n",
    "                \"Candidate ID\": candidate_id,\n",
    "                \"Candidate Job Title\": le_job_title.inverse_transform([candidate_job_title])[0],\n",
    "                \"Candidate Category\": le_category.inverse_transform([category])[0],\n",
    "                \"Match Percentage\": match_percentage,\n",
    "                \"Mutual Skills\": set(job_skills).intersection(set(skills)),\n",
    "                \"Job Skills\": job_skills,\n",
    "                \"Candidate Skills\": skills\n",
    "            })\n",
    "\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "    return predictions_df"
   ],
   "id": "d9b4e3dd15402801",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "with torch.no_grad():\n",
    "    z = model.encode(data.x, data.train_pos_edge_index)"
   ],
   "id": "455e4c57053c84e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions_df = predict_best_candidates(job_descriptions[job_descriptions['job_id'].isin(jobs_from_edges)].sample(frac=1, random_state=random_seed)[:100], resumes[resumes['candidate_id'].isin(candidates_from_edges)], z)\n",
    "\n",
    "torch.save(model.state_dict(), f\"./models/gcn-recommendation-system-{auc_roc:.2f}-acc-{uuid.uuid4()}-{time.strftime('%Y%m%d-%H%M%S')}-v1.pth\")"
   ],
   "id": "initial_id",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "predictions_df.head(1000)",
   "id": "3d6f035b4107326f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "21942676a9d862da",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
