{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "nltk.download(['stopwords', 'wordnet'])",
   "id": "c9be9623e0aee340",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def parse_experience_expectations(experience_str):\n",
    "    match = re.match(r'(\\d+)\\s+to\\s+(\\d+)\\s+Years', experience_str)\n",
    "    if match:\n",
    "        min_exp, pref_exp = match.groups()\n",
    "        return int(min_exp) * 12, int(pref_exp) * 12\n",
    "    return None, None\n",
    "\n",
    "def split_skills(skills_str):\n",
    "    pattern = re.compile(r'([A-Z][a-z]*(?:\\s[a-z]+)*)')\n",
    "    skills = pattern.findall(skills_str)\n",
    "    skills = [skill.lower() for skill in skills]\n",
    "    return skills\n",
    "\n",
    "jobs_df = pd.read_csv('./data/training/job_descriptions.csv')\n",
    "# jobs_df = jobs_df.reindex(np.random.permutation(jobs_df.index))\n",
    "# jobs_df = jobs_df.copy().iloc[0:10,]\n",
    "\n",
    "experience = jobs_df['Experience'].apply(lambda x: pd.Series(parse_experience_expectations(x)))\n",
    "jobs_df = pd.DataFrame({\n",
    "    'job_id': jobs_df['Job Id'],\n",
    "    'job_title': jobs_df['Job Title'].str.lower(),\n",
    "    'skills': jobs_df['skills'].apply(split_skills),\n",
    "    'min_experience': experience[0],\n",
    "    'max_experience': experience[1],\n",
    "})"
   ],
   "id": "7bd2ded8f38c30b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_spacy_pattern(title):\n",
    "    words = title.split()\n",
    "    pattern = [{\"LOWER\": word.lower()} for word in words]\n",
    "    return {\"label\": \"TITLE\", \"pattern\": pattern}\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "skill_pattern_path = \"./data/preprocessing/jz_skill_patterns.jsonl\"\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "ruler.from_disk(skill_pattern_path)\n",
    "\n",
    "titles_df = pd.read_json('./data/preprocessing/job-titles.json')\n",
    "title_patterns = [create_spacy_pattern(title) for title in titles_df['job-titles'].to_numpy()]\n",
    "ruler.add_patterns(title_patterns)\n",
    "\n",
    "def get_skills(doc):\n",
    "    skills = [ent.text for ent in doc.ents if ent.label_ == \"SKILL\"]\n",
    "    return list(set(skills))\n",
    "\n",
    "def get_title(doc):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"TITLE\":\n",
    "            return ent.text\n",
    "    return None\n",
    "\n",
    "def extract_experience(cv_text):\n",
    "    # Define a pattern for experience\n",
    "    experience_pattern = r'\\b(\\d+)\\s*(year|month)\\b'\n",
    "\n",
    "    # Find all experience mentions in the CV text\n",
    "    experience_found = re.findall(experience_pattern, cv_text)\n",
    "\n",
    "    # Filter out None or empty entries and sum up experience\n",
    "    total_months = 0\n",
    "    for value, unit in experience_found:\n",
    "        if unit == \"year\":\n",
    "            total_months += int(value) * 12\n",
    "        elif unit == \"month\":\n",
    "            total_months += int(value)\n",
    "\n",
    "    return total_months\n",
    "\n",
    "def clean_text(text):\n",
    "    review = re.sub('(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\"', \" \", text)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    lm = WordNetLemmatizer()\n",
    "    review = [lm.lemmatize(word) for word in review if word not in set(stopwords.words(\"english\"))]\n",
    "    return \" \".join(review)\n",
    "\n",
    "resume_df = pd.read_csv('./data/training/resume-dataset.csv')\n",
    "resume_df['candidate_id'] = range(1, len(resume_df) + 1)\n",
    "# resume_df = resume_df.reindex(np.random.permutation(resume_df.index))\n",
    "# resume_df = resume_df.copy().iloc[0:10,]\n",
    "\n",
    "processed_resumes = []\n",
    "for _, row in resume_df.iterrows():\n",
    "    text = row['Resume']\n",
    "    candidate_id = row['candidate_id']\n",
    "    cv_text = clean_text(text)\n",
    "    doc = nlp(cv_text)\n",
    "    skills = get_skills(doc)\n",
    "    title = get_title(doc)\n",
    "    experience_data = extract_experience(cv_text)\n",
    "    processed_resumes.append({ \"candidate_id\": candidate_id, \"job_title\": title, \"skills\": skills, \"experience\": experience_data })\n",
    "\n",
    "resume_df = pd.DataFrame(processed_resumes)\n",
    "resume_df.head()"
   ],
   "id": "4c712d761aed549c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "jobs_df.to_csv('./data/processed/job_descriptions_processed.csv')\n",
    "resume_df.to_csv(\"./data/processed/resume-dataset-processed.csv\")"
   ],
   "id": "804f14903b037d90",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
