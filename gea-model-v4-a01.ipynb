{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# GAE",
   "id": "74f7ed965b90fc08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import train_test_split_edges, negative_sampling\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.nn import Node2Vec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "a511aa2d122e9de1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Load datasets\n",
    "job_descriptions = pd.read_csv('./data/processed/job_descriptions_processed-a01.csv')\n",
    "resumes = pd.read_csv('./data/processed/general-resume-dataset-processed-v1-a01.csv', converters={'skills': literal_eval})\n",
    "\n",
    "# Shuffle job_descriptions and select the first N rows\n",
    "job_descriptions = job_descriptions.sample(frac=1, random_state=random_seed).head(25000)\n",
    "\n",
    "# Convert 'skills' column to list\n",
    "job_descriptions['skills'] = job_descriptions['skills'].apply(literal_eval)"
   ],
   "id": "fa9cfddac8b5ada2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Replace None values in job_title and category with a default value before encoding\n",
    "job_descriptions['job_title'].fillna('unknown', inplace=True)\n",
    "resumes['job_title'].fillna('unknown', inplace=True)\n",
    "resumes['category'].fillna('unknown', inplace=True)\n",
    "\n",
    "# Ensure job_ids and candidate_ids are correctly assigned\n",
    "job_descriptions['job_id'] = range(1, len(job_descriptions) + 1)\n",
    "resumes['candidate_id'] = range(1, len(resumes) + 1)\n",
    "\n",
    "# Add 'unknown' to the list of all titles and categories to handle unseen labels\n",
    "all_titles = job_descriptions['job_title'].tolist() + resumes['job_title'].tolist()\n",
    "all_titles.append('unknown')\n",
    "all_categories = resumes['category'].tolist()\n",
    "all_categories.append('unknown')"
   ],
   "id": "b70a742ea5564a74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fit the label encoders\n",
    "le_job_title = LabelEncoder()\n",
    "le_category = LabelEncoder()\n",
    "le_job_title.fit(all_titles)\n",
    "le_category.fit(all_categories)\n",
    "\n",
    "# Transform the columns\n",
    "job_descriptions['job_title'] = le_job_title.transform(job_descriptions['job_title'])\n",
    "resumes['job_title'] = le_job_title.transform(resumes['job_title'])\n",
    "resumes['category'] = le_category.transform(resumes['category'])\n",
    "\n",
    "# Encode skills\n",
    "all_skills = set(skill for skills in job_descriptions['skills'].tolist() + resumes['skills'].tolist() for skill in skills)\n",
    "le_skills = {skill: i for i, skill in enumerate(all_skills)}"
   ],
   "id": "c49775725ec99b91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "edge_index = torch.load('./data/features/edge_index-25k-a01.pt')\n",
    "edge_weight = torch.load('./data/features/edge_weight-25k-a01.pt')\n",
    "nodes_length = 0\n",
    "with open('./data/features/nodes_len-a01.txt', 'r') as file:\n",
    "    nodes_length = np.int64(file.read())"
   ],
   "id": "fedaf4988a9294bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x = torch.load('./data/features/x-25k-a01.pt')",
   "id": "c620e7b3c4d55285",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = Data(x=x, edge_index=edge_index, edge_weight=edge_weight)\n",
    "original_edge_index = data.edge_index.clone()\n",
    "data = train_test_split_edges(data)"
   ],
   "id": "88519b6f8f6d76b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a dictionary to map edge indices to their weights\n",
    "edge_weight_dict = {tuple(edge_index[:, i].tolist()): edge_weight[i].item() for i in range(edge_index.size(1))}\n",
    "\n",
    "def get_edge_weights(edge_index, edge_weight_dict):\n",
    "    weights = []\n",
    "    for i in range(edge_index.size(1)):\n",
    "        edge = tuple(edge_index[:, i].tolist())\n",
    "        weight = edge_weight_dict.get(edge, 0)  # Default to 0 if edge not found\n",
    "        weights.append(weight)\n",
    "    return torch.tensor(weights, dtype=torch.float)"
   ],
   "id": "92a9f77324216cda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_edge_weights = get_edge_weights(data.train_pos_edge_index, edge_weight_dict)\n",
    "test_edge_weights = get_edge_weights(data.test_pos_edge_index, edge_weight_dict)\n",
    "val_edge_weights = get_edge_weights(data.val_pos_edge_index, edge_weight_dict)"
   ],
   "id": "3482204b0f2c8be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data.train_pos_edge_weight = train_edge_weights\n",
    "data.test_pos_edge_weight = test_edge_weights\n",
    "data.val_pos_edge_weight = val_edge_weights\n",
    "\n",
    "# Manually create negative edges for training\n",
    "neg_edge_index_train = negative_sampling(\n",
    "    edge_index=data.train_pos_edge_index,\n",
    "    num_nodes=data.num_nodes,\n",
    "    num_neg_samples=data.train_pos_edge_index.size(1),\n",
    ")\n",
    "data.train_neg_edge_index = neg_edge_index_train\n",
    "\n",
    "# Assign zero weights to negative edges for training\n",
    "neg_train_edge_weights = torch.zeros(neg_edge_index_train.size(1), dtype=torch.float)\n",
    "\n",
    "# Manually create negative edges for testing\n",
    "neg_edge_index_test = negative_sampling(\n",
    "    edge_index=data.test_pos_edge_index,\n",
    "    num_nodes=data.num_nodes,\n",
    "    num_neg_samples=data.test_pos_edge_index.size(1),\n",
    ")\n",
    "data.test_neg_edge_index = neg_edge_index_test\n",
    "\n",
    "# Assign zero weights to negative edges for testing\n",
    "neg_test_edge_weights = torch.zeros(neg_edge_index_test.size(1), dtype=torch.float)\n",
    "\n",
    "# Combine positive and negative edge weights for training\n",
    "data.train_neg_edge_weight = neg_train_edge_weights\n",
    "\n",
    "# Combine positive and negative edge weights for testing\n",
    "data.test_neg_edge_weight = neg_test_edge_weights\n",
    "\n",
    "# Ensure edge_index tensors are of integer type\n",
    "data.train_pos_edge_index = data.train_pos_edge_index.long()\n",
    "data.test_pos_edge_index = data.test_pos_edge_index.long()\n",
    "data.train_neg_edge_index = data.train_neg_edge_index.long()\n",
    "data.test_neg_edge_index = data.test_neg_edge_index.long()"
   ],
   "id": "91f230b61ba4cc8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define number of nodes\n",
    "num_nodes = data.num_nodes\n",
    "\n",
    "# Node2Vec parameters\n",
    "embedding_dim = 64\n",
    "walk_length = 20\n",
    "context_size = 10\n",
    "walks_per_node = 10\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "num_epochs = 21"
   ],
   "id": "fba21fbb8d038909",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize Node2Vec\n",
    "node2vec = Node2Vec(\n",
    "    edge_index=original_edge_index,\n",
    "    embedding_dim=embedding_dim,\n",
    "    walk_length=walk_length,\n",
    "    context_size=context_size,\n",
    "    walks_per_node=walks_per_node,\n",
    "    num_negative_samples=1,\n",
    "    p=1,\n",
    "    q=1,\n",
    "    sparse=True,\n",
    "    num_nodes=num_nodes  # Specify number of nodes\n",
    ")\n",
    "\n",
    "# Move to the appropriate device (CPU/GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "node2vec = node2vec.to(device)"
   ],
   "id": "6f325c1adced2d3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Optimizer for Node2Vec\n",
    "optimizer = torch.optim.SparseAdam(node2vec.parameters(), lr=lr)"
   ],
   "id": "d2b1d3e64f0c57b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training loop for Node2Vec\n",
    "def train_node2vec(num_epochs):\n",
    "    node2vec.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        loader = node2vec.loader(batch_size=batch_size, shuffle=True, num_workers=0)  # Set num_workers=0\n",
    "        for i, (pos_rw, neg_rw) in enumerate(loader):\n",
    "            optimizer.zero_grad()\n",
    "            loss = node2vec.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch + 1}, Iteration {i}, Loss: {total_loss / 10}')\n",
    "                total_loss = 0"
   ],
   "id": "a4673e0d68813981",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train Node2Vec model\n",
    "train_node2vec(num_epochs)"
   ],
   "id": "36416a190e418fdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract embeddings\n",
    "node_embeddings = node2vec.embedding.weight.data.cpu().numpy()\n",
    "\n",
    "# Update node features with embeddings\n",
    "data.x = torch.tensor(node_embeddings, dtype=torch.float)"
   ],
   "id": "4f2994a9c90aef5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class GAE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GAE, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index, edge_weight):\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight))\n",
    "        return self.conv2(x, edge_index, edge_weight)\n",
    "\n",
    "    def decode(self, z, pos_edge_index, neg_edge_index):\n",
    "        pos_pred = (z[pos_edge_index[0].long()] * z[pos_edge_index[1].long()]).sum(dim=1)\n",
    "        neg_pred = (z[neg_edge_index[0].long()] * z[neg_edge_index[1].long()]).sum(dim=1)\n",
    "        return pos_pred, neg_pred\n",
    "\n",
    "    def forward(self, data):\n",
    "        z = self.encode(data.x, data.train_pos_edge_index, data.train_pos_edge_weight)\n",
    "        return z"
   ],
   "id": "280a1a320e603e0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize and train GAE model as before\n",
    "model = GAE(data.num_node_features, 32)  # Adjust dimensions as needed\n",
    "gae_optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ],
   "id": "d9923f5f9b0fdb86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train(data):\n",
    "    model.train()\n",
    "    gae_optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.train_pos_edge_index, data.train_pos_edge_weight)  # Pass train_pos_edge_weight\n",
    "    pos_pred, neg_pred = model.decode(z, data.train_pos_edge_index, data.train_neg_edge_index)\n",
    "    pos_loss = loss_fn(pos_pred, torch.ones_like(pos_pred))\n",
    "    neg_loss = loss_fn(neg_pred, torch.zeros_like(neg_pred))\n",
    "    loss = pos_loss + neg_loss\n",
    "    if torch.isnan(loss) or torch.isinf(loss):\n",
    "        print(\"Warning: NaN or Inf loss detected\")\n",
    "        return float('inf')\n",
    "    loss.backward()\n",
    "    gae_optimizer.step()\n",
    "    return loss.item()"
   ],
   "id": "d59e18cf369aff0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for epoch in range(30):\n",
    "    loss = train(data)\n",
    "    if loss == float('inf'):\n",
    "        break\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss}')"
   ],
   "id": "819793948be2b1e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def precision_at_k(y_true, y_pred, k):\n",
    "    idx = np.argsort(y_pred)[::-1][:k]\n",
    "    y_pred_binary = np.zeros_like(y_pred)\n",
    "    y_pred_binary[idx] = 1\n",
    "    tp = np.sum(y_true * y_pred_binary)\n",
    "    precision = tp / k\n",
    "    return precision\n",
    "\n",
    "def recall_at_k(y_true, y_pred, k):\n",
    "    idx = np.argsort(y_pred)[::-1][:k]\n",
    "    y_pred_binary = np.zeros_like(y_pred)\n",
    "    y_pred_binary[idx] = 1\n",
    "    tp = np.sum(y_true * y_pred_binary)\n",
    "    recall = tp / np.sum(y_true)\n",
    "    return recall\n",
    "\n",
    "def average_precision(y_true, y_pred):\n",
    "    idx = np.argsort(y_pred)[::-1]\n",
    "    y_true_sorted = y_true[idx]\n",
    "    tp = np.cumsum(y_true_sorted)\n",
    "    precision = tp / (np.arange(len(y_true_sorted)) + 1)\n",
    "    avg_precision = np.sum(precision * y_true_sorted) / np.sum(y_true_sorted)\n",
    "    return avg_precision\n",
    "\n",
    "def mean_average_precision(y_true, y_pred):\n",
    "    return np.mean([average_precision(y_t, y_p) for y_t, y_p in zip(y_true, y_pred)])\n",
    "\n",
    "def dcg_score(y_true, y_pred, k):\n",
    "    order = np.argsort(y_pred)[::-1]\n",
    "    y_true_sorted = np.take(y_true, order[:k])\n",
    "    gain = 2 ** y_true_sorted - 1\n",
    "    discounts = np.log2(np.arange(len(y_true_sorted)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "def ndcg_score(y_true, y_pred, k):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    actual = dcg_score(y_true, y_pred, k)\n",
    "    return actual / best"
   ],
   "id": "6d8004ed44dd947a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_model(data, model, k):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(data.x, data.val_pos_edge_index, data.val_pos_edge_weight)\n",
    "        pos_pred = torch.sigmoid((z[data.val_pos_edge_index[0].long()] * z[data.val_pos_edge_index[1].long()]).sum(dim=1)).cpu().numpy()\n",
    "        neg_pred = torch.sigmoid((z[data.val_neg_edge_index[0].long()] * z[data.val_neg_edge_index[1].long()]).sum(dim=1)).cpu().numpy()\n",
    "\n",
    "    y_true = np.concatenate([np.ones(pos_pred.shape[0]), np.zeros(neg_pred.shape[0])])\n",
    "    y_pred = np.concatenate([pos_pred, neg_pred])\n",
    "\n",
    "    auc_roc = roc_auc_score(y_true, y_pred)\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "\n",
    "    precision = precision_at_k(y_true, y_pred, k)\n",
    "    recall = recall_at_k(y_true, y_pred, k)\n",
    "    map_score = mean_average_precision([y_true], [y_pred])\n",
    "    ndcg = ndcg_score(y_true, y_pred, k)\n",
    "\n",
    "    return auc_roc, ap, precision, recall, map_score, ndcg"
   ],
   "id": "dd65d2d7892ba243",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "k=10",
   "id": "a6ac9fd7abb81a9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "auc_roc, ap, k_prec, recall, map_score, ndcg = evaluate_model(data, model, k)\n",
    "print(f\"AUC-ROC: {auc_roc:.4f}, AP: {ap:.4f}\")\n",
    "print(f\"Precision@{k}: {k_prec:.4f}\")\n",
    "print(f\"Recall@{k}: {recall:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}\")\n",
    "print(f\"NDCG@{k}: {ndcg:.4f}\")"
   ],
   "id": "37b2a03df1f5ce83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_best_candidates(job_descriptions, resumes, z, k=1):\n",
    "    job_ids = job_descriptions['job_id'].values\n",
    "    candidate_ids = resumes['candidate_id'].values + len(job_descriptions)\n",
    "\n",
    "    job_indices = job_ids - 1\n",
    "    candidate_indices = candidate_ids - 1\n",
    "\n",
    "    job_embeddings = z[job_indices]\n",
    "    candidate_embeddings = z[candidate_indices]\n",
    "\n",
    "    # Calculate scores using matrix multiplication\n",
    "    scores = torch.sigmoid(torch.matmul(job_embeddings, candidate_embeddings.T)).cpu().numpy()\n",
    "\n",
    "    predictions = []\n",
    "    for i, job_id in enumerate(job_ids):\n",
    "        best_match_indices = scores[i].argsort()[::-1][:k]\n",
    "        for idx in best_match_indices:\n",
    "            candidate_id = resumes.iloc[idx]['candidate_id']\n",
    "            candidate_job_title = resumes.iloc[idx]['job_title']\n",
    "            category = resumes.iloc[idx]['category']\n",
    "            skills = resumes.iloc[idx]['skills']\n",
    "            job_title = job_descriptions.iloc[i]['job_title']\n",
    "            job_skills = job_descriptions.iloc[i]['skills']\n",
    "            score = scores[i][idx]\n",
    "\n",
    "            match_percentage = score * 100  # Assuming the score is between 0 and 1\n",
    "            predictions.append({\n",
    "                \"Job ID\": job_id,\n",
    "                \"Job Title\": le_job_title.inverse_transform([job_title])[0],\n",
    "                \"Candidate ID\": candidate_id,\n",
    "                \"Candidate Job Title\": le_job_title.inverse_transform([candidate_job_title])[0],\n",
    "                \"Candidate Category\": le_category.inverse_transform([category])[0],\n",
    "                \"Match Percentage\": match_percentage,\n",
    "                \"Mutual Skills\": set(job_skills).intersection(set(skills)),\n",
    "                \"Job Skills\": job_skills,\n",
    "                \"Candidate Skills\": skills\n",
    "            })\n",
    "\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "    return predictions_df"
   ],
   "id": "a2bdfd90257c0b6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "with torch.no_grad():\n",
    "    z = model.encode(data.x, data.test_pos_edge_index, data.test_pos_edge_weight)"
   ],
   "id": "455e4c57053c84e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "jobs_to_predict = job_descriptions[job_descriptions['job_title'].isin(resumes['job_title'])].sample(frac=1, random_state=random_seed)",
   "id": "fed5a321cb5ba810",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions_df = predict_best_candidates(jobs_to_predict, resumes, z)\n",
    "predictions_df = predictions_df[predictions_df['Mutual Skills'].map(len) != 0]"
   ],
   "id": "7a2ba7424bc80603",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "predictions_df.head(75000)",
   "id": "1930b82d20689a44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T16:14:12.187993Z",
     "start_time": "2024-05-26T16:14:12.184246Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), f\"./models/gea-recommendation-system-v4-a01-1.pth\")",
   "id": "initial_id",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3d6f035b4107326f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
