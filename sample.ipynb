{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from torch_geometric.graphgym import optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Example DataFrame structures for job descriptions and resumes\n",
    "job_descriptions = pd.DataFrame({\n",
    "    'job_id': [1, 2],\n",
    "    'skills': [['python', 'ml'], ['java', 'spring']],\n",
    "    'job_title': ['data scientist', 'backend developer'],\n",
    "    'min_experience': [12, 24],\n",
    "    'max_experience': [36, 48]\n",
    "})\n",
    "\n",
    "resumes = pd.DataFrame({\n",
    "    'job_title': ['data scientist', 'backend developer'],\n",
    "    'skills': [['python', 'data analysis'], ['java', 'spring boot']],\n",
    "    'experience': [24, 36]\n",
    "})\n",
    "resumes['candidate_id'] = range(1, len(resumes) + 1)\n",
    "\n",
    "# One-hot encoding skills\n",
    "all_skills = list(set(sum(job_descriptions['skills'].tolist() + resumes['skills'].tolist(), [])))\n",
    "mlb = MultiLabelBinarizer(classes=all_skills)\n",
    "job_skills_encoded = mlb.fit_transform(job_descriptions['skills'])\n",
    "resume_skills_encoded = mlb.transform(resumes['skills'])\n",
    "\n",
    "job_skills_tensor = torch.tensor(job_skills_encoded, dtype=torch.float)\n",
    "resume_skills_tensor = torch.tensor(resume_skills_encoded, dtype=torch.float)\n",
    "\n",
    "# Function to create feature matrix from selected columns\n",
    "def create_feature_matrix(df, feature_columns):\n",
    "    features = []\n",
    "    for _, row in df.iterrows():\n",
    "        features.append(torch.tensor([row[col] for col in feature_columns], dtype=torch.float))\n",
    "    return torch.stack(features)\n",
    "\n",
    "# Append skill features to experience features\n",
    "job_exp_features = create_feature_matrix(job_descriptions, ['min_experience', 'max_experience'])\n",
    "resume_exp_features = create_feature_matrix(resumes, ['experience'])\n",
    "\n",
    "# Add dummy column to resume_exp_features to match job_exp_features dimensions\n",
    "dummy_column = torch.zeros(resume_exp_features.size(0), 1)\n",
    "resume_exp_features = torch.cat([resume_exp_features, dummy_column], dim=1)\n",
    "\n",
    "# Ensure the dimensions of tensors match correctly for concatenation\n",
    "job_features = torch.cat([job_skills_tensor, job_exp_features], dim=1)\n",
    "resume_features = torch.cat([resume_skills_tensor, resume_exp_features], dim=1)\n",
    "\n",
    "x_one_hot = torch.cat([job_features, resume_features], dim=0)\n",
    "\n",
    "# Embedding skills using nn.Embedding\n",
    "skill_to_index = {skill: idx for idx, skill in enumerate(all_skills)}\n",
    "embedding_dim = 50\n",
    "embedding = nn.Embedding(len(all_skills), embedding_dim)\n",
    "\n",
    "# Function to get average embedding for a list of skills\n",
    "def get_skill_embedding(skills, embedding, skill_to_index):\n",
    "    skill_indices = [skill_to_index[skill] for skill in skills if skill in skill_to_index]\n",
    "    if not skill_indices:\n",
    "        return torch.zeros(embedding_dim)\n",
    "    skill_tensor = torch.tensor(skill_indices, dtype=torch.long)\n",
    "    skill_embeddings = embedding(skill_tensor)\n",
    "    return skill_embeddings.mean(dim=0)\n",
    "\n",
    "# Encode skills as embeddings\n",
    "job_skills_embedded = torch.stack([get_skill_embedding(skills, embedding, skill_to_index) for skills in job_descriptions['skills']])\n",
    "resume_skills_embedded = torch.stack([get_skill_embedding(skills, embedding, skill_to_index) for skills in resumes['skills']])\n",
    "\n",
    "# Ensure the dimensions of tensors match correctly for concatenation\n",
    "job_features_embedded = torch.cat([job_skills_embedded, job_exp_features], dim=1)\n",
    "resume_features_embedded = torch.cat([resume_skills_embedded, resume_exp_features], dim=1)\n",
    "\n",
    "x_embeddings = torch.cat([job_features_embedded, resume_features_embedded], dim=0)\n",
    "\n",
    "# Function to create edge index for bipartite graph\n",
    "def create_edge_index(job_descriptions, resumes):\n",
    "    edges = []\n",
    "    for i, job in job_descriptions.iterrows():\n",
    "        for j, resume in resumes.iterrows():\n",
    "            if set(job['skills']).intersection(set(resume['skills'])):\n",
    "                edges.append([i, j + len(job_descriptions)])  # Offset for bipartite graph\n",
    "    return torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "edge_index = create_edge_index(job_descriptions, resumes)\n",
    "\n",
    "# Create Data objects for GCN\n",
    "data_one_hot = Data(x=x_one_hot, edge_index=edge_index)\n",
    "data_embeddings = Data(x=x_embeddings, edge_index=edge_index)\n",
    "\n",
    "# Define the GCN model\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "input_dim = x_embeddings.size(1)  # Number of input features (52 in this case)\n",
    "hidden_dim = 16  # Size of hidden layers\n",
    "output_dim = 2  # Size of the output layer\n",
    "\n",
    "model = GCN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Create realistic targets for binary classification\n",
    "num_jobs = len(job_descriptions)\n",
    "num_resumes = len(resumes)\n",
    "targets = torch.zeros(num_jobs + num_resumes, dtype=torch.long)\n",
    "targets[num_jobs:] = 1\n",
    "\n",
    "# Training loop with detailed debug information\n",
    "def train(data, model, criterion, optimizer, targets, epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        print(f'Output at epoch {epoch}: {out}')  # Debug: Print the model output\n",
    "        loss = criterion(out, targets)\n",
    "        print(f'Loss at epoch {epoch}: {loss}')  # Debug: Print the loss\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "train(data_embeddings, model, criterion, optimizer, targets)\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(model, data, targets):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "        accuracy = accuracy_score(targets, pred)\n",
    "        precision = precision_score(targets, pred)\n",
    "        recall = recall_score(targets, pred)\n",
    "        f1 = f1_score(targets, pred)\n",
    "        print(f'Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}')\n",
    "\n",
    "evaluate(model, data_embeddings, targets)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c93d0d2a370b085",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
