{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output at epoch 0: tensor([[10.8042,  2.7606],\n",
      "        [12.8000,  1.8840],\n",
      "        [11.4010,  2.7950],\n",
      "        [14.4341,  1.6823]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 0: 5.339587211608887\n",
      "Epoch 0, Loss: 5.339587211608887\n",
      "Output at epoch 1: tensor([[ 9.3973,  4.2724],\n",
      "        [11.0631,  3.2097],\n",
      "        [ 9.9110,  4.3318],\n",
      "        [12.6097,  3.4100]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 1: 3.6972529888153076\n",
      "Output at epoch 2: tensor([[ 8.0718,  5.7653],\n",
      "        [ 9.5510,  4.5265],\n",
      "        [ 8.5617,  5.8856],\n",
      "        [11.1239,  5.1961]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 2: 2.1936662197113037\n",
      "Output at epoch 3: tensor([[ 6.8248,  7.1930],\n",
      "        [ 8.5481,  6.5688],\n",
      "        [ 7.2943,  7.3760],\n",
      "        [10.0266,  7.4821]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 3: 1.07418954372406\n",
      "Output at epoch 4: tensor([[5.9485, 8.3504],\n",
      "        [7.6855, 8.6054],\n",
      "        [6.3813, 8.6448],\n",
      "        [9.0745, 9.7288]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 4: 1.0653457641601562\n",
      "Output at epoch 5: tensor([[ 5.3615,  8.8409],\n",
      "        [ 7.0766,  9.7464],\n",
      "        [ 5.7928,  9.2796],\n",
      "        [ 8.3794, 11.0642]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 5: 1.5856566429138184\n",
      "Output at epoch 6: tensor([[ 5.0209,  8.8013],\n",
      "        [ 6.6874, 10.0036],\n",
      "        [ 5.4376,  9.3432],\n",
      "        [ 7.9045, 11.4437]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 6: 1.8008315563201904\n",
      "Output at epoch 7: tensor([[ 4.8907,  8.4685],\n",
      "        [ 6.4540,  9.6816],\n",
      "        [ 5.2770,  9.0649],\n",
      "        [ 7.5870, 11.1733]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 7: 1.7304165363311768\n",
      "Output at epoch 8: tensor([[ 4.8500,  7.8938],\n",
      "        [ 6.3277,  8.9721],\n",
      "        [ 5.1956,  8.5074],\n",
      "        [ 7.3992, 10.4795]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 8: 1.4710224866867065\n",
      "Output at epoch 9: tensor([[4.8718, 7.1597],\n",
      "        [6.3232, 8.0526],\n",
      "        [5.1689, 7.7617],\n",
      "        [7.3353, 9.5356]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 9: 1.1136057376861572\n",
      "Output at epoch 10: tensor([[4.9341, 6.3300],\n",
      "        [6.4583, 7.3126],\n",
      "        [5.1781, 6.9008],\n",
      "        [7.3825, 8.6438]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 10: 0.8099345564842224\n",
      "Epoch 10, Loss: 0.8099345564842224\n",
      "Output at epoch 11: tensor([[5.0177, 5.4778],\n",
      "        [6.6275, 6.5837],\n",
      "        [5.2069, 6.0059],\n",
      "        [7.4627, 7.7347]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 11: 0.6396616101264954\n",
      "Output at epoch 12: tensor([[5.0998, 4.6873],\n",
      "        [6.7955, 5.9213],\n",
      "        [5.2375, 5.1776],\n",
      "        [7.5485, 6.9129]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 12: 0.6602104902267456\n",
      "Output at epoch 13: tensor([[5.1637, 4.0880],\n",
      "        [6.9296, 5.4428],\n",
      "        [5.2582, 4.5512],\n",
      "        [7.6149, 6.3246]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 13: 0.7846296429634094\n",
      "Output at epoch 14: tensor([[5.2141, 3.8153],\n",
      "        [7.0088, 5.1993],\n",
      "        [5.2795, 4.2490],\n",
      "        [7.6463, 6.0338]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 14: 0.875541627407074\n",
      "Output at epoch 15: tensor([[5.2126, 3.7010],\n",
      "        [7.0252, 5.1811],\n",
      "        [5.2705, 4.1487],\n",
      "        [7.6375, 6.0305]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 15: 0.8848986625671387\n",
      "Output at epoch 16: tensor([[5.1649, 3.7263],\n",
      "        [6.9856, 5.3576],\n",
      "        [5.2179, 4.2165],\n",
      "        [7.5943, 6.2766]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 16: 0.8153285384178162\n",
      "Output at epoch 17: tensor([[5.0815, 3.8639],\n",
      "        [6.9030, 5.6866],\n",
      "        [5.1481, 4.4297],\n",
      "        [7.5268, 6.7202]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 17: 0.7024712562561035\n",
      "Output at epoch 18: tensor([[4.9909, 4.0900],\n",
      "        [6.7986, 6.1176],\n",
      "        [5.0858, 4.7564],\n",
      "        [7.4501, 7.2965]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 18: 0.598658561706543\n",
      "Output at epoch 19: tensor([[4.9024, 4.3577],\n",
      "        [6.6940, 6.5848],\n",
      "        [5.0312, 5.1379],\n",
      "        [7.3787, 7.9227]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 19: 0.5490925908088684\n",
      "Output at epoch 20: tensor([[4.8303, 4.6206],\n",
      "        [6.6118, 7.0166],\n",
      "        [4.9940, 5.5178],\n",
      "        [7.3280, 8.5078]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 20: 0.5607092976570129\n",
      "Epoch 20, Loss: 0.5607092976570129\n",
      "Output at epoch 21: tensor([[4.7863, 4.8390],\n",
      "        [6.5697, 7.3542],\n",
      "        [4.9697, 5.8270],\n",
      "        [7.3094, 8.9769]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 21: 0.601706326007843\n",
      "Output at epoch 22: tensor([[4.7751, 4.9849],\n",
      "        [6.5761, 7.5633],\n",
      "        [4.9691, 6.0458],\n",
      "        [7.3280, 9.2862]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 22: 0.633159875869751\n",
      "Output at epoch 23: tensor([[4.7987, 5.0497],\n",
      "        [6.6329, 7.6347],\n",
      "        [5.0006, 6.1743],\n",
      "        [7.3850, 9.4243]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 23: 0.6331988573074341\n",
      "Output at epoch 24: tensor([[4.8553, 5.0366],\n",
      "        [6.7373, 7.5775],\n",
      "        [5.0622, 6.2158],\n",
      "        [7.4779, 9.4026]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 24: 0.5993197560310364\n",
      "Output at epoch 25: tensor([[4.9406, 4.9583],\n",
      "        [6.8829, 7.4135],\n",
      "        [5.1499, 6.1849],\n",
      "        [7.6019, 9.2491]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 25: 0.5438317060470581\n",
      "Output at epoch 26: tensor([[5.0479, 4.8351],\n",
      "        [7.0603, 7.1755],\n",
      "        [5.2579, 6.1055],\n",
      "        [7.7504, 9.0060]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 26: 0.48802104592323303\n",
      "Output at epoch 27: tensor([[5.1680, 4.6929],\n",
      "        [7.2565, 6.9062],\n",
      "        [5.3905, 6.0150],\n",
      "        [7.9144, 8.7276]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 27: 0.4531760811805725\n",
      "Output at epoch 28: tensor([[5.2835, 4.5576],\n",
      "        [7.4521, 6.6516],\n",
      "        [5.5444, 5.9502],\n",
      "        [8.0808, 8.4744]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 28: 0.4479691982269287\n",
      "Output at epoch 29: tensor([[5.3814, 4.4555],\n",
      "        [7.6357, 6.4649],\n",
      "        [5.6803, 5.9273],\n",
      "        [8.2423, 8.3095]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 29: 0.4602965712547302\n",
      "Output at epoch 30: tensor([[5.4704, 4.4306],\n",
      "        [7.8582, 6.4681],\n",
      "        [5.8007, 5.9856],\n",
      "        [8.4385, 8.3414]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 30: 0.4682372510433197\n",
      "Epoch 30, Loss: 0.4682372510433197\n",
      "Output at epoch 31: tensor([[5.5850, 4.5451],\n",
      "        [8.0640, 6.6066],\n",
      "        [5.9295, 6.1735],\n",
      "        [8.6319, 8.5401]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 31: 0.45766499638557434\n",
      "Output at epoch 32: tensor([[5.6805, 4.7300],\n",
      "        [8.2527, 6.8716],\n",
      "        [6.0352, 6.4396],\n",
      "        [8.8523, 8.9094]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 32: 0.4318173825740814\n",
      "Output at epoch 33: tensor([[5.7541, 4.9630],\n",
      "        [8.4066, 7.2248],\n",
      "        [6.1139, 6.7589],\n",
      "        [9.0316, 9.3813]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 33: 0.3991709351539612\n",
      "Output at epoch 34: tensor([[5.8118, 5.2140],\n",
      "        [8.5350, 7.6208],\n",
      "        [6.1733, 7.0985],\n",
      "        [9.1797, 9.9034]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 34: 0.376163125038147\n",
      "Output at epoch 35: tensor([[ 5.8604,  5.4464],\n",
      "        [ 8.6476,  8.0032],\n",
      "        [ 6.2215,  7.4184],\n",
      "        [ 9.3076, 10.4102]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 35: 0.3700259327888489\n",
      "Output at epoch 36: tensor([[ 5.9054,  5.6253],\n",
      "        [ 8.7525,  8.3166],\n",
      "        [ 6.2658,  7.6800],\n",
      "        [ 9.4244, 10.8374]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 36: 0.3742828965187073\n",
      "Output at epoch 37: tensor([[ 5.9510,  5.7257],\n",
      "        [ 8.8555,  8.5208],\n",
      "        [ 6.3113,  7.8554],\n",
      "        [ 9.5371, 11.1381]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 37: 0.3759469985961914\n",
      "Output at epoch 38: tensor([[ 6.0001,  5.7383],\n",
      "        [ 8.9608,  8.5997],\n",
      "        [ 6.3616,  7.9340],\n",
      "        [ 9.6506, 11.2933]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 38: 0.36625146865844727\n",
      "Output at epoch 39: tensor([[ 6.0541,  5.6701],\n",
      "        [ 9.0705,  8.5629],\n",
      "        [ 6.4179,  7.9232],\n",
      "        [ 9.7674, 11.3136]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 39: 0.3460630476474762\n",
      "Output at epoch 40: tensor([[ 6.1120,  5.5420],\n",
      "        [ 9.1838,  8.4408],\n",
      "        [ 6.4791,  7.8461],\n",
      "        [ 9.8868, 11.2347]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 40: 0.3238222897052765\n",
      "Epoch 40, Loss: 0.3238222897052765\n",
      "Output at epoch 41: tensor([[ 6.1710,  5.3836],\n",
      "        [ 9.2964,  8.2786],\n",
      "        [ 6.5412,  7.7359],\n",
      "        [10.0042, 11.1093]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 41: 0.30852749943733215\n",
      "Output at epoch 42: tensor([[ 6.2264,  5.2286],\n",
      "        [ 9.4020,  8.1268],\n",
      "        [ 6.5982,  7.6297],\n",
      "        [10.1122, 10.9964]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 42: 0.30271053314208984\n",
      "Output at epoch 43: tensor([[ 6.2733,  5.1067],\n",
      "        [ 9.4930,  8.0301],\n",
      "        [ 6.6438,  7.5611],\n",
      "        [10.2023, 10.9483]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 43: 0.3009446859359741\n",
      "Output at epoch 44: tensor([[ 6.3076,  5.0379],\n",
      "        [ 9.5637,  8.0165],\n",
      "        [ 6.6734,  7.5522],\n",
      "        [10.2679, 10.9976]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 44: 0.29532483220100403\n",
      "Output at epoch 45: tensor([[ 6.3283,  5.0274],\n",
      "        [ 9.6121,  8.0911],\n",
      "        [ 6.6853,  7.6088],\n",
      "        [10.3067, 11.1504]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 45: 0.2826469838619232\n",
      "Output at epoch 46: tensor([[ 6.3368,  5.0661],\n",
      "        [ 9.6407,  8.2360],\n",
      "        [ 6.6815,  7.7211],\n",
      "        [10.3215, 11.3858]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 46: 0.26649796962738037\n",
      "Output at epoch 47: tensor([[ 6.3373,  5.1338],\n",
      "        [ 9.6556,  8.4164],\n",
      "        [ 6.6672,  7.8665],\n",
      "        [10.3193, 11.6631]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 47: 0.25301238894462585\n",
      "Output at epoch 48: tensor([[ 6.3353,  5.2049],\n",
      "        [ 9.6647,  8.5895],\n",
      "        [ 6.6461,  8.0123],\n",
      "        [10.3095, 11.9324]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 48: 0.24517905712127686\n",
      "Output at epoch 49: tensor([[ 6.3370,  5.2572],\n",
      "        [ 9.6762,  8.7165],\n",
      "        [ 6.6517,  8.1447],\n",
      "        [10.3017, 12.1486]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 49: 0.2414669394493103\n",
      "Output at epoch 50: tensor([[ 6.3539,  5.2765],\n",
      "        [ 9.6995,  8.7720],\n",
      "        [ 6.6693,  8.2382],\n",
      "        [10.3076, 12.2818]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 50: 0.2363777756690979\n",
      "Epoch 50, Loss: 0.2363777756690979\n",
      "Output at epoch 51: tensor([[ 6.3865,  5.2564],\n",
      "        [ 9.7372,  8.7478],\n",
      "        [ 6.6955,  8.2844],\n",
      "        [10.3301, 12.3224]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 51: 0.2274078130722046\n",
      "Output at epoch 52: tensor([[ 6.4335,  5.2026],\n",
      "        [ 9.7884,  8.6548],\n",
      "        [ 6.7298,  8.2902],\n",
      "        [10.3683, 12.2828]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 52: 0.21586188673973083\n",
      "Output at epoch 53: tensor([[ 6.4922,  5.1304],\n",
      "        [ 9.8496,  8.5187],\n",
      "        [ 6.7716,  8.2738],\n",
      "        [10.4182, 12.1931]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 53: 0.20503833889961243\n",
      "Output at epoch 54: tensor([[ 6.5589,  5.0601],\n",
      "        [ 9.9150,  8.3733],\n",
      "        [ 6.8196,  8.2595],\n",
      "        [10.4729, 12.0928]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 54: 0.19719743728637695\n",
      "Output at epoch 55: tensor([[ 6.6296,  5.0118],\n",
      "        [ 9.9781,  8.2525],\n",
      "        [ 6.8724,  8.2716],\n",
      "        [10.5250, 12.0218]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 55: 0.19184616208076477\n",
      "Output at epoch 56: tensor([[ 6.7007,  5.0008],\n",
      "        [10.0335,  8.1823],\n",
      "        [ 6.9284,  8.3281],\n",
      "        [10.5681, 12.0104]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 56: 0.18658415973186493\n",
      "Output at epoch 57: tensor([[ 6.7700,  5.0332],\n",
      "        [10.0780,  8.1747],\n",
      "        [ 6.9887,  8.4367],\n",
      "        [10.5983, 12.0726]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 57: 0.17960089445114136\n",
      "Output at epoch 58: tensor([[ 6.8255,  5.1023],\n",
      "        [10.1065,  8.2241],\n",
      "        [ 7.0361,  8.5887],\n",
      "        [10.6089, 12.2017]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 58: 0.17076894640922546\n",
      "Output at epoch 59: tensor([[ 6.8701,  5.1951],\n",
      "        [10.1229,  8.3115],\n",
      "        [ 7.0794,  8.7702],\n",
      "        [10.6043, 12.3751]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 59: 0.16236305236816406\n",
      "Output at epoch 60: tensor([[ 6.9177,  5.2953],\n",
      "        [10.1375,  8.4102],\n",
      "        [ 7.1244,  8.9599],\n",
      "        [10.5977, 12.5618]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 60: 0.1557750403881073\n",
      "Epoch 60, Loss: 0.1557750403881073\n",
      "Output at epoch 61: tensor([[ 6.9708,  5.3843],\n",
      "        [10.1559,  8.4927],\n",
      "        [ 7.1716,  9.1355],\n",
      "        [10.5954, 12.7295]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 61: 0.15072742104530334\n",
      "Output at epoch 62: tensor([[ 7.0316,  5.4480],\n",
      "        [10.1824,  8.5384],\n",
      "        [ 7.2217,  9.2803],\n",
      "        [10.6025, 12.8538]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 62: 0.14587877690792084\n",
      "Output at epoch 63: tensor([[ 7.1011,  5.4798],\n",
      "        [10.2193,  8.5377],\n",
      "        [ 7.2751,  9.3867],\n",
      "        [10.6217, 12.9235]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 63: 0.1401635855436325\n",
      "Output at epoch 64: tensor([[ 7.1790,  5.4813],\n",
      "        [10.2664,  8.4933],\n",
      "        [ 7.3408,  9.4583],\n",
      "        [10.6529, 12.9416]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 64: 0.1338001936674118\n",
      "Output at epoch 65: tensor([[ 7.2560,  5.4597],\n",
      "        [10.3177,  8.4180],\n",
      "        [ 7.4117,  9.5042],\n",
      "        [10.6885, 12.9229]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 65: 0.12774629890918732\n",
      "Output at epoch 66: tensor([[ 7.3299,  5.4280],\n",
      "        [10.3696,  8.3307],\n",
      "        [ 7.4782,  9.5377],\n",
      "        [10.7241, 12.8895]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 66: 0.12252506613731384\n",
      "Output at epoch 67: tensor([[ 7.3983,  5.3994],\n",
      "        [10.4176,  8.2510],\n",
      "        [ 7.5372,  9.5742],\n",
      "        [10.7546, 12.8646]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 67: 0.11813519895076752\n",
      "Output at epoch 68: tensor([[ 7.4590,  5.3841],\n",
      "        [10.4583,  8.1945],\n",
      "        [ 7.5857,  9.6243],\n",
      "        [10.7760, 12.8664]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 68: 0.11404283344745636\n",
      "Output at epoch 69: tensor([[ 7.5098,  5.3860],\n",
      "        [10.4891,  8.1687],\n",
      "        [ 7.6212,  9.6922],\n",
      "        [10.7853, 12.9036]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 69: 0.10973017662763596\n",
      "Output at epoch 70: tensor([[ 7.5510,  5.4050],\n",
      "        [10.5101,  8.1731],\n",
      "        [ 7.6448,  9.7793],\n",
      "        [10.7825, 12.9755]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 70: 0.1051088348031044\n",
      "Epoch 70, Loss: 0.1051088348031044\n",
      "Output at epoch 71: tensor([[ 7.5842,  5.4361],\n",
      "        [10.5231,  8.1997],\n",
      "        [ 7.6587,  9.8798],\n",
      "        [10.7701, 13.0729]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 71: 0.1005224883556366\n",
      "Output at epoch 72: tensor([[ 7.6118,  5.4710],\n",
      "        [10.5315,  8.2357],\n",
      "        [ 7.6658,  9.9845],\n",
      "        [10.7602, 13.1820]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 72: 0.09649255871772766\n",
      "Output at epoch 73: tensor([[ 7.6402,  5.5016],\n",
      "        [10.5502,  8.2696],\n",
      "        [ 7.6739, 10.0840],\n",
      "        [10.7693, 13.2887]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 73: 0.09303221106529236\n",
      "Output at epoch 74: tensor([[ 7.6709,  5.5212],\n",
      "        [10.5802,  8.2914],\n",
      "        [ 7.6850, 10.1708],\n",
      "        [10.7850, 13.3795]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 74: 0.08969883620738983\n",
      "Output at epoch 75: tensor([[ 7.7046,  5.5264],\n",
      "        [10.6215,  8.2961],\n",
      "        [ 7.7000, 10.2407],\n",
      "        [10.8072, 13.4483]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 75: 0.08631309866905212\n",
      "Output at epoch 76: tensor([[ 7.7415,  5.5171],\n",
      "        [10.6734,  8.2840],\n",
      "        [ 7.7191, 10.2938],\n",
      "        [10.8356, 13.4957]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 76: 0.08285339176654816\n",
      "Output at epoch 77: tensor([[ 7.7811,  5.4962],\n",
      "        [10.7343,  8.2596],\n",
      "        [ 7.7415, 10.3332],\n",
      "        [10.8695, 13.5272]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 77: 0.07943835854530334\n",
      "Output at epoch 78: tensor([[ 7.8220,  5.4689],\n",
      "        [10.8022,  8.2306],\n",
      "        [ 7.7660, 10.3646],\n",
      "        [10.9142, 13.5529]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 78: 0.07630294561386108\n",
      "Output at epoch 79: tensor([[ 7.8596,  5.4404],\n",
      "        [10.8639,  8.2046],\n",
      "        [ 7.7855, 10.3924],\n",
      "        [10.9619, 13.5826]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 79: 0.07357578724622726\n",
      "Output at epoch 80: tensor([[ 7.8935,  5.4170],\n",
      "        [10.9181,  8.1897],\n",
      "        [ 7.7998, 10.4238],\n",
      "        [11.0005, 13.6245]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 80: 0.07099296897649765\n",
      "Epoch 80, Loss: 0.07099296897649765\n",
      "Output at epoch 81: tensor([[ 7.9232,  5.4014],\n",
      "        [10.9642,  8.1896],\n",
      "        [ 7.8091, 10.4635],\n",
      "        [11.0294, 13.6831]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 81: 0.06843959540128708\n",
      "Output at epoch 82: tensor([[ 7.9487,  5.3938],\n",
      "        [11.0024,  8.2043],\n",
      "        [ 7.8136, 10.5117],\n",
      "        [11.0489, 13.7583]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 82: 0.06589572131633759\n",
      "Output at epoch 83: tensor([[ 7.9708,  5.3922],\n",
      "        [11.0339,  8.2302],\n",
      "        [ 7.8214, 10.5669],\n",
      "        [11.0603, 13.8457]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 83: 0.06351802498102188\n",
      "Output at epoch 84: tensor([[ 7.9967,  5.3943],\n",
      "        [11.0634,  8.2617],\n",
      "        [ 7.8328, 10.6255],\n",
      "        [11.0699, 13.9391]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 84: 0.06126531958580017\n",
      "Output at epoch 85: tensor([[ 8.0267,  5.3969],\n",
      "        [11.0923,  8.2930],\n",
      "        [ 7.8472, 10.6837],\n",
      "        [11.0792, 14.0314]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 85: 0.059141114354133606\n",
      "Output at epoch 86: tensor([[ 8.0610,  5.3974],\n",
      "        [11.1219,  8.3189],\n",
      "        [ 7.8645, 10.7386],\n",
      "        [11.0898, 14.1166]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 86: 0.0571245439350605\n",
      "Output at epoch 87: tensor([[ 8.0996,  5.3945],\n",
      "        [11.1533,  8.3359],\n",
      "        [ 7.8849, 10.7887],\n",
      "        [11.1029, 14.1906]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 87: 0.05518309772014618\n",
      "Output at epoch 88: tensor([[ 8.1422,  5.3881],\n",
      "        [11.1867,  8.3428],\n",
      "        [ 7.9081, 10.8338],\n",
      "        [11.1189, 14.2520]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 88: 0.053296759724617004\n",
      "Output at epoch 89: tensor([[ 8.1883,  5.3790],\n",
      "        [11.2221,  8.3401],\n",
      "        [ 7.9341, 10.8751],\n",
      "        [11.1376, 14.3013]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 89: 0.05146930739283562\n",
      "Output at epoch 90: tensor([[ 8.2314,  5.3686],\n",
      "        [11.2562,  8.3298],\n",
      "        [ 7.9638, 10.9150],\n",
      "        [11.1549, 14.3409]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 90: 0.04980000853538513\n",
      "Epoch 90, Loss: 0.04980000853538513\n",
      "Output at epoch 91: tensor([[ 8.2711,  5.3591],\n",
      "        [11.2887,  8.3147],\n",
      "        [ 7.9894, 10.9553],\n",
      "        [11.1702, 14.3741]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 91: 0.04820205643773079\n",
      "Output at epoch 92: tensor([[ 8.3074,  5.3523],\n",
      "        [11.3190,  8.2975],\n",
      "        [ 8.0108, 10.9979],\n",
      "        [11.1830, 14.4041]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 92: 0.046668581664562225\n",
      "Output at epoch 93: tensor([[ 8.3401,  5.3491],\n",
      "        [11.3469,  8.2804],\n",
      "        [ 8.0278, 11.0443],\n",
      "        [11.1929, 14.4334]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 93: 0.045191191136837006\n",
      "Output at epoch 94: tensor([[ 8.3692,  5.3500],\n",
      "        [11.3720,  8.2648],\n",
      "        [ 8.0404, 11.0940],\n",
      "        [11.1997, 14.4637]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 94: 0.043768420815467834\n",
      "Output at epoch 95: tensor([[ 8.3946,  5.3535],\n",
      "        [11.3944,  8.2508],\n",
      "        [ 8.0481, 11.1453],\n",
      "        [11.2034, 14.4950]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 95: 0.04240046441555023\n",
      "Output at epoch 96: tensor([[ 8.4166,  5.3588],\n",
      "        [11.4143,  8.2382],\n",
      "        [ 8.0527, 11.1983],\n",
      "        [11.2041, 14.5273]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 96: 0.041091449558734894\n",
      "Output at epoch 97: tensor([[ 8.4413,  5.3651],\n",
      "        [11.4345,  8.2265],\n",
      "        [ 8.0639, 11.2521],\n",
      "        [11.2058, 14.5599]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 97: 0.03987748175859451\n",
      "Output at epoch 98: tensor([[ 8.4683,  5.3713],\n",
      "        [11.4552,  8.2153],\n",
      "        [ 8.0769, 11.3053],\n",
      "        [11.2110, 14.5924]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 98: 0.03872738778591156\n",
      "Output at epoch 99: tensor([[ 8.4998,  5.3771],\n",
      "        [11.4834,  8.2048],\n",
      "        [ 8.0929, 11.3573],\n",
      "        [11.2217, 14.6246]], grad_fn=<AddBackward0>)\n",
      "Loss at epoch 99: 0.037581369280815125\n",
      "Accuracy: 1.0, Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.graphgym import optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Example DataFrame structures for job descriptions and resumes\n",
    "job_descriptions = pd.DataFrame({\n",
    "    'job_id': [1, 2],\n",
    "    'skills': [['python', 'ml'], ['java', 'spring']],\n",
    "    'job_title': ['data scientist', 'backend developer'],\n",
    "    'min_experience': [12, 24],\n",
    "    'max_experience': [36, 48]\n",
    "})\n",
    "\n",
    "resumes = pd.DataFrame({\n",
    "    'job_title': ['data scientist', 'backend developer'],\n",
    "    'skills': [['python', 'data analysis'], ['java', 'spring boot']],\n",
    "    'experience': [24, 36]\n",
    "})\n",
    "resumes['candidate_id'] = range(1, len(resumes) + 1)\n",
    "\n",
    "# One-hot encoding skills\n",
    "all_skills = list(set(sum(job_descriptions['skills'].tolist() + resumes['skills'].tolist(), [])))\n",
    "mlb = MultiLabelBinarizer(classes=all_skills)\n",
    "job_skills_encoded = mlb.fit_transform(job_descriptions['skills'])\n",
    "resume_skills_encoded = mlb.transform(resumes['skills'])\n",
    "\n",
    "job_skills_tensor = torch.tensor(job_skills_encoded, dtype=torch.float)\n",
    "resume_skills_tensor = torch.tensor(resume_skills_encoded, dtype=torch.float)\n",
    "\n",
    "# Function to create feature matrix from selected columns\n",
    "def create_feature_matrix(df, feature_columns):\n",
    "    features = []\n",
    "    for _, row in df.iterrows():\n",
    "        features.append(torch.tensor([row[col] for col in feature_columns], dtype=torch.float))\n",
    "    return torch.stack(features)\n",
    "\n",
    "# Append skill features to experience features\n",
    "job_exp_features = create_feature_matrix(job_descriptions, ['min_experience', 'max_experience'])\n",
    "resume_exp_features = create_feature_matrix(resumes, ['experience'])\n",
    "\n",
    "# Add dummy column to resume_exp_features to match job_exp_features dimensions\n",
    "dummy_column = torch.zeros(resume_exp_features.size(0), 1)\n",
    "resume_exp_features = torch.cat([resume_exp_features, dummy_column], dim=1)\n",
    "\n",
    "# Ensure the dimensions of tensors match correctly for concatenation\n",
    "job_features = torch.cat([job_skills_tensor, job_exp_features], dim=1)\n",
    "resume_features = torch.cat([resume_skills_tensor, resume_exp_features], dim=1)\n",
    "\n",
    "x_one_hot = torch.cat([job_features, resume_features], dim=0)\n",
    "\n",
    "# Embedding skills using nn.Embedding\n",
    "skill_to_index = {skill: idx for idx, skill in enumerate(all_skills)}\n",
    "embedding_dim = 50\n",
    "embedding = nn.Embedding(len(all_skills), embedding_dim)\n",
    "\n",
    "# Function to get average embedding for a list of skills\n",
    "def get_skill_embedding(skills, embedding, skill_to_index):\n",
    "    skill_indices = [skill_to_index[skill] for skill in skills if skill in skill_to_index]\n",
    "    if not skill_indices:\n",
    "        return torch.zeros(embedding_dim)\n",
    "    skill_tensor = torch.tensor(skill_indices, dtype=torch.long)\n",
    "    skill_embeddings = embedding(skill_tensor)\n",
    "    return skill_embeddings.mean(dim=0)\n",
    "\n",
    "# Encode skills as embeddings\n",
    "job_skills_embedded = torch.stack([get_skill_embedding(skills, embedding, skill_to_index) for skills in job_descriptions['skills']])\n",
    "resume_skills_embedded = torch.stack([get_skill_embedding(skills, embedding, skill_to_index) for skills in resumes['skills']])\n",
    "\n",
    "# Ensure the dimensions of tensors match correctly for concatenation\n",
    "job_features_embedded = torch.cat([job_skills_embedded, job_exp_features], dim=1)\n",
    "resume_features_embedded = torch.cat([resume_skills_embedded, resume_exp_features], dim=1)\n",
    "\n",
    "x_embeddings = torch.cat([job_features_embedded, resume_features_embedded], dim=0)\n",
    "\n",
    "# Function to create edge index for bipartite graph\n",
    "def create_edge_index(job_descriptions, resumes):\n",
    "    edges = []\n",
    "    for i, job in job_descriptions.iterrows():\n",
    "        for j, resume in resumes.iterrows():\n",
    "            if set(job['skills']).intersection(set(resume['skills'])):\n",
    "                edges.append([i, j + len(job_descriptions)])  # Offset for bipartite graph\n",
    "    return torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "edge_index = create_edge_index(job_descriptions, resumes)\n",
    "\n",
    "# Create Data objects for GCN\n",
    "data_one_hot = Data(x=x_one_hot, edge_index=edge_index)\n",
    "data_embeddings = Data(x=x_embeddings, edge_index=edge_index)\n",
    "\n",
    "# Define the GCN model\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "input_dim = x_embeddings.size(1)  # Number of input features (52 in this case)\n",
    "hidden_dim = 16  # Size of hidden layers\n",
    "output_dim = 2  # Size of the output layer\n",
    "\n",
    "model = GCN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Create realistic targets for binary classification\n",
    "num_jobs = len(job_descriptions)\n",
    "num_resumes = len(resumes)\n",
    "targets = torch.zeros(num_jobs + num_resumes, dtype=torch.long)\n",
    "targets[num_jobs:] = 1\n",
    "\n",
    "# Training loop with detailed debug information\n",
    "def train(data, model, criterion, optimizer, targets, epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        print(f'Output at epoch {epoch}: {out}')  # Debug: Print the model output\n",
    "        loss = criterion(out, targets)\n",
    "        print(f'Loss at epoch {epoch}: {loss}')  # Debug: Print the loss\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "train(data_embeddings, model, criterion, optimizer, targets)\n",
    "\n",
    "# Evaluation\n",
    "def evaluate(model, data, targets):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "        accuracy = accuracy_score(targets, pred)\n",
    "        precision = precision_score(targets, pred)\n",
    "        recall = recall_score(targets, pred)\n",
    "        f1 = f1_score(targets, pred)\n",
    "        print(f'Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}')\n",
    "\n",
    "evaluate(model, data_embeddings, targets)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T20:41:44.004181Z",
     "start_time": "2024-05-24T20:41:43.849555Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
