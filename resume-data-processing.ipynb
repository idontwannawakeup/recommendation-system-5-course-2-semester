{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "nltk.download(['stopwords', 'wordnet'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def create_spacy_pattern(title):\n",
    "    words = title.split()\n",
    "    pattern = [{\"LOWER\": word.lower()} for word in words]\n",
    "    return {\"label\": \"TITLE\", \"pattern\": pattern}\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "skill_pattern_path = \"./data/preprocessing/jz_skill_patterns.jsonl\"\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "ruler.from_disk(skill_pattern_path)\n",
    "\n",
    "titles_df = pd.read_json('./data/preprocessing/job-titles.json')\n",
    "title_patterns = [create_spacy_pattern(title) for title in titles_df['job-titles'].to_numpy()]\n",
    "ruler.add_patterns(title_patterns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def resume_get_skills(doc):\n",
    "    skills = [ent.text for ent in doc.ents if ent.label_ == \"SKILL\"]\n",
    "    return list(set(skills))\n",
    "\n",
    "def resume_get_title(doc):\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"TITLE\":\n",
    "            return ent.text\n",
    "    return None\n",
    "\n",
    "def resume_get_experience(cv_text):\n",
    "    # Define a pattern for experience\n",
    "    experience_pattern = r'\\b(\\d+)\\s*(year|month)\\b'\n",
    "\n",
    "    # Find all experience mentions in the CV text\n",
    "    experience_found = re.findall(experience_pattern, cv_text)\n",
    "\n",
    "    # Filter out None or empty entries and sum up experience\n",
    "    total_months = 0\n",
    "    for value, unit in experience_found:\n",
    "        if unit == \"year\":\n",
    "            total_months += int(value) * 12\n",
    "        elif unit == \"month\":\n",
    "            total_months += int(value)\n",
    "\n",
    "    return total_months\n",
    "\n",
    "def clean_text(text):\n",
    "    review = re.sub('(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\"', \" \", text)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    lm = WordNetLemmatizer()\n",
    "    review = [lm.lemmatize(word) for word in review if word not in set(stopwords.words(\"english\"))]\n",
    "    return \" \".join(review)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "resume_df = pd.read_csv('./data/training/resume-dataset.csv')\n",
    "resume_df['candidate_id'] = range(1, len(resume_df) + 1)\n",
    "# resume_df = resume_df.reindex(np.random.permutation(resume_df.index))\n",
    "# resume_df = resume_df.copy().iloc[0:10,]"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "processed_resumes = []\n",
    "for _, row in resume_df.iterrows():\n",
    "    text = row['Resume']\n",
    "    candidate_id = row['candidate_id']\n",
    "    cv_text = clean_text(text)\n",
    "    doc = nlp(cv_text)\n",
    "    skills = resume_get_skills(doc)\n",
    "    title = resume_get_title(doc)\n",
    "    experience_data = resume_get_experience(cv_text)\n",
    "    processed_resumes.append({ \"candidate_id\": candidate_id, \"category\": row['Category'], \"job_title\": title, \"skills\": skills, \"experience\": experience_data })\n",
    "\n",
    "dataset = pd.DataFrame(processed_resumes)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset.head()"
  },
  {
   "cell_type": "code",
   "source": "dataset",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
